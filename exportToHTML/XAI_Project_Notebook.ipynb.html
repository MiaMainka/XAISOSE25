<html>
<head>
<title>XAI_Project_Notebook.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #080808;}
.s1 { color: #0033b3;}
.s2 { color: #8c8c8c; font-style: italic;}
.s3 { color: #067d17;}
.s4 { color: #1750eb;}
.s5 { color: #0037a6;}
.ls0 { height: 1px; border-width: 0; color: #dfe1e5; background-color:#dfe1e5}
.ln { color: #aeb3c2; font-weight: normal; font-style: normal; }
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
XAI_Project_Notebook.ipynb</font>
</center></td></tr></table>
<pre><a name="l1"><span class="ln">1    </span></a><span class="s0">#%% md 
<a name="l2"><span class="ln">2    </span></a>#  Student Habits vs Academic Performance 
<a name="l3"><span class="ln">3    </span></a> 
<a name="l4"><span class="ln">4    </span></a>--- 
<a name="l5"><span class="ln">5    </span></a> 
<a name="l6"><span class="ln">6    </span></a>**Projektarbeit im Rahmen des Kurses &quot;Erklärbare KI und Visualisierungen&quot;** 
<a name="l7"><span class="ln">7    </span></a>**Name:** Mia Mainka 
<a name="l8"><span class="ln">8    </span></a>**Matrikelnummer:** 3047072 
<a name="l9"><span class="ln">9    </span></a> 
<a name="l10"><span class="ln">10   </span></a>--- 
<a name="l11"><span class="ln">11   </span></a> 
<a name="l12"><span class="ln">12   </span></a>## Technische Rahmenbedingungen 
<a name="l13"><span class="ln">13   </span></a> 
<a name="l14"><span class="ln">14   </span></a>Dieses Projekt wurde unter folgenden technischen Voraussetzungen erstellt: 
<a name="l15"><span class="ln">15   </span></a> 
<a name="l16"><span class="ln">16   </span></a>- **Betriebssystem:** Windows 11 (64-Bit) 
<a name="l17"><span class="ln">17   </span></a>- **Python-Version:** 3.12.9 
<a name="l18"><span class="ln">18   </span></a>- **Entwicklungsumgebung (IDE):** JetBrains PyCharm 
<a name="l19"><span class="ln">19   </span></a> 
<a name="l20"><span class="ln">20   </span></a>Vor der Ausführung dieses Notebooks müssen alle benötigten Bibliotheken installiert werden. 
<a name="l21"><span class="ln">21   </span></a>Verwenden Sie dazu die bereitgestellte Datei `requirements.txt`, innerhalb einer virtuellen Umgebung. Außerdem muss der anschließende codeblock zum import aller Bibliotheken ausgeführt werden. 
<a name="l22"><span class="ln">22   </span></a> 
<a name="l23"><span class="ln">23   </span></a>```bash 
<a name="l24"><span class="ln">24   </span></a>pip install -r requirements.txt 
<a name="l25"><span class="ln">25   </span></a> 
<a name="l26"><span class="ln">26   </span></a> 
<a name="l27"><span class="ln">27   </span></a> <hr class="ls0"><a name="l28"><span class="ln">28   </span></a>#%% 
<a name="l29"><span class="ln">29   </span></a></span><span class="s1">import </span><span class="s0">pandas </span><span class="s1">as </span><span class="s0">pd</span>
<a name="l30"><span class="ln">30   </span></a><span class="s1">import </span><span class="s0">numpy </span><span class="s1">as </span><span class="s0">np</span>
<a name="l31"><span class="ln">31   </span></a><span class="s1">import </span><span class="s0">matplotlib.pyplot </span><span class="s1">as </span><span class="s0">plt</span>
<a name="l32"><span class="ln">32   </span></a><span class="s1">import </span><span class="s0">seaborn </span><span class="s1">as </span><span class="s0">sns</span>
<a name="l33"><span class="ln">33   </span></a><span class="s1">import </span><span class="s0">shap</span>
<a name="l34"><span class="ln">34   </span></a><span class="s1">import </span><span class="s0">ipywidgets </span><span class="s1">as </span><span class="s0">widgets</span>
<a name="l35"><span class="ln">35   </span></a><span class="s1">from </span><span class="s0">IPython.display </span><span class="s1">import </span><span class="s0">display, clear_output, HTML</span>
<a name="l36"><span class="ln">36   </span></a><span class="s1">from </span><span class="s0">sklearn.linear_model </span><span class="s1">import </span><span class="s0">LinearRegression</span>
<a name="l37"><span class="ln">37   </span></a><span class="s1">from </span><span class="s0">sklearn.ensemble </span><span class="s1">import </span><span class="s0">RandomForestRegressor</span>
<a name="l38"><span class="ln">38   </span></a><span class="s1">from </span><span class="s0">sklearn.model_selection </span><span class="s1">import </span><span class="s0">train_test_split</span>
<a name="l39"><span class="ln">39   </span></a><span class="s1">from </span><span class="s0">sklearn.preprocessing </span><span class="s1">import </span><span class="s0">OneHotEncoder</span>
<a name="l40"><span class="ln">40   </span></a><span class="s1">from </span><span class="s0">sklearn.compose </span><span class="s1">import </span><span class="s0">ColumnTransformer</span>
<a name="l41"><span class="ln">41   </span></a><span class="s1">from </span><span class="s0">sklearn.pipeline </span><span class="s1">import </span><span class="s0">Pipeline</span>
<a name="l42"><span class="ln">42   </span></a><span class="s1">from </span><span class="s0">sklearn.metrics </span><span class="s1">import </span><span class="s0">mean_squared_error, r2_score</span>
<a name="l43"><span class="ln">43   </span></a><span class="s1">from </span><span class="s0">scipy.stats </span><span class="s1">import </span><span class="s0">chi2_contingency, f_oneway</span>
<a name="l44"><span class="ln">44   </span></a><span class="s1">import </span><span class="s0">itertools</span>
<a name="l45"><span class="ln">45   </span></a><span class="s1">import </span><span class="s0">re</span>
<a name="l46"><span class="ln">46   </span></a>
<a name="l47"><span class="ln">47   </span></a><hr class="ls0"><a name="l48"><span class="ln">48   </span></a><span class="s0">#%% md 
<a name="l49"><span class="ln">49   </span></a>#  Inhaltsverzeichnis 
<a name="l50"><span class="ln">50   </span></a> 
<a name="l51"><span class="ln">51   </span></a>## Allgemeine Struktur 
<a name="l52"><span class="ln">52   </span></a> 
<a name="l53"><span class="ln">53   </span></a>- [Student Habits vs Academic Performance](#student-habits-vs-academic-performance) 
<a name="l54"><span class="ln">54   </span></a>  - [Technische Rahmenbedingungen](#technische-rahmenbedingungen) 
<a name="l55"><span class="ln">55   </span></a>  - [Inhaltsverzeichnis](#inhaltsverzeichnis-temporär) 
<a name="l56"><span class="ln">56   </span></a>  - [Einleitung](#einleitung) 
<a name="l57"><span class="ln">57   </span></a>    - [Übersicht der enthaltenen Merkmale](#übersicht-der-enthaltenen-merkmale) 
<a name="l58"><span class="ln">58   </span></a>    - [Synthetische Datengrundlage und methodische Einordnung](#synthetische-datengrundlage-und-methodische-einordnung) 
<a name="l59"><span class="ln">59   </span></a>    - [Limitationen für die Auswertung im Projektkontext](#limitationen-für-die-auswertung-im-projektkontext) 
<a name="l60"><span class="ln">60   </span></a>    - [Kontaktaufnahme zur Verifikation](#kontaktaufnahme-zur-verifikation) 
<a name="l61"><span class="ln">61   </span></a>    - [Zielsetzung und Forschungsfokus](#zielsetzung-und-forschungsfokus) 
<a name="l62"><span class="ln">62   </span></a> 
<a name="l63"><span class="ln">63   </span></a>## Explorative Datenanalyse 
<a name="l64"><span class="ln">64   </span></a> 
<a name="l65"><span class="ln">65   </span></a>- [Überblick über die Merkmalsverteilungen und explorative Datenanalyse](#überblick-über-die-merkmalsverteilungen-und-explorative-datenanalyse) 
<a name="l66"><span class="ln">66   </span></a>  - [Verteilung der numerischen Merkmale](#verteilung-der-numerischen-merkmale) 
<a name="l67"><span class="ln">67   </span></a>    - [Beschreibung und Interpretation der Verteilungen numerischer Merkmale](#beschreibung-und-interpretation-der-verteilungen-numerischer-merkmale) 
<a name="l68"><span class="ln">68   </span></a>    - [Beobachtungen und Interpretationen:](#beobachtungen-und-interpretationen) 
<a name="l69"><span class="ln">69   </span></a>    - [Darstellung als Korrelationsmatrix](#darstellung-als-korrelationsmatrix) 
<a name="l70"><span class="ln">70   </span></a>  - [Interpretation der Korrelationsmatrix](#interpretation-der-korrelationsmatrix) 
<a name="l71"><span class="ln">71   </span></a>    - [Vorgehen und Ziel](#vorgehen-und-ziel) 
<a name="l72"><span class="ln">72   </span></a>    - [Was ist auffällig?](#was-ist-auffällig) 
<a name="l73"><span class="ln">73   </span></a>    - [Was lässt sich daraus schließen?](#was-lässt-sich-daraus-schließen) 
<a name="l74"><span class="ln">74   </span></a>    - [Bewertung der Aussagekraft](#bewertung-der-aussagekraft) 
<a name="l75"><span class="ln">75   </span></a>  - [Verteilung kategorialer Daten](#verteilung-kategorialer-daten) 
<a name="l76"><span class="ln">76   </span></a>  - [Analyse der kategorialen Merkmale](#analyse-der-kategorialen-merkmale) 
<a name="l77"><span class="ln">77   </span></a>    - [Geschlecht (`gender`)](#geschlecht-gender) 
<a name="l78"><span class="ln">78   </span></a>    - [Nebenjob (`part_time_job`)](#nebenjob-part_time_job) 
<a name="l79"><span class="ln">79   </span></a>    - [Ernährung (`diet_quality`)](#ernährung-diet_quality) 
<a name="l80"><span class="ln">80   </span></a>    - [Bildungsstand der Eltern (`parental_education_level`)](#bildungsstand-der-eltern-parental_education_level) 
<a name="l81"><span class="ln">81   </span></a>    - [Internetqualität (`internet_quality`)](#internetqualität-internet_quality) 
<a name="l82"><span class="ln">82   </span></a>    - [Außercurriculare Aktivitäten (`extracurricular_participation`)](#außercurriculare-aktivitäten-extracurricular_participation) 
<a name="l83"><span class="ln">83   </span></a>    - [Fazit zur Verteilung](#fazit-zur-verteilung) 
<a name="l84"><span class="ln">84   </span></a>    - [Kreuzverteilungen zwischen kategorialen Merkmalen](#kreuzverteilungen-zwischen-kategorialen-merkmalen) 
<a name="l85"><span class="ln">85   </span></a>  - [Korrelation zwischen kategorialen Merkmalen](#korrelation-zwischen-kategorialen-merkmalen) 
<a name="l86"><span class="ln">86   </span></a>    - [Interpretation der Ergebnisse:](#interpretation-der-ergebnisse) 
<a name="l87"><span class="ln">87   </span></a>    - [Einordnung für die weitere Analyse:](#einordnung-für-die-weitere-analyse) 
<a name="l88"><span class="ln">88   </span></a>  - [Zusammenhang zwischen kategorialen und numerischen Merkmalen](#zusammenhang-zwischen-kategorialen-und-numerischen-merkmalen) 
<a name="l89"><span class="ln">89   </span></a>    - [Interpretation der Varianzaufklärung: Kategoriale vs. numerische Merkmale](#interpretation-der-varianzaufklärung-kategoriale-vs-numerische-merkmale) 
<a name="l90"><span class="ln">90   </span></a>  - [Fazit der explorativen Datenanalyse](#fazit-der-explorativen-datenanalyse) 
<a name="l91"><span class="ln">91   </span></a> 
<a name="l92"><span class="ln">92   </span></a>## Modellierung und Evaluation 
<a name="l93"><span class="ln">93   </span></a> 
<a name="l94"><span class="ln">94   </span></a>- [Modelltraining: Auswahl, Erklärung und Evaluation](#modelltraining-auswahl-erklärung-und-evaluation) 
<a name="l95"><span class="ln">95   </span></a>  - [Einleitung](#einleitung-1) 
<a name="l96"><span class="ln">96   </span></a>  - [Zielsetzung](#zielsetzung) 
<a name="l97"><span class="ln">97   </span></a>  - [Begründung für die Modellauswahl](#begründung-für-die-modellauswahl) 
<a name="l98"><span class="ln">98   </span></a>  - [Funktionsweise der linearen Regression](#funktionsweise-der-linearen-regression) 
<a name="l99"><span class="ln">99   </span></a>  - [Nächste Schritte lineare Regression](#nächste-schritte-lineare-regression) 
<a name="l100"><span class="ln">100  </span></a>  - [Bewertung des linearen Regressionsmodells](#bewertung-des-linearen-regressionsmodells) 
<a name="l101"><span class="ln">101  </span></a>    - [Modellgüte](#modellgüte) 
<a name="l102"><span class="ln">102  </span></a>    - [Interpretation und Limitationen](#interpretation-und-limitationen) 
<a name="l103"><span class="ln">103  </span></a>  - [Vergleichsmodell: Random Forest Regressor](#vergleichsmodell-random-forest-regressor) 
<a name="l104"><span class="ln">104  </span></a>  - [Auswertung des Random-Forest-Modells](#auswertung-des-random-forest-modells) 
<a name="l105"><span class="ln">105  </span></a>  - [Vergleich der Modelle: Lineare Regression vs. Random Forest](#vergleich-der-modelle-lineare-regression-vs-random-forest) 
<a name="l106"><span class="ln">106  </span></a>    - [Modellgüte und Vorhersagekraft im Vergleich](#modellgüte-und-vorhersagekraft-im-vergleich) 
<a name="l107"><span class="ln">107  </span></a>    - [Erklärbarkeit und didaktische Eignung](#erklärbarkeit-und-didaktische-eignung) 
<a name="l108"><span class="ln">108  </span></a>    - [Methodische Entscheidung](#methodische-entscheidung) 
<a name="l109"><span class="ln">109  </span></a> 
<a name="l110"><span class="ln">110  </span></a>## XAI-Analyse mit SHAP 
<a name="l111"><span class="ln">111  </span></a> 
<a name="l112"><span class="ln">112  </span></a>- [Einleitung in erklärbare KI (XAI / Explainable Artificial Intelligence)](#einleitung-in-erklärbare-ki-xai--explainable-artificial-intelligence) 
<a name="l113"><span class="ln">113  </span></a>  - [SHAP Barplot – Globale Bedeutung der Merkmale](#shap-barplot--globale-bedeutung-der-merkmale) 
<a name="l114"><span class="ln">114  </span></a>  - [SHAP Summary Plot – Wirkung und Streuung der Merkmalseffekte](#shap-summary-plot--wirkung-und-streuung-der-merkmalseffekte) 
<a name="l115"><span class="ln">115  </span></a>  - [SHAP Dependence Plot – Lernzeit in Wechselwirkung mit Schlafdauer](#shap-dependence-plot--lernzeit-in-wechselwirkung-mit-schlafdauer) 
<a name="l116"><span class="ln">116  </span></a>  - [SHAP Barplot – Globale Bedeutung der Merkmale (Random Forest)](#shap-barplot--globale-bedeutung-der-merkmale-random-forest) 
<a name="l117"><span class="ln">117  </span></a>  - [SHAP Summary Plot – Verteilung und Richtung der Merkmalseffekte (Random Forest)](#shap-summary-plot--verteilung-und-richtung-der-merkmalseffekte-random-forest) 
<a name="l118"><span class="ln">118  </span></a>  - [SHAP Dependence Plot – Lernzeit in Wechselwirkung mit Schlafdauer (Random Forest)](#shap-dependence-plot--lernzeit-in-wechselwirkung-mit-schlafdauer-random-forest) 
<a name="l119"><span class="ln">119  </span></a>  - [SHAP Dependence Plot – Mentale Gesundheit in Wechselwirkung mit Lernverhalten (Random Forest)](#shap-dependence-plot--mentale-gesundheit-in-wechselwirkung-mit-lernverhalten-random-forest) 
<a name="l120"><span class="ln">120  </span></a> 
<a name="l121"><span class="ln">121  </span></a>## Modellvergleich &amp; Schwellenwertanalyse 
<a name="l122"><span class="ln">122  </span></a> 
<a name="l123"><span class="ln">123  </span></a>- [Vergleich der erklärbaren Modelle: Lineare Regression vs. Random Forest](#vergleich-der-erklärbaren-modelle-lineare-regression-vs-random-forest) 
<a name="l124"><span class="ln">124  </span></a>  - [Vergleich der globalen SHAP-Werte – Lineare Regression vs. Random Forest](#vergleich-der-globalen-shap-werte--lineare-regression-vs-random-forest) 
<a name="l125"><span class="ln">125  </span></a> 
<a name="l126"><span class="ln">126  </span></a>- [Schwellenwertanalyse einzelner Merkmale](#schwellenwertanalyse-einzelner-merkmale) 
<a name="l127"><span class="ln">127  </span></a>  - [Schwellenwertanalyse: Einflussverlauf und Nullschnitt numerischer Merkmale](#schwellenwertanalyse-einflussverlauf-und-nullschnitt-numerischer-merkmale) 
<a name="l128"><span class="ln">128  </span></a>  - [Interpretation der Schwellenwertanalyse](#interpretation-der-schwellenwertanalyse) 
<a name="l129"><span class="ln">129  </span></a>    - [Was war erwartbar?](#was-war-erwartbar) 
<a name="l130"><span class="ln">130  </span></a>    - [Was war überraschend?](#was-war-überraschend) 
<a name="l131"><span class="ln">131  </span></a>    - [Bedeutung der Nullschnittpunkte](#bedeutung-der-nullschnittpunkte) 
<a name="l132"><span class="ln">132  </span></a> 
<a name="l133"><span class="ln">133  </span></a>## Fazit 
<a name="l134"><span class="ln">134  </span></a> 
<a name="l135"><span class="ln">135  </span></a>- [Schlussbetrachtung und Gesamteinordnung](#schlussbetrachtung-und-gesamteinordnung) 
<a name="l136"><span class="ln">136  </span></a>  - [Zusammenfassung des Projektverlaufs](#zusammenfassung-des-projektverlaufs) 
<a name="l137"><span class="ln">137  </span></a>    - [Methodische Reflexion](#methodische-reflexion) 
<a name="l138"><span class="ln">138  </span></a>    - [Interpretation der wichtigsten Ergebnisse](#interpretation-der-wichtigsten-ergebnisse) 
<a name="l139"><span class="ln">139  </span></a>    - [Limitationen](#limitationen) 
<a name="l140"><span class="ln">140  </span></a>    - [Bedeutung und Einsatzpotenzial](#bedeutung-und-einsatzpotenzial) 
<a name="l141"><span class="ln">141  </span></a>  - [Lessons Learned – Was aus dem Projekt mitgenommen wurde](#lessons-learned--was-aus-dem-projekt-mitgenommen-wurde) 
<a name="l142"><span class="ln">142  </span></a> 
<a name="l143"><span class="ln">143  </span></a>- [Bonus: Interaktiver Vorhersage-Rechner](#bonus-interaktiver-vorhersage-rechner) 
<a name="l144"><span class="ln">144  </span></a> 
<a name="l145"><span class="ln">145  </span></a> 
<a name="l146"><span class="ln">146  </span></a> <hr class="ls0"><a name="l147"><span class="ln">147  </span></a>#%% md 
<a name="l148"><span class="ln">148  </span></a>## Einleitung 
<a name="l149"><span class="ln">149  </span></a> 
<a name="l150"><span class="ln">150  </span></a>Diese Projektarbeit beschäftigt sich mit der Frage, wie bestimmte Verhaltensgewohnheiten und Lebensumstände von Studierenden mit ihrer akademischen Leistung zusammenhängen. Grundlage der Analyse ist der Datensatz 
<a name="l151"><span class="ln">151  </span></a>**[Student Habits vs Academic Performance](https://www.kaggle.com/datasets/jayaantanaath/student-habits-vs-academic-performance)**, bereitgestellt von Jayanta Naath auf Kaggle. 
<a name="l152"><span class="ln">152  </span></a> 
<a name="l153"><span class="ln">153  </span></a>Der Datensatz enthält **1.000 synthetisch erzeugte Beobachtungen** mit je 16 Merkmalen, die studentische Alltagsgewohnheiten, Ressourcen und mentale Faktoren erfassen. Die Zielvariable ist die erreichte **Prüfungsnote** (`exam_score`), welche als kontinuierlicher Wert angegeben ist. 
<a name="l154"><span class="ln">154  </span></a> 
<a name="l155"><span class="ln">155  </span></a>### Übersicht der enthaltenen Merkmale 
<a name="l156"><span class="ln">156  </span></a> 
<a name="l157"><span class="ln">157  </span></a>- `student_id` – eindeutiger Bezeichner je Datensatz 
<a name="l158"><span class="ln">158  </span></a>- `age` – Alter der Studierenden 
<a name="l159"><span class="ln">159  </span></a>- `gender` – Geschlecht (Male/Female) 
<a name="l160"><span class="ln">160  </span></a>- `study_hours_per_day` – tägliche Lernzeit in Stunden 
<a name="l161"><span class="ln">161  </span></a>- `social_media_hours` – tägliche Nutzung sozialer Medien 
<a name="l162"><span class="ln">162  </span></a>- `netflix_hours` – tägliche Netflix-Nutzung 
<a name="l163"><span class="ln">163  </span></a>- `part_time_job` – Nebenjob (Yes/No) 
<a name="l164"><span class="ln">164  </span></a>- `attendance_percentage` – Anwesenheitsquote in Prozent 
<a name="l165"><span class="ln">165  </span></a>- `sleep_hours` – durchschnittliche Schlafdauer pro Nacht 
<a name="l166"><span class="ln">166  </span></a>- `diet_quality` – Qualität der Ernährung (Poor, Fair, Good) 
<a name="l167"><span class="ln">167  </span></a>- `exercise_frequency` – sportliche Aktivität pro Woche (in Tagen) 
<a name="l168"><span class="ln">168  </span></a>- `parental_education_level` – höchster Bildungsabschluss der Eltern 
<a name="l169"><span class="ln">169  </span></a>- `internet_quality` – subjektive Einschätzung der Internetverbindung (Poor/Average/Good) 
<a name="l170"><span class="ln">170  </span></a>- `mental_health_rating` – Bewertung der psychischen Gesundheit (Skala 1–10) 
<a name="l171"><span class="ln">171  </span></a>- `extracurricular_participation` – Teilnahme an außercurricularen Aktivitäten (Yes/No) 
<a name="l172"><span class="ln">172  </span></a>- `exam_score` – Prüfungsleistung (Zielgröße) 
<a name="l173"><span class="ln">173  </span></a> 
<a name="l174"><span class="ln">174  </span></a>### Synthetische Datengrundlage und methodische Einordnung 
<a name="l175"><span class="ln">175  </span></a> 
<a name="l176"><span class="ln">176  </span></a>Laut Angabe des Autors handelt es sich bei diesem Datensatz um vollständig **synthetisch erzeugte Daten**, die mithilfe der Python-Bibliotheken `numpy` und `pandas` generiert wurden. Die Werte beruhen auf **zufälligen Verteilungen** und wurden durch **logische Abhängigkeiten** miteinander verknüpft, um laut Beschreibung *„real-life scenarios“* zu imitieren: 
<a name="l177"><span class="ln">177  </span></a> 
<a name="l178"><span class="ln">178  </span></a>&gt; *“This dataset is synthetic, created using Python libraries (numpy, pandas) with random distributions and logical dependencies to mimic real-life scenarios.”* 
<a name="l179"><span class="ln">179  </span></a> 
<a name="l180"><span class="ln">180  </span></a>Der genaue Aufbau dieser sogenannten „logical dependencies“ wird jedoch nicht näher erläutert. Es bleibt unklar, auf welchen realen Vorbildern diese Strukturen basieren – oder ob sie vollständig künstlich konstruiert wurden. Auch ist nicht ersichtlich, ob z.B. empirische Bildungsstudien oder statistische Referenzwerte für das Design herangezogen wurden. Diese Unbestimmtheit erschwert die methodische Rückverfolgbarkeit der erzeugten Muster. 
<a name="l181"><span class="ln">181  </span></a> 
<a name="l182"><span class="ln">182  </span></a>### Limitationen für die Auswertung im Projektkontext 
<a name="l183"><span class="ln">183  </span></a> 
<a name="l184"><span class="ln">184  </span></a>Aus der künstlichen Herkunft des Datensatzes ergeben sich mehrere Einschränkungen, die für die Interpretation der Analyseergebnisse zentral sind: 
<a name="l185"><span class="ln">185  </span></a> 
<a name="l186"><span class="ln">186  </span></a>1. Die dargestellten Zusammenhänge spiegeln keine realen Daten wider, sondern resultieren aus der Auswahl der verwendeten Verteilungen und Regeln bei der Simulation. 
<a name="l187"><span class="ln">187  </span></a>2. Eine Übertragbarkeit auf reale Studierendenpopulationen ist methodisch nicht möglich, da keine empirische Validierung stattgefunden hat. 
<a name="l188"><span class="ln">188  </span></a>3. Die Analyseergebnisse können zwar interne Strukturen und Korrelationen im Datensatz aufdecken, dürfen jedoch **nicht als kausale oder evidenzbasierte Aussagen** interpretiert werden. Die gefundenen Muster gelten ausschließlich innerhalb des simulierten Rahmens. 
<a name="l189"><span class="ln">189  </span></a> 
<a name="l190"><span class="ln">190  </span></a>Insbesondere der unklare Begriff „logical dependencies“ lässt offen, ob die beobachtbaren Beziehungen (z.B. zwischen Lernzeit und Prüfungsnote oder Social-Media-Konsum und mentaler Gesundheit) gezielt eingebaut wurden oder lediglich zufällig entstanden sind. Dadurch ist eine inhaltliche Bewertung der Ergebnisse nur mit großer methodischer Vorsicht möglich. 
<a name="l191"><span class="ln">191  </span></a> 
<a name="l192"><span class="ln">192  </span></a>### Kontaktaufnahme zur Verifikation 
<a name="l193"><span class="ln">193  </span></a> 
<a name="l194"><span class="ln">194  </span></a>Zur besseren Einschätzung des zugrundeliegenden Generierungsverfahrens wurde der Autor des Datensatzes per E-Mail kontaktiert. In der Anfrage wurde insbesondere um eine Erläuterung gebeten, wie die „realistischen Muster für Bildungspraxis“ konkret implementiert wurden. Zum Zeitpunkt der Dokumentation liegt noch keine Rückmeldung vor. Die methodische Herleitung bleibt daher vorerst unklar. 
<a name="l195"><span class="ln">195  </span></a> 
<a name="l196"><span class="ln">196  </span></a>Im Rahmen dieser Projektarbeit wird der Datensatz dennoch genutzt, um Verfahren erklärbarer KI zu erproben und explorative Visualisierungen durchzuführen. Die Interpretation aller Ergebnisse erfolgt bewusst zurückhaltend und **innerhalb des Rahmens der angenommenen Datenlogik**. 
<a name="l197"><span class="ln">197  </span></a> 
<a name="l198"><span class="ln">198  </span></a>### Zielsetzung und Forschungsfokus 
<a name="l199"><span class="ln">199  </span></a> 
<a name="l200"><span class="ln">200  </span></a>Ziel dieses Projekts ist es zu untersuchen, welche Gewohnheiten, Verhaltensmuster und Merkmale im studentischen Alltag mit der akademischen Leistung gemessen an der Prüfungsnote (`exam_score`) zusammenhängen. Dabei stehen folgende Leitfragen im Mittelpunkt: 
<a name="l201"><span class="ln">201  </span></a> 
<a name="l202"><span class="ln">202  </span></a>- Inwiefern wirken sich Variablen wie tägliche Lernzeit, Schlafdauer, Social-Media-Nutzung oder mentale Gesundheit auf die Prüfungsleistung aus? 
<a name="l203"><span class="ln">203  </span></a>- Welche Muster lassen sich bei Studierenden mit besonders hohen oder niedrigen Leistungen erkennen? 
<a name="l204"><span class="ln">204  </span></a>- Welche Merkmale zeigen sich – global betrachtet oder lokal an einzelnen Beispielen als besonders einflussreich für Modellentscheidungen? 
<a name="l205"><span class="ln">205  </span></a> 
<a name="l206"><span class="ln">206  </span></a>Ziel der Analyse ist es, mithilfe maschineller Lernverfahren und Methoden der erklärbaren KI (XAI - Explainable Artificial Intelligence) relevante Zusammenhänge aufzudecken und zu visualisieren. Dabei wird besonderer Wert auf Transparenz und Nachvollziehbarkeit gelegt. 
<a name="l207"><span class="ln">207  </span></a> 
<a name="l208"><span class="ln">208  </span></a>Das methodische Vorgehen orientiert sich an den Inhalten der begleitenden Vorlesung „Erklärbare KI und Visualisierungen“. Dabei kommen u.a. folgende Ansätze zum Einsatz: 
<a name="l209"><span class="ln">209  </span></a> 
<a name="l210"><span class="ln">210  </span></a>- **Explorative Datenanalyse (EDA)** zur Aufdeckung grundlegender Strukturen, Verteilungen und Korrelationen im Datensatz. 
<a name="l211"><span class="ln">211  </span></a>- **Modellierung mit Regressionsverfahren** und ggf. komplexeren Algorithmen, um Zusammenhänge zwischen den Merkmalen und der Zielgröße zu quantifizieren. 
<a name="l212"><span class="ln">212  </span></a>- **Erklärbarkeit durch XAI-Methoden**, insbesondere: 
<a name="l213"><span class="ln">213  </span></a>  - **LIME (Local Interpretable Model-Agnostic Explanations)** zur lokalen Erklärung einzelner Vorhersagen, 
<a name="l214"><span class="ln">214  </span></a>  - **SHAP (SHapley Additive ExPlanations)** zur Bestimmung globaler Merkmalseinflüsse und Wechselwirkungen. 
<a name="l215"><span class="ln">215  </span></a>- **Visuelle Aufbereitung der Ergebnisse**, um auch nicht-technischen Zielgruppen nachvollziehbare Einsichten zu ermöglichen. 
<a name="l216"><span class="ln">216  </span></a> 
<a name="l217"><span class="ln">217  </span></a>Die Analyseergebnisse werden stets im Kontext der synthetischen Natur des Datensatzes reflektiert und methodisch vorsichtig interpretiert. 
<a name="l218"><span class="ln">218  </span></a> 
<a name="l219"><span class="ln">219  </span></a> 
<a name="l220"><span class="ln">220  </span></a> <hr class="ls0"><a name="l221"><span class="ln">221  </span></a>#%% md 
<a name="l222"><span class="ln">222  </span></a>--- 
<a name="l223"><span class="ln">223  </span></a> 
<a name="l224"><span class="ln">224  </span></a># Überblick über die Merkmalsverteilungen und explorative Datenanalyse 
<a name="l225"><span class="ln">225  </span></a> 
<a name="l226"><span class="ln">226  </span></a>Bevor mit der Modellierung oder erklärenden Verfahren wie LIME oder SHAP begonnen werden kann, ist es wichtig zu verstehen, wie die einzelnen Merkmale im Datensatz verteilt sind. Die explorative Analyse (EDA) hilft dabei, ein erstes Gefühl für die Daten zu bekommen und mögliche Besonderheiten wie Ausreißer oder Schieflagen zu erkennen. 
<a name="l227"><span class="ln">227  </span></a> 
<a name="l228"><span class="ln">228  </span></a>In diesem Abschnitt werden alle Merkmale aufgeteilt in **numerische** und **kategoriale** Variablen untersucht. Ziel ist es, zu sehen: 
<a name="l229"><span class="ln">229  </span></a>- wie sich die Werte innerhalb eines Merkmals verteilen 
<a name="l230"><span class="ln">230  </span></a>- ob sich Auffälligkeiten oder Muster zeigen 
<a name="l231"><span class="ln">231  </span></a>- welche Variablen später für eine Modellierung besonders interessant sein könnten. 
<a name="l232"><span class="ln">232  </span></a> 
<a name="l233"><span class="ln">233  </span></a>Diese erste Analyse liefert wichtige Grundlagen für alle weiteren Schritte im Projekt. 
<a name="l234"><span class="ln">234  </span></a> 
<a name="l235"><span class="ln">235  </span></a> 
<a name="l236"><span class="ln">236  </span></a> <hr class="ls0"><a name="l237"><span class="ln">237  </span></a>#%% md 
<a name="l238"><span class="ln">238  </span></a>## Verteilung der numerischen Merkmale 
<a name="l239"><span class="ln">239  </span></a> 
<a name="l240"><span class="ln">240  </span></a>Numerische Merkmale sind kontinuierlich messbare Größen wie zum Beispiel Alter, tägliche Lernzeit oder Prüfungsleistung. In diesem Abschnitt wird die Verteilung aller numerischen Variablen dargestellt, um erste Muster zu erkennen. 
<a name="l241"><span class="ln">241  </span></a> 
<a name="l242"><span class="ln">242  </span></a>Besonders interessant ist dabei: 
<a name="l243"><span class="ln">243  </span></a>- ob die Verteilung symmetrisch oder schief ist, 
<a name="l244"><span class="ln">244  </span></a>- ob es extreme Ausprägungen gibt, 
<a name="l245"><span class="ln">245  </span></a>- und wie stark die Streuung innerhalb eines Merkmals ausfällt. 
<a name="l246"><span class="ln">246  </span></a> 
<a name="l247"><span class="ln">247  </span></a>Diese Erkenntnisse helfen später dabei, geeignete Modelle zu wählen und die Merkmale richtig vorzubereiten – z.B. ob eine Skalierung nötig ist oder ob sich ein Merkmal als erklärungsstark für die Zielgröße `exam_score` eignet. 
<a name="l248"><span class="ln">248  </span></a> <hr class="ls0"><a name="l249"><span class="ln">249  </span></a>#%% 
<a name="l250"><span class="ln">250  </span></a></span><span class="s2"># Schritt 2: CSV-Datei einlesen</span>
<a name="l251"><span class="ln">251  </span></a><span class="s2"># Die Datei muss im Unterordner &quot;data&quot; liegen</span>
<a name="l252"><span class="ln">252  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l253"><span class="ln">253  </span></a>
<a name="l254"><span class="ln">254  </span></a><span class="s2"># Schritt 3: Ungültige Werte bereinigen</span>
<a name="l255"><span class="ln">255  </span></a><span class="s2"># Altersangabe von 0 ist inhaltlich nicht plausibel und wird herausgefiltert</span>
<a name="l256"><span class="ln">256  </span></a><span class="s0">df_filtered = df[df[</span><span class="s3">&quot;age&quot;</span><span class="s0">] &gt; </span><span class="s4">0</span><span class="s0">].copy()</span>
<a name="l257"><span class="ln">257  </span></a>
<a name="l258"><span class="ln">258  </span></a><span class="s2"># Schritt 4: Liste numerischer Merkmale definieren</span>
<a name="l259"><span class="ln">259  </span></a><span class="s2"># Diese Merkmale sollen als Histogramme dargestellt werden</span>
<a name="l260"><span class="ln">260  </span></a><span class="s0">numerical_features = [</span>
<a name="l261"><span class="ln">261  </span></a>    <span class="s3">'age'</span><span class="s0">,</span>
<a name="l262"><span class="ln">262  </span></a>    <span class="s3">'study_hours_per_day'</span><span class="s0">,</span>
<a name="l263"><span class="ln">263  </span></a>    <span class="s3">'sleep_hours'</span><span class="s0">,</span>
<a name="l264"><span class="ln">264  </span></a>    <span class="s3">'social_media_hours'</span><span class="s0">,</span>
<a name="l265"><span class="ln">265  </span></a>    <span class="s3">'netflix_hours'</span><span class="s0">,</span>
<a name="l266"><span class="ln">266  </span></a>    <span class="s3">'attendance_percentage'</span><span class="s0">,</span>
<a name="l267"><span class="ln">267  </span></a>    <span class="s3">'exercise_frequency'</span><span class="s0">,</span>
<a name="l268"><span class="ln">268  </span></a>    <span class="s3">'mental_health_rating'</span><span class="s0">,</span>
<a name="l269"><span class="ln">269  </span></a>    <span class="s3">'exam_score'</span>
<a name="l270"><span class="ln">270  </span></a><span class="s0">]</span>
<a name="l271"><span class="ln">271  </span></a>
<a name="l272"><span class="ln">272  </span></a><span class="s2"># Schritt 5: Plot-Stil und Layout definieren</span>
<a name="l273"><span class="ln">273  </span></a><span class="s0">sns.set(style=</span><span class="s3">&quot;whitegrid&quot;</span><span class="s0">)  </span><span class="s2"># Heller Hintergrund mit Gitterlinien</span>
<a name="l274"><span class="ln">274  </span></a><span class="s0">plt.rcParams[</span><span class="s3">&quot;figure.figsize&quot;</span><span class="s0">] = (</span><span class="s4">16</span><span class="s0">, </span><span class="s4">12</span><span class="s0">)  </span><span class="s2"># Gesamtgröße des Plots</span>
<a name="l275"><span class="ln">275  </span></a><span class="s0">fig, axes = plt.subplots(</span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">)  </span><span class="s2"># 3x3-Raster für 9 Merkmale</span>
<a name="l276"><span class="ln">276  </span></a><span class="s0">axes = axes.flatten()  </span><span class="s2"># Achsenarray flach machen für einfacheren Zugriff</span>
<a name="l277"><span class="ln">277  </span></a>
<a name="l278"><span class="ln">278  </span></a><span class="s2"># Schritt 6: Farbverlauf festlegen</span>
<a name="l279"><span class="ln">279  </span></a><span class="s2"># &quot;coolwarm&quot; verläuft von blau (niedrig) über weiß zu rot (hoch)</span>
<a name="l280"><span class="ln">280  </span></a><span class="s0">cmap = plt.get_cmap(</span><span class="s3">&quot;coolwarm&quot;</span><span class="s0">)</span>
<a name="l281"><span class="ln">281  </span></a>
<a name="l282"><span class="ln">282  </span></a><span class="s2"># Schritt 7: Plot für jedes Merkmal erzeugen</span>
<a name="l283"><span class="ln">283  </span></a><span class="s1">for </span><span class="s0">i, feature </span><span class="s1">in </span><span class="s0">enumerate(numerical_features):</span>
<a name="l284"><span class="ln">284  </span></a>    <span class="s2"># Histogramm berechnen: Zähle Werte pro Intervall (bin)</span>
<a name="l285"><span class="ln">285  </span></a>    <span class="s0">counts, bins = np.histogram(df_filtered[feature], bins=</span><span class="s4">30</span><span class="s0">)</span>
<a name="l286"><span class="ln">286  </span></a>
<a name="l287"><span class="ln">287  </span></a>    <span class="s2"># Bin-Mittelpunkte für die Platzierung der Balken berechnen</span>
<a name="l288"><span class="ln">288  </span></a>    <span class="s0">bin_centers = </span><span class="s4">0.5 </span><span class="s0">* (bins[</span><span class="s4">1</span><span class="s0">:] + bins[:-</span><span class="s4">1</span><span class="s0">])</span>
<a name="l289"><span class="ln">289  </span></a>
<a name="l290"><span class="ln">290  </span></a>    <span class="s2"># Normierung: Häufigkeiten (counts) werden auf 0–1 skaliert für die Farbvergabe</span>
<a name="l291"><span class="ln">291  </span></a>    <span class="s0">norm = plt.Normalize(vmin=min(counts), vmax=max(counts))</span>
<a name="l292"><span class="ln">292  </span></a>
<a name="l293"><span class="ln">293  </span></a>    <span class="s2"># Farben zuweisen: Hohe Balken = warm (rot), niedrige = kühl (blau)</span>
<a name="l294"><span class="ln">294  </span></a>    <span class="s0">colors = cmap(norm(counts))</span>
<a name="l295"><span class="ln">295  </span></a>
<a name="l296"><span class="ln">296  </span></a>    <span class="s2"># Zeichne farbcodierte Balken</span>
<a name="l297"><span class="ln">297  </span></a>    <span class="s0">axes[i].bar(</span>
<a name="l298"><span class="ln">298  </span></a>        <span class="s0">bin_centers,  </span><span class="s2"># Position auf der x-Achse (zentriert)</span>
<a name="l299"><span class="ln">299  </span></a>        <span class="s0">counts,  </span><span class="s2"># Höhe der Balken</span>
<a name="l300"><span class="ln">300  </span></a>        <span class="s0">width=np.diff(bins),  </span><span class="s2"># Breite der Balken</span>
<a name="l301"><span class="ln">301  </span></a>        <span class="s0">align=</span><span class="s3">&quot;center&quot;</span><span class="s0">,  </span><span class="s2"># Balken mittig über bin platzieren</span>
<a name="l302"><span class="ln">302  </span></a>        <span class="s0">color=colors,  </span><span class="s2"># Farbe abhängig von Häufigkeit</span>
<a name="l303"><span class="ln">303  </span></a>        <span class="s0">edgecolor=</span><span class="s3">&quot;black&quot;  </span><span class="s2"># Schwarze Kanten für bessere Lesbarkeit</span>
<a name="l304"><span class="ln">304  </span></a>    <span class="s0">)</span>
<a name="l305"><span class="ln">305  </span></a>
<a name="l306"><span class="ln">306  </span></a>    <span class="s2"># Titel und Achsenbeschriftung setzen</span>
<a name="l307"><span class="ln">307  </span></a>    <span class="s0">axes[i].set_title(</span><span class="s3">f&quot;Verteilung von </span><span class="s5">{</span><span class="s0">feature</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s0">, fontsize=</span><span class="s4">11</span><span class="s0">)</span>
<a name="l308"><span class="ln">308  </span></a>    <span class="s0">axes[i].set_xlabel(feature)</span>
<a name="l309"><span class="ln">309  </span></a>    <span class="s0">axes[i].set_ylabel(</span><span class="s3">&quot;Häufigkeit&quot;</span><span class="s0">)</span>
<a name="l310"><span class="ln">310  </span></a>
<a name="l311"><span class="ln">311  </span></a><span class="s2"># Schritt 8: Gesamttitel und Layout anpassen</span>
<a name="l312"><span class="ln">312  </span></a><span class="s0">plt.suptitle(</span><span class="s3">&quot;Numerische Merkmale – farbliche Hervorhebung nach Häufigkeit&quot;</span><span class="s0">, fontsize=</span><span class="s4">15</span><span class="s0">)</span>
<a name="l313"><span class="ln">313  </span></a><span class="s0">plt.tight_layout(rect=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0.96</span><span class="s0">])</span>
<a name="l314"><span class="ln">314  </span></a><span class="s0">plt.show()</span>
<a name="l315"><span class="ln">315  </span></a><hr class="ls0"><a name="l316"><span class="ln">316  </span></a><span class="s0">#%% md 
<a name="l317"><span class="ln">317  </span></a>### Beschreibung und Interpretation der Verteilungen numerischer Merkmale 
<a name="l318"><span class="ln">318  </span></a> 
<a name="l319"><span class="ln">319  </span></a>In diesem Abschnitt wurden die wichtigsten numerischen Merkmale mithilfe von **Histogrammen** visualisiert. Ein Histogramm ist besonders geeignet, um die **Verteilung** einer kontinuierlichen Variable darzustellen, da es Häufigkeiten in bestimmten Wertebereichen (sogenannten Bins) zeigt. Die Histogramme wurden so eingefärbt, dass **häufig auftretende Werte rötlich** und **seltenere Werte bläulich** erscheinen. Das erleichtert das visuelle Erkennen von Schwerpunkten. 
<a name="l320"><span class="ln">320  </span></a> 
<a name="l321"><span class="ln">321  </span></a>#### Vorgehensweise: 
<a name="l322"><span class="ln">322  </span></a>- Es wurden 30 Bins pro Variable definiert (also 30 Werteintervalle mit gleicher Breite). 
<a name="l323"><span class="ln">323  </span></a>- Nur eindeutig unplausible Werte wurden vorab bereinigt, etwa `age = 0`. Realistische Nullen, wie z.B. `netflix_hours = 0`, wurden beibehalten. 
<a name="l324"><span class="ln">324  </span></a>- Die Plots zeigen die Häufigkeitsverteilung aller neun numerischen Merkmale im Datensatz. 
<a name="l325"><span class="ln">325  </span></a> 
<a name="l326"><span class="ln">326  </span></a>--- 
<a name="l327"><span class="ln">327  </span></a> 
<a name="l328"><span class="ln">328  </span></a>### Beobachtungen und Interpretationen: 
<a name="l329"><span class="ln">329  </span></a> 
<a name="l330"><span class="ln">330  </span></a>- **Alter (`age`)** 
<a name="l331"><span class="ln">331  </span></a>  Die Werte konzentrieren sich zwischen 18 und 24 Jahren, mit einem Peak bei etwa 20. Das entspricht einer typischen Studierendenpopulation. 
<a name="l332"><span class="ln">332  </span></a> 
<a name="l333"><span class="ln">333  </span></a>- **Tägliche Lernzeit (`study_hours_per_day`)** 
<a name="l334"><span class="ln">334  </span></a>  Die Verteilung ist leicht linksschief, mit einem deutlichen Peak zwischen 3 und 4 Stunden. Das ist plausibel für regulär Studierende. 
<a name="l335"><span class="ln">335  </span></a> 
<a name="l336"><span class="ln">336  </span></a>- **Schlafdauer (`sleep_hours`)** 
<a name="l337"><span class="ln">337  </span></a>  Der Schwerpunkt liegt zwischen 6 und 7 Stunden – das ist unterhalb der allgemein empfohlenen 7 bis 9 Stunden. Auffällig ist, dass Schlafzeiten unter 6 Stunden relativ häufig vorkommen, was möglicherweise auf eine hohe Belastung oder ungesunde Routinen hinweist. 
<a name="l338"><span class="ln">338  </span></a> 
<a name="l339"><span class="ln">339  </span></a>- **Social-Media-Nutzung (`social_media_hours`)** 
<a name="l340"><span class="ln">340  </span></a>  Die meisten Personen nutzen soziale Medien zwischen 2 und 4 Stunden täglich. Das liegt im erwartbaren Bereich, könnte aber je nach individueller Tagesplanung als hoch gewertet werden. 
<a name="l341"><span class="ln">341  </span></a> 
<a name="l342"><span class="ln">342  </span></a>- **Netflix-Nutzung (`netflix_hours`)** 
<a name="l343"><span class="ln">343  </span></a>  Viele Einträge liegen bei 1–2 Stunden pro Tag. Es gibt jedoch auch eine erkennbare Anzahl mit `0` Stunden, was realistisch und im Datensatz belassen wurde. 
<a name="l344"><span class="ln">344  </span></a> 
<a name="l345"><span class="ln">345  </span></a>- **Anwesenheitsquote (`attendance_percentage`)** 
<a name="l346"><span class="ln">346  </span></a>  Die Werte sind stark rechtsschief verteilt, mit einem Peak bei 100 %. Das könnte durch die Datensimulation bedingt sein und einen impliziten Zusammenhang mit Leistungsdaten nahelegen. 
<a name="l347"><span class="ln">347  </span></a> 
<a name="l348"><span class="ln">348  </span></a>- **Sporthäufigkeit (`exercise_frequency`)** 
<a name="l349"><span class="ln">349  </span></a>  Fast alle Werte sind gleichmäßig über 0–6 Tage verteilt, mit leichtem Peak bei 3 Tagen. Eine klare Vorliebe für bestimmte Bewegungsmuster ist nicht erkennbar. 
<a name="l350"><span class="ln">350  </span></a> 
<a name="l351"><span class="ln">351  </span></a>- **Mentale Gesundheit (`mental_health_rating`)** 
<a name="l352"><span class="ln">352  </span></a>  Die Werte verteilen sich relativ gleichmäßig auf die Skala von 1 bis 10, mit leichter Häufung im mittleren Bereich (5–7). Sehr niedrige Bewertungen (unter 3) kommen kaum vor. 
<a name="l353"><span class="ln">353  </span></a> 
<a name="l354"><span class="ln">354  </span></a>- **Prüfungsnote (`exam_score`)** 
<a name="l355"><span class="ln">355  </span></a>  Die Noten sind zwischen 40 und 100 breit verteilt, mit einem Peak bei ca. 75 Punkten. Auffällig ist, dass extrem niedrige Werte fast nicht vorhanden sind – das könnte ein Indiz für eine Verzerrung in der Datenverteilung sein. 
<a name="l356"><span class="ln">356  </span></a> 
<a name="l357"><span class="ln">357  </span></a>--- 
<a name="l358"><span class="ln">358  </span></a> 
<a name="l359"><span class="ln">359  </span></a>Diese erste Auswertung zeigt bereits wichtige Tendenzen im Datensatz, die im weiteren Projektverlauf berücksichtigt werden. Besonders die teilweise schiefen Verteilungen und die Peaks bei Extremwerten (z.B. 100 % Anwesenheit) sollten bei der Modellwahl und bei erklärenden Methoden wie LIME oder SHAP kritisch reflektiert werden. 
<a name="l360"><span class="ln">360  </span></a> <hr class="ls0"><a name="l361"><span class="ln">361  </span></a>#%% md 
<a name="l362"><span class="ln">362  </span></a>### Darstellung als Korrelationsmatrix <hr class="ls0"><a name="l363"><span class="ln">363  </span></a>#%% 
<a name="l364"><span class="ln">364  </span></a></span><span class="s2"># Schritt 2: Daten einlesen</span>
<a name="l365"><span class="ln">365  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l366"><span class="ln">366  </span></a>
<a name="l367"><span class="ln">367  </span></a><span class="s2"># Schritt 3: Unplausible Werte bereinigen (z.B. Alter = 0 ist nicht realistisch)</span>
<a name="l368"><span class="ln">368  </span></a><span class="s0">df = df[df[</span><span class="s3">&quot;age&quot;</span><span class="s0">] &gt; </span><span class="s4">0</span><span class="s0">]</span>
<a name="l369"><span class="ln">369  </span></a>
<a name="l370"><span class="ln">370  </span></a><span class="s2"># Schritt 4: Liste der numerischen Merkmale (wie bereits in vorheriger Analyse definiert)</span>
<a name="l371"><span class="ln">371  </span></a><span class="s0">numerical_features = [</span>
<a name="l372"><span class="ln">372  </span></a>    <span class="s3">'age'</span><span class="s0">,</span>
<a name="l373"><span class="ln">373  </span></a>    <span class="s3">'study_hours_per_day'</span><span class="s0">,</span>
<a name="l374"><span class="ln">374  </span></a>    <span class="s3">'sleep_hours'</span><span class="s0">,</span>
<a name="l375"><span class="ln">375  </span></a>    <span class="s3">'social_media_hours'</span><span class="s0">,</span>
<a name="l376"><span class="ln">376  </span></a>    <span class="s3">'netflix_hours'</span><span class="s0">,</span>
<a name="l377"><span class="ln">377  </span></a>    <span class="s3">'attendance_percentage'</span><span class="s0">,</span>
<a name="l378"><span class="ln">378  </span></a>    <span class="s3">'exercise_frequency'</span><span class="s0">,</span>
<a name="l379"><span class="ln">379  </span></a>    <span class="s3">'mental_health_rating'</span><span class="s0">,</span>
<a name="l380"><span class="ln">380  </span></a>    <span class="s3">'exam_score'</span>
<a name="l381"><span class="ln">381  </span></a><span class="s0">]</span>
<a name="l382"><span class="ln">382  </span></a>
<a name="l383"><span class="ln">383  </span></a><span class="s2"># Schritt 5: Korrelationsmatrix berechnen (nur für numerische Merkmale)</span>
<a name="l384"><span class="ln">384  </span></a><span class="s0">correlation_matrix = df[numerical_features].corr()</span>
<a name="l385"><span class="ln">385  </span></a>
<a name="l386"><span class="ln">386  </span></a><span class="s2"># Schritt 6: Plot-Stil und Größe definieren</span>
<a name="l387"><span class="ln">387  </span></a><span class="s0">sns.set(style=</span><span class="s3">&quot;whitegrid&quot;</span><span class="s0">)</span>
<a name="l388"><span class="ln">388  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">12</span><span class="s0">, </span><span class="s4">9</span><span class="s0">))</span>
<a name="l389"><span class="ln">389  </span></a>
<a name="l390"><span class="ln">390  </span></a><span class="s2"># Schritt 7: Heatmap erzeugen</span>
<a name="l391"><span class="ln">391  </span></a><span class="s0">sns.heatmap(</span>
<a name="l392"><span class="ln">392  </span></a>    <span class="s0">correlation_matrix,</span>
<a name="l393"><span class="ln">393  </span></a>    <span class="s0">annot=</span><span class="s1">True</span><span class="s0">,              </span><span class="s2"># Korrelationswerte als Text anzeigen</span>
<a name="l394"><span class="ln">394  </span></a>    <span class="s0">fmt=</span><span class="s3">&quot;.2f&quot;</span><span class="s0">,               </span><span class="s2"># Format mit 2 Nachkommastellen</span>
<a name="l395"><span class="ln">395  </span></a>    <span class="s0">cmap=</span><span class="s3">&quot;coolwarm&quot;</span><span class="s0">,         </span><span class="s2"># Farbskala: Blau = negativ, Rot = positiv</span>
<a name="l396"><span class="ln">396  </span></a>    <span class="s0">square=</span><span class="s1">True</span><span class="s0">,             </span><span class="s2"># Zellen quadratisch</span>
<a name="l397"><span class="ln">397  </span></a>    <span class="s0">linewidths=</span><span class="s4">0.5</span><span class="s0">,          </span><span class="s2"># Linien zwischen Feldern</span>
<a name="l398"><span class="ln">398  </span></a>    <span class="s0">cbar_kws={</span><span class="s3">&quot;shrink&quot;</span><span class="s0">: </span><span class="s4">.8</span><span class="s0">}  </span><span class="s2"># Farblegende verkleinern</span>
<a name="l399"><span class="ln">399  </span></a><span class="s0">)</span>
<a name="l400"><span class="ln">400  </span></a>
<a name="l401"><span class="ln">401  </span></a><span class="s2"># Schritt 8: Achsentitel und Layout anpassen</span>
<a name="l402"><span class="ln">402  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Korrelationsmatrix der numerischen Merkmale&quot;</span><span class="s0">, fontsize=</span><span class="s4">14</span><span class="s0">)</span>
<a name="l403"><span class="ln">403  </span></a><span class="s0">plt.xticks(rotation=</span><span class="s4">45</span><span class="s0">, ha=</span><span class="s3">&quot;right&quot;</span><span class="s0">)</span>
<a name="l404"><span class="ln">404  </span></a><span class="s0">plt.yticks(rotation=</span><span class="s4">0</span><span class="s0">)</span>
<a name="l405"><span class="ln">405  </span></a><span class="s0">plt.tight_layout()</span>
<a name="l406"><span class="ln">406  </span></a><span class="s0">plt.show()</span>
<a name="l407"><span class="ln">407  </span></a><hr class="ls0"><a name="l408"><span class="ln">408  </span></a><span class="s0">#%% md 
<a name="l409"><span class="ln">409  </span></a>## Interpretation der Korrelationsmatrix 
<a name="l410"><span class="ln">410  </span></a> 
<a name="l411"><span class="ln">411  </span></a>Um ein besseres Verständnis für die Zusammenhänge zwischen den numerischen Variablen im Datensatz zu gewinnen, wurde eine **Korrelationsmatrix** erstellt und als Heatmap visualisiert. Dabei wurde der Pearson-Korrelationskoeffizient berechnet, der angibt, wie stark zwei Variablen **linear** miteinander zusammenhängen. 
<a name="l412"><span class="ln">412  </span></a> 
<a name="l413"><span class="ln">413  </span></a>Die Darstellung zeigt, in welchem Ausmaß sich zwei Merkmale gemeinsam verändern, also ob hohe Werte des einen Merkmals mit hohen (positiver Zusammenhang) oder niedrigen Werten (negativer Zusammenhang) des anderen Merkmals einhergehen. Die Farbskala reicht von **blau (negativ)** bis **rot (positiv)** und verdeutlicht die Stärke dieser Zusammenhänge auf einen Blick. 
<a name="l414"><span class="ln">414  </span></a> 
<a name="l415"><span class="ln">415  </span></a>--- 
<a name="l416"><span class="ln">416  </span></a> 
<a name="l417"><span class="ln">417  </span></a>### Vorgehen und Ziel 
<a name="l418"><span class="ln">418  </span></a> 
<a name="l419"><span class="ln">419  </span></a>Die Korrelationsanalyse wurde ausschließlich auf **numerische Merkmale** angewendet, da für kategoriale Merkmale andere Methoden wie z.B. Cramér’s V oder logistische Regressionsansätze besser geeignet sind. 
<a name="l420"><span class="ln">420  </span></a> 
<a name="l421"><span class="ln">421  </span></a>Ziel dieser Darstellung ist es: 
<a name="l422"><span class="ln">422  </span></a>- frühe Hinweise auf **relevante Einflussfaktoren** für die Prüfungsleistung (`exam_score`) zu erkennen, 
<a name="l423"><span class="ln">423  </span></a>- **redundante Merkmale** zu identifizieren, die stark miteinander korreliert sein könnten, 
<a name="l424"><span class="ln">424  </span></a>- und eine Grundlage für die spätere Auswahl und Bewertung von Modellen und Erklärbarkeits-Methoden zu schaffen. 
<a name="l425"><span class="ln">425  </span></a> 
<a name="l426"><span class="ln">426  </span></a>--- 
<a name="l427"><span class="ln">427  </span></a> 
<a name="l428"><span class="ln">428  </span></a>### Was ist auffällig? 
<a name="l429"><span class="ln">429  </span></a> 
<a name="l430"><span class="ln">430  </span></a>Beim Durchsehen der Heatmap fallen mehrere interessante Punkte auf: 
<a name="l431"><span class="ln">431  </span></a> 
<a name="l432"><span class="ln">432  </span></a>- **Starke Korrelation** zwischen `study_hours_per_day` und `exam_score` (**+0.83**): 
<a name="l433"><span class="ln">433  </span></a>  Diese Beziehung ist sehr deutlich und deckt sich mit der allgemeinen Erwartung, dass mehr tägliche Lernzeit zu besseren Prüfungsergebnissen führt. Es ist plausibel und unterstreicht die Bedeutung dieser Variable für spätere Modelle. 
<a name="l434"><span class="ln">434  </span></a> 
<a name="l435"><span class="ln">435  </span></a>- **Moderate Korrelation** zwischen `mental_health_rating` und `exam_score` (**+0.32**): 
<a name="l436"><span class="ln">436  </span></a>  Auch hier zeigt sich ein nachvollziehbarer Zusammenhang: Studierende mit besser eingeschätztem mentalen Wohlbefinden scheinen tendenziell bessere Noten zu erreichen. Es wäre interessant, ob dieser Zusammenhang auch bei realen Daten bestehen bleibt. 
<a name="l437"><span class="ln">437  </span></a> 
<a name="l438"><span class="ln">438  </span></a>- **Schwache negative Korrelationen** zwischen `social_media_hours`, `netflix_hours` und `exam_score` (jeweils **-0.17**): 
<a name="l439"><span class="ln">439  </span></a>  Diese deuten darauf hin, dass übermäßiger Konsum von Medieninhalten leicht negativ mit der Prüfungsleistung zusammenhängt. Ein häufig angenommener, aber hier nur schwach messbarer Effekt. 
<a name="l440"><span class="ln">440  </span></a> 
<a name="l441"><span class="ln">441  </span></a>- **`age` ist mit fast keinem anderen Merkmal korreliert** (nahe 0): 
<a name="l442"><span class="ln">442  </span></a>  Das liegt daran, dass die Studierenden in der Stichprobe alle sehr ähnliche Altersangaben haben (zwischen 18 und 24 Jahren). Da wenig Varianz besteht, kann auch kaum eine lineare Beziehung zu anderen Merkmalen bestehen. 
<a name="l443"><span class="ln">443  </span></a> 
<a name="l444"><span class="ln">444  </span></a>--- 
<a name="l445"><span class="ln">445  </span></a> 
<a name="l446"><span class="ln">446  </span></a>### Was lässt sich daraus schließen? 
<a name="l447"><span class="ln">447  </span></a> 
<a name="l448"><span class="ln">448  </span></a>Die Analyse zeigt, dass **nicht alle Variablen gleichermaßen informativ** für die Zielgröße `exam_score` sind. Besonders `study_hours_per_day`, aber auch `mental_health_rating`, `exercise_frequency` und `attendance_percentage` liefern erste Hinweise auf potenziell relevante Prädiktoren. 
<a name="l449"><span class="ln">449  </span></a> 
<a name="l450"><span class="ln">450  </span></a>Gleichzeitig ist klar: 
<a name="l451"><span class="ln">451  </span></a>Eine hohe oder niedrige Korrelation sagt noch nichts über Kausalität aus. Es könnte z.B. sein, dass gute Noten die Motivation zum Lernen erhöhen (statt umgekehrt) oder dass beide Effekte durch Dritte beeinflusst werden. Um diese Fragen zu klären, sind **modellspezifische Erklärungen** durch LIME oder SHAP notwendig, die im weiteren Verlauf des Notebooks erfolgen. 
<a name="l452"><span class="ln">452  </span></a> 
<a name="l453"><span class="ln">453  </span></a>--- 
<a name="l454"><span class="ln">454  </span></a> 
<a name="l455"><span class="ln">455  </span></a>### Bewertung der Aussagekraft 
<a name="l456"><span class="ln">456  </span></a> 
<a name="l457"><span class="ln">457  </span></a>Die Korrelationsmatrix ist ein **wertvoller erster Schritt**, um grobe Zusammenhänge zu erfassen. Sie hilft dabei: 
<a name="l458"><span class="ln">458  </span></a>- **Hypothesen zu formulieren**, die später geprüft werden können, 
<a name="l459"><span class="ln">459  </span></a>- die **Modellwahl gezielter** zu gestalten (z.B. Merkmalsauswahl), 
<a name="l460"><span class="ln">460  </span></a>- und **Redundanz zwischen Features** zu erkennen. 
<a name="l461"><span class="ln">461  </span></a> 
<a name="l462"><span class="ln">462  </span></a>Jedoch muss betont werden, dass komplexe, nichtlineare Zusammenhänge hier **nicht sichtbar** sind. Diese erfordern weiterführende Visualisierungen und modellbasierte Analysen, wie sie im nächsten Schritt des Projekts folgen werden. 
<a name="l463"><span class="ln">463  </span></a> <hr class="ls0"><a name="l464"><span class="ln">464  </span></a>#%% md 
<a name="l465"><span class="ln">465  </span></a>--- 
<a name="l466"><span class="ln">466  </span></a>## Verteilung kategorialer Daten <hr class="ls0"><a name="l467"><span class="ln">467  </span></a>#%% 
<a name="l468"><span class="ln">468  </span></a></span><span class="s2"># Schritt 2: CSV-Datei einlesen</span>
<a name="l469"><span class="ln">469  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l470"><span class="ln">470  </span></a>
<a name="l471"><span class="ln">471  </span></a><span class="s2"># Schritt 3: Plot-Stil und Darstellungsoptionen festlegen</span>
<a name="l472"><span class="ln">472  </span></a><span class="s0">sns.set(style=</span><span class="s3">&quot;whitegrid&quot;</span><span class="s0">)  </span><span class="s2"># Heller Hintergrund mit Gitter</span>
<a name="l473"><span class="ln">473  </span></a><span class="s0">plt.rcParams[</span><span class="s3">&quot;figure.figsize&quot;</span><span class="s0">] = (</span><span class="s4">14</span><span class="s0">, </span><span class="s4">10</span><span class="s0">)  </span><span class="s2"># Standardgröße der Plots</span>
<a name="l474"><span class="ln">474  </span></a>
<a name="l475"><span class="ln">475  </span></a><span class="s2"># Schritt 4: Liste aller kategorialen Merkmale definieren</span>
<a name="l476"><span class="ln">476  </span></a><span class="s0">categorical_features = [</span>
<a name="l477"><span class="ln">477  </span></a>    <span class="s3">'gender'</span><span class="s0">,</span>
<a name="l478"><span class="ln">478  </span></a>    <span class="s3">'part_time_job'</span><span class="s0">,</span>
<a name="l479"><span class="ln">479  </span></a>    <span class="s3">'diet_quality'</span><span class="s0">,</span>
<a name="l480"><span class="ln">480  </span></a>    <span class="s3">'parental_education_level'</span><span class="s0">,</span>
<a name="l481"><span class="ln">481  </span></a>    <span class="s3">'internet_quality'</span><span class="s0">,</span>
<a name="l482"><span class="ln">482  </span></a>    <span class="s3">'extracurricular_participation'</span>
<a name="l483"><span class="ln">483  </span></a><span class="s0">]</span>
<a name="l484"><span class="ln">484  </span></a>
<a name="l485"><span class="ln">485  </span></a><span class="s2"># Schritt 5: Subplots vorbereiten (2 Zeilen, 3 Spalten)</span>
<a name="l486"><span class="ln">486  </span></a><span class="s0">fig, axes = plt.subplots(nrows=</span><span class="s4">2</span><span class="s0">, ncols=</span><span class="s4">3</span><span class="s0">)</span>
<a name="l487"><span class="ln">487  </span></a><span class="s0">axes = axes.flatten()  </span><span class="s2"># Achsen in flache Liste umwandeln</span>
<a name="l488"><span class="ln">488  </span></a>
<a name="l489"><span class="ln">489  </span></a><span class="s2"># Schritt 6: Iteration über alle Merkmale mit Countplots</span>
<a name="l490"><span class="ln">490  </span></a><span class="s1">for </span><span class="s0">i, feature </span><span class="s1">in </span><span class="s0">enumerate(categorical_features):</span>
<a name="l491"><span class="ln">491  </span></a>    <span class="s0">sns.countplot(</span>
<a name="l492"><span class="ln">492  </span></a>        <span class="s0">data=df,</span>
<a name="l493"><span class="ln">493  </span></a>        <span class="s0">x=feature,</span>
<a name="l494"><span class="ln">494  </span></a>        <span class="s0">hue=feature,         </span><span class="s2"># Farben nach Kategorie aufteilen</span>
<a name="l495"><span class="ln">495  </span></a>        <span class="s0">legend=</span><span class="s1">False</span><span class="s0">,        </span><span class="s2"># Legende ausschalten, da redundant zur x-Achse</span>
<a name="l496"><span class="ln">496  </span></a>        <span class="s0">ax=axes[i],</span>
<a name="l497"><span class="ln">497  </span></a>        <span class="s0">palette=</span><span class="s3">&quot;Set2&quot;       </span><span class="s2"># Farbpalette bleibt erhalten</span>
<a name="l498"><span class="ln">498  </span></a>    <span class="s0">)</span>
<a name="l499"><span class="ln">499  </span></a>    <span class="s0">axes[i].set_title(</span><span class="s3">f&quot;Verteilung von </span><span class="s5">{</span><span class="s0">feature</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s0">, fontsize=</span><span class="s4">12</span><span class="s0">)</span>
<a name="l500"><span class="ln">500  </span></a>    <span class="s0">axes[i].set_xlabel(</span><span class="s3">&quot;&quot;</span><span class="s0">)  </span><span class="s2"># Kein Label unter der x-Achse</span>
<a name="l501"><span class="ln">501  </span></a>    <span class="s0">axes[i].set_ylabel(</span><span class="s3">&quot;Anzahl&quot;</span><span class="s0">)</span>
<a name="l502"><span class="ln">502  </span></a>    <span class="s0">axes[i].tick_params(axis=</span><span class="s3">'x'</span><span class="s0">, rotation=</span><span class="s4">20</span><span class="s0">)</span>
<a name="l503"><span class="ln">503  </span></a>
<a name="l504"><span class="ln">504  </span></a><span class="s2"># Schritt 7: Layout und Gesamttitel anpassen</span>
<a name="l505"><span class="ln">505  </span></a><span class="s0">plt.suptitle(</span><span class="s3">&quot;Verteilungen der kategorialen Merkmale&quot;</span><span class="s0">, fontsize=</span><span class="s4">15</span><span class="s0">)</span>
<a name="l506"><span class="ln">506  </span></a><span class="s0">plt.tight_layout(rect=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0.95</span><span class="s0">])  </span><span class="s2"># Layout für saubere Darstellung</span>
<a name="l507"><span class="ln">507  </span></a><span class="s0">plt.show()</span>
<a name="l508"><span class="ln">508  </span></a><hr class="ls0"><a name="l509"><span class="ln">509  </span></a><span class="s0">#%% md 
<a name="l510"><span class="ln">510  </span></a>## Analyse der kategorialen Merkmale 
<a name="l511"><span class="ln">511  </span></a> 
<a name="l512"><span class="ln">512  </span></a>Die obige Darstellung zeigt die Häufigkeitsverteilungen aller **kategorialen Merkmale** im Datensatz. Ziel dieser Visualisierung ist es, einen Überblick darüber zu gewinnen, wie stark einzelne Kategorien vertreten sind, ob es dominante Ausprägungen gibt und ob die Verteilungen eventuell zu Verzerrungen in der Modellbildung führen könnten. Nachfolgend werden die einzelnen Merkmale interpretiert: 
<a name="l513"><span class="ln">513  </span></a> 
<a name="l514"><span class="ln">514  </span></a>--- 
<a name="l515"><span class="ln">515  </span></a> 
<a name="l516"><span class="ln">516  </span></a>### Geschlecht (`gender`) 
<a name="l517"><span class="ln">517  </span></a>Die Variable `gender` ist in drei Kategorien unterteilt: *Male*, *Female* und *Other*. Die Verteilung ist nahezu ausgeglichen zwischen *Male* und *Female*, was aus statistischer Sicht vorteilhaft ist. Auffällig ist jedoch der geringe Anteil der Kategorie *Other*, was eine sinnvolle Berücksichtigung dieses Merkmals im Modell erschweren könnte. 
<a name="l518"><span class="ln">518  </span></a> 
<a name="l519"><span class="ln">519  </span></a>--- 
<a name="l520"><span class="ln">520  </span></a> 
<a name="l521"><span class="ln">521  </span></a>### Nebenjob (`part_time_job`) 
<a name="l522"><span class="ln">522  </span></a>Ein Großteil der Studierenden gibt an, **keinen Nebenjob** zu haben. Lediglich ca. ein Fünftel arbeitet neben dem Studium. Diese ungleiche Verteilung könnte im Modell zu einer Verzerrung führen, insbesondere wenn sich Nebenjobs stark auf andere Merkmale wie Lernzeit oder psychische Gesundheit auswirken. 
<a name="l523"><span class="ln">523  </span></a> 
<a name="l524"><span class="ln">524  </span></a>--- 
<a name="l525"><span class="ln">525  </span></a> 
<a name="l526"><span class="ln">526  </span></a>### Ernährung (`diet_quality`) 
<a name="l527"><span class="ln">527  </span></a>Die meisten Angaben fallen auf die Kategorien *Fair* und *Good*, während *Poor* seltener vorkommt. Die gleichmäßige Verteilung zwischen *Fair* und *Good* ermöglicht einen differenzierten Vergleich, allerdings ist die Kategorie *Poor* möglicherweise unterrepräsentiert. 
<a name="l528"><span class="ln">528  </span></a> 
<a name="l529"><span class="ln">529  </span></a>--- 
<a name="l530"><span class="ln">530  </span></a> 
<a name="l531"><span class="ln">531  </span></a>### Bildungsstand der Eltern (`parental_education_level`) 
<a name="l532"><span class="ln">532  </span></a>Hier fällt auf, dass *High School* als höchster Bildungsstand dominiert, gefolgt von *Bachelor*. *Master*-Abschlüsse sind vergleichsweise selten vertreten. Da der elterliche Bildungshintergrund als sozioökonomischer Einflussfaktor relevant sein kann, ist diese Verteilung für spätere Interpretationen wichtig. 
<a name="l533"><span class="ln">533  </span></a> 
<a name="l534"><span class="ln">534  </span></a>--- 
<a name="l535"><span class="ln">535  </span></a> 
<a name="l536"><span class="ln">536  </span></a>### Internetqualität (`internet_quality`) 
<a name="l537"><span class="ln">537  </span></a>Die meisten Studierenden berichten von einer *guten* oder *durchschnittlichen* Internetqualität. Die Kategorie *Poor* ist deutlich schwächer vertreten. Diese Unausgeglichenheit könnte darauf hinweisen, dass schlechter Internetzugang seltener ein Problem ist, was wiederum Einfluss auf Online-Lernzeiten oder Mediennutzung haben kann. 
<a name="l538"><span class="ln">538  </span></a> 
<a name="l539"><span class="ln">539  </span></a>--- 
<a name="l540"><span class="ln">540  </span></a> 
<a name="l541"><span class="ln">541  </span></a>### Außercurriculare Aktivitäten (`extracurricular_participation`) 
<a name="l542"><span class="ln">542  </span></a>Der Großteil der Studierenden nimmt **nicht** an außercurricularen Aktivitäten teil. Dies könnte auf einen eingeschränkten Zeitrahmen, fehlende Angebote oder geringes Interesse hindeuten. Auch hier ist die Verteilung sehr einseitig, was bei späteren Analysen mit Vorsicht zu behandeln ist. 
<a name="l543"><span class="ln">543  </span></a> 
<a name="l544"><span class="ln">544  </span></a>--- 
<a name="l545"><span class="ln">545  </span></a> 
<a name="l546"><span class="ln">546  </span></a>### Fazit zur Verteilung 
<a name="l547"><span class="ln">547  </span></a>Die meisten kategorialen Merkmale zeigen **ungleiche Verteilungen**, was in der Modellierung berücksichtigt werden muss – z.B. durch gewichtete Klassen oder geeignete Kodierungsverfahren. Merkmale mit stark unterrepräsentierten Kategorien sollten besonders sorgfältig behandelt werden, da sie das Modell verzerren oder zu Overfitting führen können. 
<a name="l548"><span class="ln">548  </span></a> 
<a name="l549"><span class="ln">549  </span></a>Die Balkendiagramme sind bewusst gewählt worden, um Häufigkeiten klar und vergleichbar darzustellen. Sie eignen sich besonders für kategoriale Variablen, da sie visuell deutlich machen, wie stark die einzelnen Ausprägungen vertreten sind. Zusammen mit den numerischen Verteilungen ergibt sich ein vollständiges Bild der Datenstruktur. 
<a name="l550"><span class="ln">550  </span></a> <hr class="ls0"><a name="l551"><span class="ln">551  </span></a>#%% md 
<a name="l552"><span class="ln">552  </span></a>### Kreuzverteilungen zwischen kategorialen Merkmalen 
<a name="l553"><span class="ln">553  </span></a>In diesem Abschnitt analysieren wir, wie die kategorialen Merkmale des Datensatzes miteinander zusammenhängen. Da klassische Korrelationsmaße wie der Pearson-Koeffizient für kategoriale Daten nicht geeignet sind, nutzen wir stattdessen Kreuztabellen. Diese zeigen, wie häufig Merkmalsausprägungen gemeinsam auftreten. 
<a name="l554"><span class="ln">554  </span></a> 
<a name="l555"><span class="ln">555  </span></a>Zur besseren Lesbarkeit werden die Werte zeilenweise normalisiert und als Heatmap dargestellt. So lassen sich Muster im Antwortverhalten und potenzielle Abhängigkeiten gut erkennen. <hr class="ls0"><a name="l556"><span class="ln">556  </span></a>#%% 
<a name="l557"><span class="ln">557  </span></a></span><span class="s2"># CSV-Datei laden (Pfad ggf. anpassen)</span>
<a name="l558"><span class="ln">558  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l559"><span class="ln">559  </span></a>
<a name="l560"><span class="ln">560  </span></a><span class="s2"># Relevante kategoriale Merkmale definieren</span>
<a name="l561"><span class="ln">561  </span></a><span class="s0">categorical_features = [</span>
<a name="l562"><span class="ln">562  </span></a>    <span class="s3">'gender'</span><span class="s0">,</span>
<a name="l563"><span class="ln">563  </span></a>    <span class="s3">'part_time_job'</span><span class="s0">,</span>
<a name="l564"><span class="ln">564  </span></a>    <span class="s3">'diet_quality'</span><span class="s0">,</span>
<a name="l565"><span class="ln">565  </span></a>    <span class="s3">'parental_education_level'</span><span class="s0">,</span>
<a name="l566"><span class="ln">566  </span></a>    <span class="s3">'internet_quality'</span><span class="s0">,</span>
<a name="l567"><span class="ln">567  </span></a>    <span class="s3">'extracurricular_participation'</span>
<a name="l568"><span class="ln">568  </span></a><span class="s0">]</span>
<a name="l569"><span class="ln">569  </span></a>
<a name="l570"><span class="ln">570  </span></a>
<a name="l571"><span class="ln">571  </span></a><span class="s2"># Funktion zur Berechnung von Cramér's V</span>
<a name="l572"><span class="ln">572  </span></a><span class="s1">def </span><span class="s0">cramers_v(x, y):</span>
<a name="l573"><span class="ln">573  </span></a>    <span class="s0">confusion_matrix = pd.crosstab(x, y)</span>
<a name="l574"><span class="ln">574  </span></a>    <span class="s0">chi2 = chi2_contingency(confusion_matrix)[</span><span class="s4">0</span><span class="s0">]</span>
<a name="l575"><span class="ln">575  </span></a>    <span class="s0">n = confusion_matrix.sum().sum()</span>
<a name="l576"><span class="ln">576  </span></a>    <span class="s0">phi2 = chi2 / n</span>
<a name="l577"><span class="ln">577  </span></a>    <span class="s0">r, k = confusion_matrix.shape</span>
<a name="l578"><span class="ln">578  </span></a>    <span class="s1">return </span><span class="s0">np.sqrt(phi2 / min(k - </span><span class="s4">1</span><span class="s0">, r - </span><span class="s4">1</span><span class="s0">))</span>
<a name="l579"><span class="ln">579  </span></a>
<a name="l580"><span class="ln">580  </span></a>
<a name="l581"><span class="ln">581  </span></a><span class="s2"># Matrix vorbereiten und Werte füllen</span>
<a name="l582"><span class="ln">582  </span></a><span class="s0">cramers_matrix = pd.DataFrame(index=categorical_features, columns=categorical_features)</span>
<a name="l583"><span class="ln">583  </span></a>
<a name="l584"><span class="ln">584  </span></a><span class="s1">for </span><span class="s0">col1, col2 </span><span class="s1">in </span><span class="s0">itertools.combinations(categorical_features, </span><span class="s4">2</span><span class="s0">):</span>
<a name="l585"><span class="ln">585  </span></a>    <span class="s0">val = cramers_v(df[col1], df[col2])</span>
<a name="l586"><span class="ln">586  </span></a>    <span class="s0">cramers_matrix.loc[col1, col2] = val</span>
<a name="l587"><span class="ln">587  </span></a>    <span class="s0">cramers_matrix.loc[col2, col1] = val</span>
<a name="l588"><span class="ln">588  </span></a>
<a name="l589"><span class="ln">589  </span></a><span class="s2"># Diagonale mit 1.0 setzen</span>
<a name="l590"><span class="ln">590  </span></a><span class="s0">np.fill_diagonal(cramers_matrix.values.astype(float), </span><span class="s4">1.0</span><span class="s0">)</span>
<a name="l591"><span class="ln">591  </span></a>
<a name="l592"><span class="ln">592  </span></a><span class="s2"># Umwandlung in Float</span>
<a name="l593"><span class="ln">593  </span></a><span class="s0">cramers_matrix = cramers_matrix.astype(float)</span>
<a name="l594"><span class="ln">594  </span></a>
<a name="l595"><span class="ln">595  </span></a><span class="s2"># Stil und Farbanpassung wie bei der numerischen Heatmap</span>
<a name="l596"><span class="ln">596  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">8</span><span class="s0">))</span>
<a name="l597"><span class="ln">597  </span></a><span class="s0">sns.set(style=</span><span class="s3">&quot;white&quot;</span><span class="s0">)</span>
<a name="l598"><span class="ln">598  </span></a><span class="s0">heatmap = sns.heatmap(</span>
<a name="l599"><span class="ln">599  </span></a>    <span class="s0">cramers_matrix,</span>
<a name="l600"><span class="ln">600  </span></a>    <span class="s0">annot=</span><span class="s1">True</span><span class="s0">,</span>
<a name="l601"><span class="ln">601  </span></a>    <span class="s0">fmt=</span><span class="s3">&quot;.2f&quot;</span><span class="s0">,</span>
<a name="l602"><span class="ln">602  </span></a>    <span class="s0">cmap=</span><span class="s3">&quot;coolwarm&quot;</span><span class="s0">,  </span><span class="s2"># gleiche Farbskala wie bei numerischer Heatmap</span>
<a name="l603"><span class="ln">603  </span></a>    <span class="s0">vmin=</span><span class="s4">0</span><span class="s0">,</span>
<a name="l604"><span class="ln">604  </span></a>    <span class="s0">vmax=</span><span class="s4">1</span><span class="s0">,</span>
<a name="l605"><span class="ln">605  </span></a>    <span class="s0">linewidths=</span><span class="s4">0.5</span><span class="s0">,</span>
<a name="l606"><span class="ln">606  </span></a>    <span class="s0">square=</span><span class="s1">True</span><span class="s0">,</span>
<a name="l607"><span class="ln">607  </span></a>    <span class="s0">cbar_kws={</span><span class="s3">'label'</span><span class="s0">: </span><span class="s3">&quot;Cramér's V&quot;</span><span class="s0">}</span>
<a name="l608"><span class="ln">608  </span></a><span class="s0">)</span>
<a name="l609"><span class="ln">609  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Korrelation zwischen kategorialen Merkmalen (Cramér's V)&quot;</span><span class="s0">, fontsize=</span><span class="s4">14</span><span class="s0">)</span>
<a name="l610"><span class="ln">610  </span></a><span class="s0">plt.xticks(rotation=</span><span class="s4">45</span><span class="s0">)</span>
<a name="l611"><span class="ln">611  </span></a><span class="s0">plt.tight_layout()</span>
<a name="l612"><span class="ln">612  </span></a><span class="s0">plt.show()</span>
<a name="l613"><span class="ln">613  </span></a><hr class="ls0"><a name="l614"><span class="ln">614  </span></a><span class="s0">#%% md 
<a name="l615"><span class="ln">615  </span></a>--- 
<a name="l616"><span class="ln">616  </span></a> 
<a name="l617"><span class="ln">617  </span></a>## Korrelation zwischen kategorialen Merkmalen 
<a name="l618"><span class="ln">618  </span></a> 
<a name="l619"><span class="ln">619  </span></a>Im Gegensatz zu numerischen Merkmalen lassen sich kategoriale Merkmale nicht mit der klassischen Pearson-Korrelation vergleichen, da sie keine kontinuierlichen Werte besitzen. Stattdessen wurde in diesem Abschnitt der **Cramér’s V** Koeffizient berechnet, um die Stärke des Zusammenhangs zwischen zwei kategorialen Variablen zu bestimmen. 
<a name="l620"><span class="ln">620  </span></a> 
<a name="l621"><span class="ln">621  </span></a>**Was ist Cramér’s V?** 
<a name="l622"><span class="ln">622  </span></a> 
<a name="l623"><span class="ln">623  </span></a>Cramér’s V ist ein Maß für die Assoziation zwischen zwei kategorialen Variablen. Er basiert auf dem Chi-Quadrat-Test und liefert Werte zwischen **0 (kein Zusammenhang)** und **1 (perfekte Assoziation)**. Dieses Maß ist symmetrisch und eignet sich besonders für nominal skalierte Daten. 
<a name="l624"><span class="ln">624  </span></a> 
<a name="l625"><span class="ln">625  </span></a>### Vorgehensweise: 
<a name="l626"><span class="ln">626  </span></a> 
<a name="l627"><span class="ln">627  </span></a>- Die relevanten kategorialen Merkmale wurden zunächst identifiziert (z.B. `gender`, `diet_quality`, `internet_quality`). 
<a name="l628"><span class="ln">628  </span></a>- Für jedes Merkmals-Paar wurde ein Cramér’s V-Wert berechnet. 
<a name="l629"><span class="ln">629  </span></a>- Die Ergebnisse wurden in einer symmetrischen Matrix zusammengeführt und mithilfe einer **farbcodierten Heatmap** visualisiert analog zur Darstellung der numerischen Korrelationen. 
<a name="l630"><span class="ln">630  </span></a> 
<a name="l631"><span class="ln">631  </span></a>### Interpretation der Ergebnisse: 
<a name="l632"><span class="ln">632  </span></a> 
<a name="l633"><span class="ln">633  </span></a>Die Analyse zeigt, dass **zwischen den kategorialen Merkmalen keine starke Korrelation** vorliegt. Alle berechneten Werte für Cramér’s V liegen im Bereich zwischen **0.01 und 0.07**, was auf **sehr geringe Zusammenhänge** hindeutet. Die auffälligsten (wenn auch sehr schwachen) Assoziationen bestehen zwischen: 
<a name="l634"><span class="ln">634  </span></a> 
<a name="l635"><span class="ln">635  </span></a>- `internet_quality` und `part_time_job` (Cramér’s V ≈ 0.07) 
<a name="l636"><span class="ln">636  </span></a>- `diet_quality` und `extracurricular_participation` (Cramér’s V ≈ 0.07) 
<a name="l637"><span class="ln">637  </span></a>- `gender` und `internet_quality` (Cramér’s V ≈ 0.06) 
<a name="l638"><span class="ln">638  </span></a> 
<a name="l639"><span class="ln">639  </span></a>Diese Werte deuten darauf hin, dass in den simulierten Daten nur sehr **lockere Muster** zwischen diesen Merkmalsausprägungen bestehen. Eine inhaltlich belastbare Interpretation ist – wie bereits in der Einleitung zum Datensatz angemerkt – aufgrund der synthetischen Natur der Daten jedoch methodisch nicht möglich. 
<a name="l640"><span class="ln">640  </span></a> 
<a name="l641"><span class="ln">641  </span></a>### Einordnung für die weitere Analyse: 
<a name="l642"><span class="ln">642  </span></a> 
<a name="l643"><span class="ln">643  </span></a>Die geringen Cramér’s V-Werte deuten darauf hin, dass es **keine dominante gegenseitige Beeinflussung der kategorialen Merkmale untereinander** gibt. Für spätere erklärbare Modelle (z.B. mit LIME oder SHAP) bedeutet das, dass **keine offensichtlichen redundanten kategorialen Features** vorliegen, die vorab entfernt werden müssten. 
<a name="l644"><span class="ln">644  </span></a> 
<a name="l645"><span class="ln">645  </span></a>--- 
<a name="l646"><span class="ln">646  </span></a> <hr class="ls0"><a name="l647"><span class="ln">647  </span></a>#%% md 
<a name="l648"><span class="ln">648  </span></a>## Zusammenhang zwischen kategorialen und numerischen Merkmalen 
<a name="l649"><span class="ln">649  </span></a>Zur Analyse, ob kategoriale Merkmale (wie Geschlecht oder Internetqualität) mit numerischen Variablen (wie `exam_score`, `study_hours_per_day` usw.) in Verbindung stehen, wird die Einweg-ANOVA (Analysis of Variance) verwendet. Die ANOVA prüft, ob sich die Mittelwerte der numerischen Merkmale signifikant zwischen den Gruppen eines kategorialen Merkmals unterscheiden. 
<a name="l650"><span class="ln">650  </span></a> 
<a name="l651"><span class="ln">651  </span></a>Ein hoher F-Wert deutet auf einen stärkeren Unterschied zwischen den Gruppen hin, was auf einen möglichen Einfluss hindeuten kann. Die ANOVA gibt keine Kausalität an, ist aber ein nützliches Werkzeug zur Einschätzung der Stärke des Zusammenhangs. 
<a name="l652"><span class="ln">652  </span></a> 
<a name="l653"><span class="ln">653  </span></a>--- <hr class="ls0"><a name="l654"><span class="ln">654  </span></a>#%% 
<a name="l655"><span class="ln">655  </span></a></span><span class="s2"># Schritt 2: Datensatz laden</span>
<a name="l656"><span class="ln">656  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l657"><span class="ln">657  </span></a>
<a name="l658"><span class="ln">658  </span></a><span class="s2"># Schritt 3: Definition der Merkmalstypen</span>
<a name="l659"><span class="ln">659  </span></a><span class="s2"># Kategoriale Merkmale: Diese Merkmale definieren Gruppen</span>
<a name="l660"><span class="ln">660  </span></a><span class="s0">categorical_features = [</span>
<a name="l661"><span class="ln">661  </span></a>    <span class="s3">'gender'</span><span class="s0">,</span>
<a name="l662"><span class="ln">662  </span></a>    <span class="s3">'part_time_job'</span><span class="s0">,</span>
<a name="l663"><span class="ln">663  </span></a>    <span class="s3">'diet_quality'</span><span class="s0">,</span>
<a name="l664"><span class="ln">664  </span></a>    <span class="s3">'parental_education_level'</span><span class="s0">,</span>
<a name="l665"><span class="ln">665  </span></a>    <span class="s3">'internet_quality'</span><span class="s0">,</span>
<a name="l666"><span class="ln">666  </span></a>    <span class="s3">'extracurricular_participation'</span>
<a name="l667"><span class="ln">667  </span></a><span class="s0">]</span>
<a name="l668"><span class="ln">668  </span></a>
<a name="l669"><span class="ln">669  </span></a><span class="s2"># Numerische Merkmale: Deren Mittelwerte werden in den Gruppen verglichen</span>
<a name="l670"><span class="ln">670  </span></a><span class="s0">numerical_features = [</span>
<a name="l671"><span class="ln">671  </span></a>    <span class="s3">'age'</span><span class="s0">,</span>
<a name="l672"><span class="ln">672  </span></a>    <span class="s3">'study_hours_per_day'</span><span class="s0">,</span>
<a name="l673"><span class="ln">673  </span></a>    <span class="s3">'sleep_hours'</span><span class="s0">,</span>
<a name="l674"><span class="ln">674  </span></a>    <span class="s3">'social_media_hours'</span><span class="s0">,</span>
<a name="l675"><span class="ln">675  </span></a>    <span class="s3">'netflix_hours'</span><span class="s0">,</span>
<a name="l676"><span class="ln">676  </span></a>    <span class="s3">'attendance_percentage'</span><span class="s0">,</span>
<a name="l677"><span class="ln">677  </span></a>    <span class="s3">'exercise_frequency'</span><span class="s0">,</span>
<a name="l678"><span class="ln">678  </span></a>    <span class="s3">'mental_health_rating'</span><span class="s0">,</span>
<a name="l679"><span class="ln">679  </span></a>    <span class="s3">'exam_score'</span>
<a name="l680"><span class="ln">680  </span></a><span class="s0">]</span>
<a name="l681"><span class="ln">681  </span></a>
<a name="l682"><span class="ln">682  </span></a><span class="s2"># Schritt 4: Vorbereitung der Ergebnisstruktur</span>
<a name="l683"><span class="ln">683  </span></a><span class="s2"># Wir erstellen eine leere Matrix, in die später die ANOVA-F-Werte eingetragen werden</span>
<a name="l684"><span class="ln">684  </span></a><span class="s0">anova_matrix = pd.DataFrame(index=categorical_features, columns=numerical_features)</span>
<a name="l685"><span class="ln">685  </span></a>
<a name="l686"><span class="ln">686  </span></a><span class="s2"># Schritt 5: Berechnung der F-Werte mittels ANOVA</span>
<a name="l687"><span class="ln">687  </span></a><span class="s2"># Für jede Kombination von kategorialem und numerischem Merkmal:</span>
<a name="l688"><span class="ln">688  </span></a><span class="s1">for </span><span class="s0">cat </span><span class="s1">in </span><span class="s0">categorical_features:</span>
<a name="l689"><span class="ln">689  </span></a>    <span class="s1">for </span><span class="s0">num </span><span class="s1">in </span><span class="s0">numerical_features:</span>
<a name="l690"><span class="ln">690  </span></a>        <span class="s1">try</span><span class="s0">:</span>
<a name="l691"><span class="ln">691  </span></a>            <span class="s2"># Gruppenbildung: Numerische Werte nach Kategorien gruppieren</span>
<a name="l692"><span class="ln">692  </span></a>            <span class="s0">groups = [group[num].dropna().values </span><span class="s1">for </span><span class="s0">_, group </span><span class="s1">in </span><span class="s0">df.groupby(cat)]</span>
<a name="l693"><span class="ln">693  </span></a>
<a name="l694"><span class="ln">694  </span></a>            <span class="s2"># ANOVA-Test: Gibt F-Wert und p-Wert zurück</span>
<a name="l695"><span class="ln">695  </span></a>            <span class="s0">f_stat, p_val = f_oneway(*groups)</span>
<a name="l696"><span class="ln">696  </span></a>
<a name="l697"><span class="ln">697  </span></a>            <span class="s2"># Ergebnis eintragen (auf zwei Nachkommastellen gerundet)</span>
<a name="l698"><span class="ln">698  </span></a>            <span class="s0">anova_matrix.loc[cat, num] = round(f_stat, </span><span class="s4">2</span><span class="s0">)</span>
<a name="l699"><span class="ln">699  </span></a>        <span class="s1">except</span><span class="s0">:</span>
<a name="l700"><span class="ln">700  </span></a>            <span class="s2"># Falls Fehler (z. B. zu kleine Gruppen), trage NaN ein</span>
<a name="l701"><span class="ln">701  </span></a>            <span class="s0">anova_matrix.loc[cat, num] = np.nan</span>
<a name="l702"><span class="ln">702  </span></a>
<a name="l703"><span class="ln">703  </span></a><span class="s2"># Schritt 6: Visualisierung der Ergebnisse als Heatmap</span>
<a name="l704"><span class="ln">704  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">12</span><span class="s0">, </span><span class="s4">6</span><span class="s0">))</span>
<a name="l705"><span class="ln">705  </span></a>
<a name="l706"><span class="ln">706  </span></a><span class="s2"># Die Heatmap zeigt F-Werte (Stärke des Gruppeneffekts)</span>
<a name="l707"><span class="ln">707  </span></a><span class="s0">sns.heatmap(</span>
<a name="l708"><span class="ln">708  </span></a>    <span class="s0">anova_matrix.astype(float),       </span><span class="s2"># sicherstellen, dass alle Werte numerisch sind</span>
<a name="l709"><span class="ln">709  </span></a>    <span class="s0">annot=</span><span class="s1">True</span><span class="s0">,                       </span><span class="s2"># Werte in Zellen anzeigen</span>
<a name="l710"><span class="ln">710  </span></a>    <span class="s0">cmap=</span><span class="s3">&quot;coolwarm&quot;</span><span class="s0">,                  </span><span class="s2"># Farbschema: Blau = niedrig, Rot = hoch</span>
<a name="l711"><span class="ln">711  </span></a>    <span class="s0">fmt=</span><span class="s3">&quot;.2f&quot;</span><span class="s0">,                        </span><span class="s2"># Formatierung der Zahlen mit zwei Dezimalstellen</span>
<a name="l712"><span class="ln">712  </span></a>    <span class="s0">linewidths=</span><span class="s4">0.5</span><span class="s0">,                   </span><span class="s2"># Gitterlinien zwischen Feldern</span>
<a name="l713"><span class="ln">713  </span></a>    <span class="s0">cbar_kws={</span><span class="s3">'label'</span><span class="s0">: </span><span class="s3">'F-Wert'</span><span class="s0">}      </span><span class="s2"># Farblegende beschriften</span>
<a name="l714"><span class="ln">714  </span></a><span class="s0">)</span>
<a name="l715"><span class="ln">715  </span></a>
<a name="l716"><span class="ln">716  </span></a><span class="s2"># Achsentitel und Layout</span>
<a name="l717"><span class="ln">717  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Varianzaufklärung zwischen kategorialen und numerischen Merkmalen (ANOVA F-Werte)&quot;</span><span class="s0">)</span>
<a name="l718"><span class="ln">718  </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Numerische Merkmale&quot;</span><span class="s0">)</span>
<a name="l719"><span class="ln">719  </span></a><span class="s0">plt.ylabel(</span><span class="s3">&quot;Kategoriale Merkmale&quot;</span><span class="s0">)</span>
<a name="l720"><span class="ln">720  </span></a><span class="s0">plt.xticks(rotation=</span><span class="s4">45</span><span class="s0">)</span>
<a name="l721"><span class="ln">721  </span></a><span class="s0">plt.tight_layout()</span>
<a name="l722"><span class="ln">722  </span></a><span class="s0">plt.show()</span><hr class="ls0"><a name="l723"><span class="ln">723  </span></a><span class="s0">#%% md 
<a name="l724"><span class="ln">724  </span></a>--- 
<a name="l725"><span class="ln">725  </span></a> 
<a name="l726"><span class="ln">726  </span></a>### Interpretation der Varianzaufklärung: Kategoriale vs. numerische Merkmale 
<a name="l727"><span class="ln">727  </span></a> 
<a name="l728"><span class="ln">728  </span></a>Die obige Heatmap zeigt die F-Werte einer Einweg-ANOVA, berechnet für alle Kombinationen aus kategorialen und numerischen Merkmalen. Ziel dieser Analyse ist es zu untersuchen, ob sich die Ausprägungen eines numerischen Merkmals systematisch zwischen den Gruppen eines kategorialen Merkmals unterscheiden. 
<a name="l729"><span class="ln">729  </span></a> 
<a name="l730"><span class="ln">730  </span></a>Die F-Werte geben dabei einen Hinweis auf die Stärke des Effekts: 
<a name="l731"><span class="ln">731  </span></a>- **Höhere Werte** deuten auf **größere Unterschiede der Mittelwerte** zwischen den Gruppen hin. 
<a name="l732"><span class="ln">732  </span></a>- **Niedrige Werte** (&lt; 1) bedeuten, dass **kaum Unterschiede** zwischen den Gruppen festgestellt wurden. 
<a name="l733"><span class="ln">733  </span></a>- Diese Analyse ersetzt keine Signifikanzprüfung, liefert aber eine erste Orientierung für interessante Kombinationen. 
<a name="l734"><span class="ln">734  </span></a> 
<a name="l735"><span class="ln">735  </span></a>#### Beobachtungen aus der Matrix 
<a name="l736"><span class="ln">736  </span></a> 
<a name="l737"><span class="ln">737  </span></a>- `parental_education_level` zeigt mit einem **F-Wert von 5.10** in Bezug auf `mental_health_rating` die **stärkste Varianzaufklärung**. Dies könnte bedeuten, dass das psychische Wohlbefinden der Studierenden je nach Bildungsgrad der Eltern leicht unterschiedlich ausfällt. 
<a name="l738"><span class="ln">738  </span></a>- Auch `diet_quality` scheint mit `study_hours_per_day` (2.70) und `mental_health_rating` (2.60) eine gewisse Beziehung aufzuweisen. Dies ist plausibel, da Ernährung oft mit Energielevel und Konzentrationsfähigkeit zusammenhängt. 
<a name="l739"><span class="ln">739  </span></a>- Die übrigen Merkmale weisen größtenteils **niedrige bis sehr geringe F-Werte** auf. Besonders bei `extracurricular_participation` zeigen sich durchweg sehr geringe Unterschiede was darauf hindeutet, dass diese Variable im aktuellen Datensatz kaum Erklärungswert für numerische Merkmale liefert. 
<a name="l740"><span class="ln">740  </span></a> 
<a name="l741"><span class="ln">741  </span></a>#### Methodische Einordnung 
<a name="l742"><span class="ln">742  </span></a> 
<a name="l743"><span class="ln">743  </span></a>Die ANOVA eignet sich gut, um erste Anhaltspunkte für die Relevanz kategorialer Merkmale zu gewinnen. Die F-Werte lassen sich jedoch **nicht kausal interpretieren**. Außerdem wurden hier keine post-hoc-Tests oder p-Werte berechnet, weshalb die Ergebnisse **als explorativ** zu verstehen sind. 
<a name="l744"><span class="ln">744  </span></a> 
<a name="l745"><span class="ln">745  </span></a>Trotz dieser Einschränkungen liefert diese Matrix wertvolle Hinweise darauf, **welche Merkmale im späteren Modell berücksichtigt** oder bei der Merkmalsskalierung und gewichtung besonders beachtet werden könnten. 
<a name="l746"><span class="ln">746  </span></a> <hr class="ls0"><a name="l747"><span class="ln">747  </span></a>#%% md 
<a name="l748"><span class="ln">748  </span></a>--- 
<a name="l749"><span class="ln">749  </span></a> 
<a name="l750"><span class="ln">750  </span></a>## Fazit der explorativen Datenanalyse 
<a name="l751"><span class="ln">751  </span></a> 
<a name="l752"><span class="ln">752  </span></a>Die explorative Analyse des Datensatzes lieferte zentrale Erkenntnisse für die spätere Modellierung: 
<a name="l753"><span class="ln">753  </span></a> 
<a name="l754"><span class="ln">754  </span></a>- **Numerische Merkmale** zeigen insgesamt realistische Verteilungen. Besonders auffällig sind: 
<a name="l755"><span class="ln">755  </span></a>  - Konzentration der Lernzeit auf niedrige Werte trotz breiter Streuung bei der Prüfungsleistung. 
<a name="l756"><span class="ln">756  </span></a>  - Ein Großteil der Studierenden schläft nur 6–7 Stunden. Ein Bereich unterhalb medizinischer Empfehlungen. 
<a name="l757"><span class="ln">757  </span></a>  - Netflix- und Social-Media-Nutzung variieren stark, mit vielen Nullangaben. 
<a name="l758"><span class="ln">758  </span></a> 
<a name="l759"><span class="ln">759  </span></a>- **Kategoriale Merkmale** sind vollständig und sinnvoll verteilt, aber größtenteils unabhängig voneinander. Es gab keine stark überrepräsentierten Klassen, jedoch war z.B. „kein Nebenjob“ deutlich häufiger als „mit Nebenjob“. 
<a name="l760"><span class="ln">760  </span></a> 
<a name="l761"><span class="ln">761  </span></a>- **Korrelationen zwischen numerischen Variablen** zeigten: 
<a name="l762"><span class="ln">762  </span></a>  - Eine moderate positive Beziehung zwischen Lernzeit und Prüfungsleistung. 
<a name="l763"><span class="ln">763  </span></a>  - Keine nennenswerte Korrelation zwischen Anwesenheit und Examensnote, ein eher unerwartetes Ergebnis. 
<a name="l764"><span class="ln">764  </span></a>  - Mental Health steht in leicht positivem Zusammenhang zur Leistung. 
<a name="l765"><span class="ln">765  </span></a> 
<a name="l766"><span class="ln">766  </span></a>- **Zwischen kategorialen Variablen** und **in Kombination mit numerischen Merkmalen** ergaben sich keine stark erklärenden Muster. Viele erwartete Zusammenhänge, etwa zwischen Elternbildung oder Ernährung und Prüfungsleistung, konnten nicht bestätigt werden. 
<a name="l767"><span class="ln">767  </span></a> 
<a name="l768"><span class="ln">768  </span></a>Die Analyse liefert somit erste Hinweise darauf, welche Merkmale für erklärbare Modelle später besonders relevant sein könnten, insbesondere Lernzeit, mentale Gesundheit und eventuell sportliche Aktivität. Gleichzeitig verdeutlichen die Ergebnisse, dass manche Variablen, die in der Realität stark wirken, im synthetischen Datensatz nicht zur Geltung kommen. 
<a name="l769"><span class="ln">769  </span></a> <hr class="ls0"><a name="l770"><span class="ln">770  </span></a>#%% md 
<a name="l771"><span class="ln">771  </span></a># Modelltraining: Auswahl, Erklärung und Evaluation 
<a name="l772"><span class="ln">772  </span></a> 
<a name="l773"><span class="ln">773  </span></a>--- 
<a name="l774"><span class="ln">774  </span></a> 
<a name="l775"><span class="ln">775  </span></a>## Einleitung 
<a name="l776"><span class="ln">776  </span></a> 
<a name="l777"><span class="ln">777  </span></a>Nach der explorativen Analyse der numerischen und kategorialen Merkmale folgt nun der nächste zentrale Schritt: der Aufbau eines Vorhersagemodells für die Prüfungsleistung (`exam_score`). Ziel ist es, ein möglichst verständliches und gleichzeitig leistungsfähiges Modell zu trainieren, das auf Grundlage studentischer Merkmale wie Lernzeit, Schlafdauer oder mentaler Gesundheit plausible und interpretierbare Vorhersagen liefert. 
<a name="l778"><span class="ln">778  </span></a> 
<a name="l779"><span class="ln">779  </span></a>Das Modelltraining bildet dabei das methodische Bindeglied zwischen den beobachteten Datenstrukturen und den erklärenden Verfahren (XAI), die später zum Einsatz kommen. Es geht also nicht nur darum, ein möglichst genaues Modell zu bauen, sondern eines, das auch erklärbar und nachvollziehbar bleibt. 
<a name="l780"><span class="ln">780  </span></a> 
<a name="l781"><span class="ln">781  </span></a>--- 
<a name="l782"><span class="ln">782  </span></a> 
<a name="l783"><span class="ln">783  </span></a>## Zielsetzung 
<a name="l784"><span class="ln">784  </span></a> 
<a name="l785"><span class="ln">785  </span></a>Ziel dieses Abschnitts ist es, ein geeignetes maschinelles Lernverfahren auszuwählen, zu trainieren und zu evaluieren, das den Zusammenhang zwischen den beobachteten Merkmalen und der Zielgröße `exam_score` modelliert. Dabei wird besonders auf Interpretierbarkeit geachtet, um spätere Schritte mit XAI-Methoden wie SHAP oder LIME sinnvoll umsetzen zu können. 
<a name="l786"><span class="ln">786  </span></a> 
<a name="l787"><span class="ln">787  </span></a>--- 
<a name="l788"><span class="ln">788  </span></a> 
<a name="l789"><span class="ln">789  </span></a>## Begründung für die Modellauswahl 
<a name="l790"><span class="ln">790  </span></a> 
<a name="l791"><span class="ln">791  </span></a>Für den Einstieg wird ein **lineares Regressionsmodell** verwendet. Dieses Modell ist nicht nur in der Praxis weit verbreitet, sondern bietet auch eine Reihe von Vorteilen im Hinblick auf Erklärbarkeit: 
<a name="l792"><span class="ln">792  </span></a> 
<a name="l793"><span class="ln">793  </span></a>- Es ist mathematisch transparent und gut verständlich. 
<a name="l794"><span class="ln">794  </span></a>- Die Modellkoeffizienten geben direkt an, welchen Einfluss jedes Feature auf die Zielgröße hat. 
<a name="l795"><span class="ln">795  </span></a>- Die Ergebnisse lassen sich leicht visualisieren und interpretieren. 
<a name="l796"><span class="ln">796  </span></a> 
<a name="l797"><span class="ln">797  </span></a>Die lineare Regression stellt damit eine solide Ausgangsbasis dar, bevor eventuell komplexere Modelle betrachtet werden. 
<a name="l798"><span class="ln">798  </span></a> 
<a name="l799"><span class="ln">799  </span></a>--- 
<a name="l800"><span class="ln">800  </span></a> 
<a name="l801"><span class="ln">801  </span></a>## Funktionsweise der linearen Regression 
<a name="l802"><span class="ln">802  </span></a> 
<a name="l803"><span class="ln">803  </span></a>Das Modell basiert auf der Annahme, dass die Zielgröße als gewichtete Summe der Eingabemerkmale dargestellt werden kann: 
<a name="l804"><span class="ln">804  </span></a> 
<a name="l805"><span class="ln">805  </span></a>$$ 
<a name="l806"><span class="ln">806  </span></a>\hat{y} = \beta_0 + \beta_1 \cdot x_1 + \beta_2 \cdot x_2 + \dots + \beta_n \cdot x_n 
<a name="l807"><span class="ln">807  </span></a>$$ 
<a name="l808"><span class="ln">808  </span></a> 
<a name="l809"><span class="ln">809  </span></a>Hierbei gilt: 
<a name="l810"><span class="ln">810  </span></a> 
<a name="l811"><span class="ln">811  </span></a>- $\hat{y}$ ist der vorhergesagte `exam_score`. 
<a name="l812"><span class="ln">812  </span></a>- $x_i$ sind die Eingabewerte der einzelnen Features. 
<a name="l813"><span class="ln">813  </span></a>- $\beta_i$ sind die geschätzten Regressionskoeffizienten. 
<a name="l814"><span class="ln">814  </span></a> 
<a name="l815"><span class="ln">815  </span></a>Ein positiver Koeffizient bedeutet, dass ein höherer Wert des entsprechenden Merkmals mit einem höheren `exam_score` assoziiert ist und umgekehrt. 
<a name="l816"><span class="ln">816  </span></a> 
<a name="l817"><span class="ln">817  </span></a> 
<a name="l818"><span class="ln">818  </span></a>--- 
<a name="l819"><span class="ln">819  </span></a> 
<a name="l820"><span class="ln">820  </span></a>## Nächste Schritte lineare Regression 
<a name="l821"><span class="ln">821  </span></a> 
<a name="l822"><span class="ln">822  </span></a>1. **Datenvorverarbeitung** 
<a name="l823"><span class="ln">823  </span></a>   - Kategoriale Merkmale werden mittels One-Hot-Encoding transformiert. 
<a name="l824"><span class="ln">824  </span></a>   - Die Daten werden in Trainings- und Testdaten aufgeteilt (z.B. 80/20). 
<a name="l825"><span class="ln">825  </span></a>2. **Modelltraining** 
<a name="l826"><span class="ln">826  </span></a>   - Das Modell wird mit den Trainingsdaten trainiert. 
<a name="l827"><span class="ln">827  </span></a>3. **Modellauswertung** 
<a name="l828"><span class="ln">828  </span></a>   - Die Modellgüte wird mit Metriken wie dem mittleren quadratischen Fehler (MSE), dem mittleren absoluten Fehler (MAE) und dem Bestimmtheitsmaß \( R^2 \) bewertet. 
<a name="l829"><span class="ln">829  </span></a> 
<a name="l830"><span class="ln">830  </span></a>--- 
<a name="l831"><span class="ln">831  </span></a> 
<a name="l832"><span class="ln">832  </span></a>Die Umsetzung dieser Schritte folgt im nächsten Abschnitt. 
<a name="l833"><span class="ln">833  </span></a> <hr class="ls0"><a name="l834"><span class="ln">834  </span></a>#%% 
<a name="l835"><span class="ln">835  </span></a></span><span class="s2"># Stil für Visualisierungen setzen</span>
<a name="l836"><span class="ln">836  </span></a><span class="s0">sns.set(style=</span><span class="s3">&quot;whitegrid&quot;</span><span class="s0">)</span>
<a name="l837"><span class="ln">837  </span></a><span class="s0">plt.rcParams[</span><span class="s3">&quot;figure.figsize&quot;</span><span class="s0">] = (</span><span class="s4">10</span><span class="s0">, </span><span class="s4">6</span><span class="s0">)</span>
<a name="l838"><span class="ln">838  </span></a>
<a name="l839"><span class="ln">839  </span></a><span class="s2"># Daten einlesen</span>
<a name="l840"><span class="ln">840  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l841"><span class="ln">841  </span></a>
<a name="l842"><span class="ln">842  </span></a><span class="s2"># Relevante Features und Zielvariable festlegen</span>
<a name="l843"><span class="ln">843  </span></a><span class="s0">X = df.drop(columns=[</span><span class="s3">&quot;student_id&quot;</span><span class="s0">, </span><span class="s3">&quot;exam_score&quot;</span><span class="s0">])</span>
<a name="l844"><span class="ln">844  </span></a><span class="s0">y = df[</span><span class="s3">&quot;exam_score&quot;</span><span class="s0">]</span>
<a name="l845"><span class="ln">845  </span></a>
<a name="l846"><span class="ln">846  </span></a><span class="s2"># Kategoriale Features identifizieren</span>
<a name="l847"><span class="ln">847  </span></a><span class="s0">categorical_features = X.select_dtypes(include=</span><span class="s3">&quot;object&quot;</span><span class="s0">).columns.tolist()</span>
<a name="l848"><span class="ln">848  </span></a><span class="s0">numerical_features = X.select_dtypes(include=np.number).columns.tolist()</span>
<a name="l849"><span class="ln">849  </span></a>
<a name="l850"><span class="ln">850  </span></a><span class="s2"># Preprocessing definieren</span>
<a name="l851"><span class="ln">851  </span></a><span class="s0">preprocessor = ColumnTransformer(</span>
<a name="l852"><span class="ln">852  </span></a>    <span class="s0">transformers=[</span>
<a name="l853"><span class="ln">853  </span></a>        <span class="s0">(</span><span class="s3">&quot;cat&quot;</span><span class="s0">, OneHotEncoder(drop=</span><span class="s3">&quot;first&quot;</span><span class="s0">, sparse_output=</span><span class="s1">False</span><span class="s0">), categorical_features)</span>
<a name="l854"><span class="ln">854  </span></a>    <span class="s0">],</span>
<a name="l855"><span class="ln">855  </span></a>    <span class="s0">remainder=</span><span class="s3">&quot;passthrough&quot;</span>
<a name="l856"><span class="ln">856  </span></a><span class="s0">)</span>
<a name="l857"><span class="ln">857  </span></a>
<a name="l858"><span class="ln">858  </span></a><span class="s2"># Modellpipeline definieren: Lineare Regression</span>
<a name="l859"><span class="ln">859  </span></a><span class="s0">model_pipeline_lr = Pipeline(steps=[</span>
<a name="l860"><span class="ln">860  </span></a>    <span class="s0">(</span><span class="s3">&quot;preprocessing&quot;</span><span class="s0">, preprocessor),</span>
<a name="l861"><span class="ln">861  </span></a>    <span class="s0">(</span><span class="s3">&quot;regression&quot;</span><span class="s0">, LinearRegression())</span>
<a name="l862"><span class="ln">862  </span></a><span class="s0">])</span>
<a name="l863"><span class="ln">863  </span></a>
<a name="l864"><span class="ln">864  </span></a><span class="s2"># Trainings- und Testdaten aufteilen</span>
<a name="l865"><span class="ln">865  </span></a><span class="s0">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=</span><span class="s4">0.2</span><span class="s0">, random_state=</span><span class="s4">42</span><span class="s0">)</span>
<a name="l866"><span class="ln">866  </span></a>
<a name="l867"><span class="ln">867  </span></a><span class="s2"># Modell trainieren</span>
<a name="l868"><span class="ln">868  </span></a><span class="s0">model_pipeline_lr.fit(X_train, y_train)</span>
<a name="l869"><span class="ln">869  </span></a>
<a name="l870"><span class="ln">870  </span></a><span class="s2"># Vorhersagen erzeugen</span>
<a name="l871"><span class="ln">871  </span></a><span class="s0">y_pred_lr = model_pipeline_lr.predict(X_test)</span>
<a name="l872"><span class="ln">872  </span></a>
<a name="l873"><span class="ln">873  </span></a><span class="s2"># Evaluationsmetriken berechnen</span>
<a name="l874"><span class="ln">874  </span></a><span class="s0">mse_lr = mean_squared_error(y_test, y_pred_lr)</span>
<a name="l875"><span class="ln">875  </span></a><span class="s0">r2_lr = r2_score(y_test, y_pred_lr)</span>
<a name="l876"><span class="ln">876  </span></a>
<a name="l877"><span class="ln">877  </span></a><span class="s0">print(</span><span class="s3">f&quot;[Linear Regression] Mean Squared Error: </span><span class="s5">{</span><span class="s0">mse_lr</span><span class="s5">:</span><span class="s3">.2f</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s0">)</span>
<a name="l878"><span class="ln">878  </span></a><span class="s0">print(</span><span class="s3">f&quot;[Linear Regression] R² Score: </span><span class="s5">{</span><span class="s0">r2_lr</span><span class="s5">:</span><span class="s3">.2f</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s0">)</span>
<a name="l879"><span class="ln">879  </span></a>
<a name="l880"><span class="ln">880  </span></a><span class="s2"># Scatterplot mit Regressionslinie</span>
<a name="l881"><span class="ln">881  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">8</span><span class="s0">, </span><span class="s4">6</span><span class="s0">))</span>
<a name="l882"><span class="ln">882  </span></a><span class="s0">sns.scatterplot(x=y_test, y=y_pred_lr, alpha=</span><span class="s4">0.7</span><span class="s0">)</span>
<a name="l883"><span class="ln">883  </span></a><span class="s0">sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], color=</span><span class="s3">&quot;red&quot;</span><span class="s0">, label=</span><span class="s3">&quot;Ideallinie&quot;</span><span class="s0">)</span>
<a name="l884"><span class="ln">884  </span></a>
<a name="l885"><span class="ln">885  </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Tatsächlicher Prüfungswert&quot;</span><span class="s0">)</span>
<a name="l886"><span class="ln">886  </span></a><span class="s0">plt.ylabel(</span><span class="s3">&quot;Vorhergesagter Prüfungswert&quot;</span><span class="s0">)</span>
<a name="l887"><span class="ln">887  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Tatsächliche vs. vorhergesagte Prüfungsleistung (Linear Regression)&quot;</span><span class="s0">)</span>
<a name="l888"><span class="ln">888  </span></a><span class="s0">plt.legend()</span>
<a name="l889"><span class="ln">889  </span></a><span class="s0">plt.tight_layout()</span>
<a name="l890"><span class="ln">890  </span></a><span class="s0">plt.show()</span>
<a name="l891"><span class="ln">891  </span></a><hr class="ls0"><a name="l892"><span class="ln">892  </span></a><span class="s0">#%% md 
<a name="l893"><span class="ln">893  </span></a>## Bewertung des linearen Regressionsmodells 
<a name="l894"><span class="ln">894  </span></a> 
<a name="l895"><span class="ln">895  </span></a>Zur Beantwortung der Forschungsfrage wurde ein lineares Regressionsmodell mit allen verfügbaren Merkmalen trainiert. Ziel war es, den Zusammenhang zwischen studentischen Verhaltensweisen und der Prüfungsleistung (`exam_score`) quantitativ zu modellieren und anschließend erklärbar zu machen. 
<a name="l896"><span class="ln">896  </span></a> 
<a name="l897"><span class="ln">897  </span></a>Der folgende Plot zeigt die Gegenüberstellung der tatsächlichen Prüfungswerte aus dem Testdatensatz (x-Achse) und der durch das Modell vorhergesagten Werte (y-Achse). Die rote Linie stellt die ideale 1:1-Beziehung dar, bei der Vorhersage und Realität exakt übereinstimmen würden. 
<a name="l898"><span class="ln">898  </span></a> 
<a name="l899"><span class="ln">899  </span></a>### Modellgüte 
<a name="l900"><span class="ln">900  </span></a> 
<a name="l901"><span class="ln">901  </span></a>Das Modell erreicht einen **R²-Wert von 0.90**, was bedeutet, dass **90% der Varianz in den Prüfungsergebnissen durch die gewählten Merkmale erklärt werden kann**. Der **mittlere quadratische Fehler (MSE)** beträgt **26.48**, was bei einer Skala von 0 bis 100 als sehr solide betrachtet werden kann. 
<a name="l902"><span class="ln">902  </span></a> 
<a name="l903"><span class="ln">903  </span></a>Die Punktewolke folgt der Ideallinie mit relativ geringer Streuung, insbesondere im mittleren Wertebereich. Vereinzelte Abweichungen bei niedrigen oder sehr hohen Prüfungswerten deuten darauf hin, dass extreme Ausprägungen möglicherweise nicht vollständig durch lineare Zusammenhänge abgedeckt werden was für dieses Modell jedoch erwartbar ist. 
<a name="l904"><span class="ln">904  </span></a> 
<a name="l905"><span class="ln">905  </span></a>### Interpretation und Limitationen 
<a name="l906"><span class="ln">906  </span></a> 
<a name="l907"><span class="ln">907  </span></a>Die hohe Modellgüte ist angesichts der **synthetischen Natur des Datensatzes** mit Vorsicht zu interpretieren. Es ist möglich, dass die Generierungslogik des Datensatzes relativ starke lineare Abhängigkeiten zwischen den Merkmalen eingebaut hat. In einem realen Datensatz wäre ein R²-Wert in dieser Höhe ungewöhnlich und müsste kritisch hinterfragt werden. 
<a name="l908"><span class="ln">908  </span></a> 
<a name="l909"><span class="ln">909  </span></a>Nichtsdestotrotz bietet das Modell eine fundierte Grundlage, um auf aggregierter Ebene zu analysieren, welche Merkmale in welchem Umfang zur Vorhersage der Prüfungsleistung beitragen. 
<a name="l910"><span class="ln">910  </span></a> <hr class="ls0"><a name="l911"><span class="ln">911  </span></a>#%% md 
<a name="l912"><span class="ln">912  </span></a>--- 
<a name="l913"><span class="ln">913  </span></a> 
<a name="l914"><span class="ln">914  </span></a>## Vergleichsmodell: Random Forest Regressor 
<a name="l915"><span class="ln">915  </span></a> 
<a name="l916"><span class="ln">916  </span></a>Um die Ergebnisse der linearen Regression besser einordnen zu können, wird im Folgenden ein alternatives Modell trainiert und analysiert. Dabei handelt es sich um einen **Random Forest Regressor**, ein nicht-lineares Ensemble-Verfahren, das auf der Aggregation vieler Entscheidungsbäume basiert. 
<a name="l917"><span class="ln">917  </span></a> 
<a name="l918"><span class="ln">918  </span></a>Der Random Forest erlaubt es, auch **komplexe, nicht-lineare Zusammenhänge** zwischen den Merkmalen zu modellieren und ist gleichzeitig relativ robust gegenüber Ausreißern und übermäßiger Varianz im Datensatz. Gerade bei synthetischen Daten, bei denen lineare und nicht-lineare Muster gleichzeitig auftreten können, ist es sinnvoll, den Random Forest als leistungsfähigen Referenzpunkt heranzuziehen. 
<a name="l919"><span class="ln">919  </span></a> 
<a name="l920"><span class="ln">920  </span></a>In den folgenden Abschnitten wird das Modell trainiert, evaluiert und hinsichtlich seiner Erklärbarkeit untersucht. Ziel ist es, anschließend systematisch zu entscheiden, ob sich der Random Forest oder die lineare Regression besser für die Analyse der Prüfungsleistung eignet. 
<a name="l921"><span class="ln">921  </span></a> <hr class="ls0"><a name="l922"><span class="ln">922  </span></a>#%% 
<a name="l923"><span class="ln">923  </span></a></span>
<a name="l924"><span class="ln">924  </span></a>
<a name="l925"><span class="ln">925  </span></a><span class="s2"># Stil für die Diagramme setzen</span>
<a name="l926"><span class="ln">926  </span></a><span class="s0">sns.set(style=</span><span class="s3">&quot;whitegrid&quot;</span><span class="s0">)</span>
<a name="l927"><span class="ln">927  </span></a><span class="s0">plt.rcParams[</span><span class="s3">&quot;figure.figsize&quot;</span><span class="s0">] = (</span><span class="s4">10</span><span class="s0">, </span><span class="s4">6</span><span class="s0">)</span>
<a name="l928"><span class="ln">928  </span></a>
<a name="l929"><span class="ln">929  </span></a><span class="s2"># CSV-Datei einlesen</span>
<a name="l930"><span class="ln">930  </span></a><span class="s0">df = pd.read_csv(</span><span class="s3">&quot;data/student_habits_performance.csv&quot;</span><span class="s0">)</span>
<a name="l931"><span class="ln">931  </span></a>
<a name="l932"><span class="ln">932  </span></a><span class="s2"># Feature-Matrix (X) und Zielvariable (y) vorbereiten</span>
<a name="l933"><span class="ln">933  </span></a><span class="s0">X = df.drop(columns=[</span><span class="s3">&quot;student_id&quot;</span><span class="s0">, </span><span class="s3">&quot;exam_score&quot;</span><span class="s0">])</span>
<a name="l934"><span class="ln">934  </span></a><span class="s0">y = df[</span><span class="s3">&quot;exam_score&quot;</span><span class="s0">]</span>
<a name="l935"><span class="ln">935  </span></a>
<a name="l936"><span class="ln">936  </span></a><span class="s2"># Kategorische Features identifizieren</span>
<a name="l937"><span class="ln">937  </span></a><span class="s0">categorical_features = X.select_dtypes(include=</span><span class="s3">&quot;object&quot;</span><span class="s0">).columns.tolist()</span>
<a name="l938"><span class="ln">938  </span></a>
<a name="l939"><span class="ln">939  </span></a><span class="s2"># Preprocessing-Schritt mit OneHotEncoding</span>
<a name="l940"><span class="ln">940  </span></a><span class="s0">preprocessor = ColumnTransformer(</span>
<a name="l941"><span class="ln">941  </span></a>    <span class="s0">transformers=[</span>
<a name="l942"><span class="ln">942  </span></a>        <span class="s0">(</span><span class="s3">&quot;cat&quot;</span><span class="s0">, OneHotEncoder(drop=</span><span class="s3">&quot;first&quot;</span><span class="s0">, sparse_output=</span><span class="s1">False</span><span class="s0">), categorical_features)</span>
<a name="l943"><span class="ln">943  </span></a>    <span class="s0">],</span>
<a name="l944"><span class="ln">944  </span></a>    <span class="s0">remainder=</span><span class="s3">&quot;passthrough&quot;</span>
<a name="l945"><span class="ln">945  </span></a><span class="s0">)</span>
<a name="l946"><span class="ln">946  </span></a>
<a name="l947"><span class="ln">947  </span></a><span class="s2"># Pipeline definieren (Preprocessing + Random Forest Modell)</span>
<a name="l948"><span class="ln">948  </span></a><span class="s0">model_pipeline_rf = Pipeline(steps=[</span>
<a name="l949"><span class="ln">949  </span></a>    <span class="s0">(</span><span class="s3">&quot;preprocessing&quot;</span><span class="s0">, preprocessor),</span>
<a name="l950"><span class="ln">950  </span></a>    <span class="s0">(</span><span class="s3">&quot;regressor&quot;</span><span class="s0">, RandomForestRegressor(n_estimators=</span><span class="s4">200</span><span class="s0">, random_state=</span><span class="s4">42</span><span class="s0">))</span>
<a name="l951"><span class="ln">951  </span></a><span class="s0">])</span>
<a name="l952"><span class="ln">952  </span></a>
<a name="l953"><span class="ln">953  </span></a><span class="s2"># Train/Test Split (80/20)</span>
<a name="l954"><span class="ln">954  </span></a><span class="s0">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=</span><span class="s4">0.2</span><span class="s0">, random_state=</span><span class="s4">42</span><span class="s0">)</span>
<a name="l955"><span class="ln">955  </span></a>
<a name="l956"><span class="ln">956  </span></a><span class="s2"># Modelltraining</span>
<a name="l957"><span class="ln">957  </span></a><span class="s0">model_pipeline_rf.fit(X_train, y_train)</span>
<a name="l958"><span class="ln">958  </span></a>
<a name="l959"><span class="ln">959  </span></a><span class="s2"># Vorhersagen erstellen</span>
<a name="l960"><span class="ln">960  </span></a><span class="s0">y_pred_rf = model_pipeline_rf.predict(X_test)</span>
<a name="l961"><span class="ln">961  </span></a>
<a name="l962"><span class="ln">962  </span></a><span class="s2"># Modellgüte evaluieren</span>
<a name="l963"><span class="ln">963  </span></a><span class="s0">mse_rf = mean_squared_error(y_test, y_pred_rf)</span>
<a name="l964"><span class="ln">964  </span></a><span class="s0">r2_rf = r2_score(y_test, y_pred_rf)</span>
<a name="l965"><span class="ln">965  </span></a>
<a name="l966"><span class="ln">966  </span></a><span class="s0">print(</span><span class="s3">f&quot;[Random Forest] MSE: </span><span class="s5">{</span><span class="s0">mse_rf</span><span class="s5">:</span><span class="s3">.2f</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s0">)</span>
<a name="l967"><span class="ln">967  </span></a><span class="s0">print(</span><span class="s3">f&quot;[Random Forest] R²: </span><span class="s5">{</span><span class="s0">r2_rf</span><span class="s5">:</span><span class="s3">.2f</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s0">)</span>
<a name="l968"><span class="ln">968  </span></a>
<a name="l969"><span class="ln">969  </span></a><span class="s2"># Scatterplot zur Modellgüte</span>
<a name="l970"><span class="ln">970  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">8</span><span class="s0">, </span><span class="s4">6</span><span class="s0">))</span>
<a name="l971"><span class="ln">971  </span></a><span class="s0">sns.scatterplot(x=y_test, y=y_pred_rf, alpha=</span><span class="s4">0.6</span><span class="s0">)</span>
<a name="l972"><span class="ln">972  </span></a><span class="s0">sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], color=</span><span class="s3">&quot;red&quot;</span><span class="s0">, label=</span><span class="s3">&quot;Ideallinie&quot;</span><span class="s0">)</span>
<a name="l973"><span class="ln">973  </span></a>
<a name="l974"><span class="ln">974  </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Tatsächlicher Prüfungswert&quot;</span><span class="s0">)</span>
<a name="l975"><span class="ln">975  </span></a><span class="s0">plt.ylabel(</span><span class="s3">&quot;Vorhergesagter Prüfungswert&quot;</span><span class="s0">)</span>
<a name="l976"><span class="ln">976  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Random Forest Regressor: Tatsächlich vs. vorhergesagt&quot;</span><span class="s0">)</span>
<a name="l977"><span class="ln">977  </span></a><span class="s0">plt.legend()</span>
<a name="l978"><span class="ln">978  </span></a><span class="s0">plt.tight_layout()</span>
<a name="l979"><span class="ln">979  </span></a><span class="s0">plt.show()</span>
<a name="l980"><span class="ln">980  </span></a>
<a name="l981"><span class="ln">981  </span></a><span class="s2"># Residualplot</span>
<a name="l982"><span class="ln">982  </span></a><span class="s0">residuals_rf = y_test - y_pred_rf</span>
<a name="l983"><span class="ln">983  </span></a>
<a name="l984"><span class="ln">984  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">8</span><span class="s0">, </span><span class="s4">5</span><span class="s0">))</span>
<a name="l985"><span class="ln">985  </span></a><span class="s0">sns.scatterplot(x=y_pred_rf, y=residuals_rf, alpha=</span><span class="s4">0.6</span><span class="s0">)</span>
<a name="l986"><span class="ln">986  </span></a><span class="s0">plt.axhline(</span><span class="s4">0</span><span class="s0">, color=</span><span class="s3">&quot;red&quot;</span><span class="s0">, linestyle=</span><span class="s3">&quot;--&quot;</span><span class="s0">, linewidth=</span><span class="s4">1.2</span><span class="s0">)</span>
<a name="l987"><span class="ln">987  </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Vorhergesagte Prüfungswerte&quot;</span><span class="s0">)</span>
<a name="l988"><span class="ln">988  </span></a><span class="s0">plt.ylabel(</span><span class="s3">&quot;Residuen (Ist - Vorhergesagt)&quot;</span><span class="s0">)</span>
<a name="l989"><span class="ln">989  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Residualplot – Fehlerverteilung des Random Forest Regressors&quot;</span><span class="s0">)</span>
<a name="l990"><span class="ln">990  </span></a><span class="s0">plt.tight_layout()</span>
<a name="l991"><span class="ln">991  </span></a><span class="s0">plt.show()</span>
<a name="l992"><span class="ln">992  </span></a>
<a name="l993"><span class="ln">993  </span></a><span class="s2"># Histogramm der Residuen</span>
<a name="l994"><span class="ln">994  </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">8</span><span class="s0">, </span><span class="s4">5</span><span class="s0">))</span>
<a name="l995"><span class="ln">995  </span></a><span class="s0">sns.histplot(residuals_rf, kde=</span><span class="s1">True</span><span class="s0">, bins=</span><span class="s4">30</span><span class="s0">, color=</span><span class="s3">&quot;steelblue&quot;</span><span class="s0">)</span>
<a name="l996"><span class="ln">996  </span></a><span class="s0">plt.axvline(</span><span class="s4">0</span><span class="s0">, color=</span><span class="s3">&quot;red&quot;</span><span class="s0">, linestyle=</span><span class="s3">&quot;--&quot;</span><span class="s0">, linewidth=</span><span class="s4">1.2</span><span class="s0">)</span>
<a name="l997"><span class="ln">997  </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Residuen&quot;</span><span class="s0">)</span>
<a name="l998"><span class="ln">998  </span></a><span class="s0">plt.ylabel(</span><span class="s3">&quot;Häufigkeit&quot;</span><span class="s0">)</span>
<a name="l999"><span class="ln">999  </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Histogramm der Residuen&quot;</span><span class="s0">)</span>
<a name="l1000"><span class="ln">1000 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1001"><span class="ln">1001 </span></a><span class="s0">plt.show()</span>
<a name="l1002"><span class="ln">1002 </span></a><hr class="ls0"><a name="l1003"><span class="ln">1003 </span></a><span class="s0">#%% md 
<a name="l1004"><span class="ln">1004 </span></a>## Auswertung des Random-Forest-Modells 
<a name="l1005"><span class="ln">1005 </span></a> 
<a name="l1006"><span class="ln">1006 </span></a>Der Random Forest wurde in diesem Projekt als alternatives Regressionsmodell eingesetzt, um die lineare Regression mit einem flexibleren Ansatz zu vergleichen. Dabei ging es vor allem um die Frage, ob sich durch die Modellierung nichtlinearer Zusammenhänge eine verbesserte Vorhersagequalität erzielen lässt. 
<a name="l1007"><span class="ln">1007 </span></a> 
<a name="l1008"><span class="ln">1008 </span></a>Die Ergebnisse zeigen, dass das Modell solide performt. Der erreichte **R²-Wert von 0.85** und ein **mittlerer quadratischer Fehler von 38.17** deuten auf eine insgesamt gute Modellanpassung hin. Dennoch liegt die Modellgüte in beiden Kennzahlen leicht unter der der linearen Regression. 
<a name="l1009"><span class="ln">1009 </span></a> 
<a name="l1010"><span class="ln">1010 </span></a>Auch die Visualisierungen bestätigen diesen Eindruck. Im Scatterplot liegen die Punkte zwar größtenteils entlang der Ideallinie, die Streuung ist jedoch etwas ausgeprägter als beim linearen Modell. Der Residualplot zeigt eine weitgehend gleichmäßige Fehlerverteilung, allerdings mit einzelnen Ausreißern. Das Histogramm der Residuen wirkt insgesamt symmetrisch, weist aber eine leicht linksseitige Verzerrung auf, was auf eine gewisse systematische Unterschätzung hindeuten könnte. 
<a name="l1011"><span class="ln">1011 </span></a> 
<a name="l1012"><span class="ln">1012 </span></a>Aus methodischer Sicht ist außerdem zu beachten, dass der Random Forest als **Blackbox-Modell** keine direkte Einsicht in die Einflussstärke einzelner Merkmale bietet. Um die Ergebnisse dieses Modells interpretierbar zu machen, wären zusätzliche erklärende Verfahren erforderlich. 
<a name="l1013"><span class="ln">1013 </span></a> 
<a name="l1014"><span class="ln">1014 </span></a>Trotz guter Leistung zeigt sich also, dass der Random Forest in diesem konkreten Fall nicht nur leicht schwächer abschneidet, sondern auch hinsichtlich der Nachvollziehbarkeit gewisse Nachteile mit sich bringt. 
<a name="l1015"><span class="ln">1015 </span></a> <hr class="ls0"><a name="l1016"><span class="ln">1016 </span></a>#%% md 
<a name="l1017"><span class="ln">1017 </span></a>## Vergleich der Modelle: Lineare Regression vs. Random Forest 
<a name="l1018"><span class="ln">1018 </span></a> 
<a name="l1019"><span class="ln">1019 </span></a>Nach dem Training und der Auswertung zweier verschiedener Regressionsmodelle – der linearen Regression und des Random Forest Regressors – erfolgt an dieser Stelle eine vergleichende Analyse. Ziel ist es, sowohl ihre Vorhersagekraft als auch ihre Erklärbarkeit zu bewerten, um den weiteren Einsatz beider Modelle im Kontext erklärbarer KI zu begründen. Besonders relevant ist dabei der methodische Vergleich zwischen einem Whitebox- und einem Blackbox-Modell unter Einsatz von SHAP. 
<a name="l1020"><span class="ln">1020 </span></a> 
<a name="l1021"><span class="ln">1021 </span></a>### Modellgüte und Vorhersagekraft im Vergleich 
<a name="l1022"><span class="ln">1022 </span></a> 
<a name="l1023"><span class="ln">1023 </span></a>Die lineare Regression erzielte im Testdatensatz einen **R²-Wert von 0.90** und einen **mittleren quadratischen Fehler (MSE) von 26.48**. Diese Werte deuten auf eine sehr gute Modellpassung hin – ein Großteil der Varianz in der Zielgröße `exam_score` lässt sich durch die erklärenden Merkmale gut abbilden. Auch die visuelle Darstellung zeigt, dass die Vorhersagen der linearen Regression eng entlang der Ideallinie liegen. 
<a name="l1024"><span class="ln">1024 </span></a> 
<a name="l1025"><span class="ln">1025 </span></a>Der Random Forest Regressor kam auf einen **R²-Wert von 0.85** und einen **MSE von 38.17**. Diese Werte sind nach wie vor solide, liegen jedoch hinter denen der linearen Regression. In der grafischen Darstellung sind die Vorhersagen etwas ungenauer und streuen stärker um die Zielgerade. Trotz der grundsätzlich robusten Modellarchitektur ließ sich durch zusätzliche Hyperparameteranpassung keine signifikante Verbesserung erzielen. 
<a name="l1026"><span class="ln">1026 </span></a> 
<a name="l1027"><span class="ln">1027 </span></a>### Erklärbarkeit und didaktische Eignung 
<a name="l1028"><span class="ln">1028 </span></a> 
<a name="l1029"><span class="ln">1029 </span></a>Ein zentrales Ziel dieses Projekts besteht darin, die Einflüsse von Alltagsverhalten auf die Prüfungsleistung nicht nur zu modellieren, sondern auch **verständlich und datenbasiert zu erklären**. Hier spielt die Modellwahl eine entscheidende Rolle. 
<a name="l1030"><span class="ln">1030 </span></a> 
<a name="l1031"><span class="ln">1031 </span></a>Die **lineare Regression** ist als klassisches *Whitebox-Modell* vollständig interpretierbar. Sie erlaubt es, direkte Aussagen über den Einfluss einzelner Merkmale auf die Zielgröße zu treffen – inklusive Vorzeichen und Effektstärke. Das macht sie besonders geeignet für die Herleitung allgemeiner Erklärungsansätze, etwa in der Studienberatung. 
<a name="l1032"><span class="ln">1032 </span></a> 
<a name="l1033"><span class="ln">1033 </span></a>Der **Random Forest** gilt hingegen als *Blackbox-Modell*. Zwar liefert er ebenfalls gute Vorhersagen, doch ist die interne Logik durch die Vielzahl verschachtelter Entscheidungsbäume weniger transparent. Gerade deshalb ist er aber besonders interessant für den Einsatz erklärbarer KI-Methoden wie SHAP, die es ermöglichen, auch komplexe Modelle nachvollziehbar zu machen. 
<a name="l1034"><span class="ln">1034 </span></a> 
<a name="l1035"><span class="ln">1035 </span></a>### Methodische Entscheidung 
<a name="l1036"><span class="ln">1036 </span></a> 
<a name="l1037"><span class="ln">1037 </span></a>Obwohl die lineare Regression die besseren Leistungskennzahlen zeigt, wird **nicht auf den Random Forest verzichtet**. Vielmehr wird er **gezielt beibehalten**, um die Stärken und Schwächen von SHAP als Erklärbarkeitsmethode sowohl auf einem Whitebox- als auch einem Blackbox-Modell zu demonstrieren. 
<a name="l1038"><span class="ln">1038 </span></a> 
<a name="l1039"><span class="ln">1039 </span></a>**Für den weiteren Projektverlauf werden daher beide Modelle parallel eingesetzt**: 
<a name="l1040"><span class="ln">1040 </span></a>- Die **lineare Regression** als transparentes, referenzierbares Erklärmodell 
<a name="l1041"><span class="ln">1041 </span></a>- Der **Random Forest** als komplexeres, leistungsfähiges Blackbox-Modell, das durch SHAP aufgeschlüsselt werden soll 
<a name="l1042"><span class="ln">1042 </span></a> 
<a name="l1043"><span class="ln">1043 </span></a>Dieser Vergleich unterstützt das Ziel, die Wirkung von Alltagsfaktoren sowohl in einfacher Form als auch in komplexeren Interaktionen sichtbar zu machen. 
<a name="l1044"><span class="ln">1044 </span></a> <hr class="ls0"><a name="l1045"><span class="ln">1045 </span></a>#%% md 
<a name="l1046"><span class="ln">1046 </span></a># Einleitung in erklärbare KI (XAI / Explainable Artificial Intelligence) 
<a name="l1047"><span class="ln">1047 </span></a> 
<a name="l1048"><span class="ln">1048 </span></a>Nachdem die Vorhersageleistung der beiden Modelle, der linearen Regression und dem Random Forest Regressor analysiert und verglichen wurde, folgt nun ein Abschnitt, der sich einem zentralen Aspekt datenbasierter Modellierung widmet: der Erklärbarkeit. Besonders bei sensiblen Fragestellungen wie dem Einfluss alltäglicher Verhaltensweisen auf akademische Leistungen reicht es nicht aus, nur präzise Vorhersagen zu treffen – es muss auch nachvollziehbar sein, **warum** ein Modell zu bestimmten Entscheidungen gelangt. 
<a name="l1049"><span class="ln">1049 </span></a> 
<a name="l1050"><span class="ln">1050 </span></a>An dieser Stelle kommen Methoden der **erklärbaren künstlichen Intelligenz (XAI)** ins Spiel. Diese ermöglichen es, die Bedeutung einzelner Merkmale sichtbar zu machen – entweder für das Modellverhalten insgesamt (*global*) oder für spezifische Vorhersagen (*lokal*). Sie erhöhen nicht nur die Transparenz, sondern fördern auch das Vertrauen in datenbasierte Entscheidungshilfen. 
<a name="l1051"><span class="ln">1051 </span></a> 
<a name="l1052"><span class="ln">1052 </span></a>In diesem Projekt werden zwei unterschiedliche Modellarten – ein **Whitebox-Modell** (lineare Regression) und ein **Blackbox-Modell** (Random Forest) – eingesetzt. Dadurch entsteht eine besonders lehrreiche Ausgangslage für den Einsatz von XAI-Methoden. 
<a name="l1053"><span class="ln">1053 </span></a> 
<a name="l1054"><span class="ln">1054 </span></a>Im Fokus steht dabei: 
<a name="l1055"><span class="ln">1055 </span></a> 
<a name="l1056"><span class="ln">1056 </span></a>- **SHAP** (*SHapley Additive exPlanations*): Diese Methode basiert auf Konzepten der kooperativen Spieltheorie und weist jedem Merkmal einen Erklärungswert zu. Sie quantifiziert, welchen Beitrag ein Merkmal zur Modellvorhersage leistet – sowohl auf aggregierter Ebene als auch für einzelne Instanzen. SHAP ist mathematisch fundiert, konsistent und eignet sich besonders gut für die Visualisierung strukturierter Zusammenhänge. 
<a name="l1057"><span class="ln">1057 </span></a> 
<a name="l1058"><span class="ln">1058 </span></a>Obwohl auch Methoden wie **LIME** (*Local Interpretable Model-agnostic Explanations*) grundsätzlich eingesetzt werden könnten, liegt der Fokus in diesem Projekt vollständig auf SHAP. Der Grund: SHAP erlaubt sowohl für das transparente lineare Regressionsmodell als auch für das komplexere Random-Forest-Modell eine konsistente und vergleichbare Interpretation. 
<a name="l1059"><span class="ln">1059 </span></a> 
<a name="l1060"><span class="ln">1060 </span></a>Im nächsten Abschnitt wird SHAP auf beide Modelle angewendet, um zentrale Einflussfaktoren auf die Prüfungsleistung sichtbar zu machen und Unterschiede in der Merkmalbedeutung zwischen Whitebox- und Blackbox-Modell herauszuarbeiten. 
<a name="l1061"><span class="ln">1061 </span></a> <hr class="ls0"><a name="l1062"><span class="ln">1062 </span></a>#%% 
<a name="l1063"><span class="ln">1063 </span></a></span>
<a name="l1064"><span class="ln">1064 </span></a><span class="s2"># 1. SHAP vorbereiten</span>
<a name="l1065"><span class="ln">1065 </span></a><span class="s0">preprocessor_lr = model_pipeline_lr.named_steps[</span><span class="s3">&quot;preprocessing&quot;</span><span class="s0">]</span>
<a name="l1066"><span class="ln">1066 </span></a><span class="s0">model_lr = model_pipeline_lr.named_steps[</span><span class="s3">&quot;regression&quot;</span><span class="s0">]</span>
<a name="l1067"><span class="ln">1067 </span></a><span class="s0">X_test_transformed_lr = preprocessor_lr.transform(X_test)</span>
<a name="l1068"><span class="ln">1068 </span></a><span class="s0">feature_names_lr = preprocessor_lr.get_feature_names_out()</span>
<a name="l1069"><span class="ln">1069 </span></a>
<a name="l1070"><span class="ln">1070 </span></a><span class="s2"># 2. Feature-Namen bereinigen (entfernt technische Präfixe)</span>
<a name="l1071"><span class="ln">1071 </span></a><span class="s1">def </span><span class="s0">simplify_feature_names(feature_names):</span>
<a name="l1072"><span class="ln">1072 </span></a>    <span class="s1">return </span><span class="s0">[name.replace(</span><span class="s3">&quot;cat__&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s0">).replace(</span><span class="s3">&quot;remainder__&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s0">) </span><span class="s1">for </span><span class="s0">name </span><span class="s1">in </span><span class="s0">feature_names]</span>
<a name="l1073"><span class="ln">1073 </span></a>
<a name="l1074"><span class="ln">1074 </span></a><span class="s0">feature_names_clean = simplify_feature_names(feature_names_lr)</span>
<a name="l1075"><span class="ln">1075 </span></a>
<a name="l1076"><span class="ln">1076 </span></a><span class="s2"># 3. SHAP-Werte berechnen (für lineares Modell)</span>
<a name="l1077"><span class="ln">1077 </span></a><span class="s0">explainer_lr = shap.LinearExplainer(model_lr, X_test_transformed_lr)</span>
<a name="l1078"><span class="ln">1078 </span></a><span class="s0">shap_values_lr = explainer_lr(X_test_transformed_lr).values</span>
<a name="l1079"><span class="ln">1079 </span></a>
<a name="l1080"><span class="ln">1080 </span></a><span class="s2"># 4. Barplot – mittlere absolute SHAP-Werte pro Feature</span>
<a name="l1081"><span class="ln">1081 </span></a><span class="s0">shap_df_lr = pd.DataFrame(np.abs(shap_values_lr), columns=feature_names_clean)</span>
<a name="l1082"><span class="ln">1082 </span></a><span class="s0">shap_summary_full = shap_df_lr.mean().sort_values(ascending=</span><span class="s1">True</span><span class="s0">)</span>
<a name="l1083"><span class="ln">1083 </span></a>
<a name="l1084"><span class="ln">1084 </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">6</span><span class="s0">))</span>
<a name="l1085"><span class="ln">1085 </span></a><span class="s0">shap_summary_full.plot(kind=</span><span class="s3">'barh'</span><span class="s0">, color=</span><span class="s3">'cornflowerblue'</span><span class="s0">)</span>
<a name="l1086"><span class="ln">1086 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Barplot – Mittlere absolute SHAP-Werte (Lineare Regression)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1087"><span class="ln">1087 </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Mittlerer absoluter SHAP-Wert&quot;</span><span class="s0">)</span>
<a name="l1088"><span class="ln">1088 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1089"><span class="ln">1089 </span></a><span class="s0">plt.show()</span>
<a name="l1090"><span class="ln">1090 </span></a>
<a name="l1091"><span class="ln">1091 </span></a><span class="s2"># 5. Summary Plot – zeigt Richtung &amp; Verteilung der Effekte</span>
<a name="l1092"><span class="ln">1092 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Summary Plot – Featurewirkung und -verteilung (Lineare Regression)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1093"><span class="ln">1093 </span></a><span class="s0">shap.summary_plot(</span>
<a name="l1094"><span class="ln">1094 </span></a>    <span class="s0">shap_values_lr,</span>
<a name="l1095"><span class="ln">1095 </span></a>    <span class="s0">X_test_transformed_lr,</span>
<a name="l1096"><span class="ln">1096 </span></a>    <span class="s0">feature_names=feature_names_clean</span>
<a name="l1097"><span class="ln">1097 </span></a><span class="s0">)</span>
<a name="l1098"><span class="ln">1098 </span></a>
<a name="l1099"><span class="ln">1099 </span></a><span class="s2"># 6. Dependence Plot – zeigt Effekt von Lernzeit abhängig vom Schlaf</span>
<a name="l1100"><span class="ln">1100 </span></a><span class="s0">shap.dependence_plot(</span>
<a name="l1101"><span class="ln">1101 </span></a>    <span class="s0">ind=</span><span class="s3">&quot;remainder__study_hours_per_day&quot;</span><span class="s0">,              </span><span class="s2"># originaler Feature-Name!</span>
<a name="l1102"><span class="ln">1102 </span></a>    <span class="s0">shap_values=shap_values_lr,</span>
<a name="l1103"><span class="ln">1103 </span></a>    <span class="s0">features=X_test_transformed_lr,</span>
<a name="l1104"><span class="ln">1104 </span></a>    <span class="s0">feature_names=feature_names_lr,                    </span><span class="s2"># original-Namen, nicht bereinigt!</span>
<a name="l1105"><span class="ln">1105 </span></a>    <span class="s0">interaction_index=</span><span class="s3">&quot;remainder__sleep_hours&quot;</span><span class="s0">,</span>
<a name="l1106"><span class="ln">1106 </span></a>    <span class="s0">show=</span><span class="s1">False                                          </span><span class="s2"># verhindert automatische Anzeige</span>
<a name="l1107"><span class="ln">1107 </span></a><span class="s0">)</span>
<a name="l1108"><span class="ln">1108 </span></a>
<a name="l1109"><span class="ln">1109 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Dependence Plot – Wirkung von Lernzeit abhängig vom Schlaf (Lineare Regression)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1110"><span class="ln">1110 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1111"><span class="ln">1111 </span></a><span class="s0">plt.show()</span>
<a name="l1112"><span class="ln">1112 </span></a>
<a name="l1113"><span class="ln">1113 </span></a>
<a name="l1114"><span class="ln">1114 </span></a><hr class="ls0"><a name="l1115"><span class="ln">1115 </span></a><span class="s0">#%% md 
<a name="l1116"><span class="ln">1116 </span></a>### SHAP Barplot – Globale Bedeutung der Merkmale 
<a name="l1117"><span class="ln">1117 </span></a> 
<a name="l1118"><span class="ln">1118 </span></a>**Methode:** SHAP (SHapley Additive exPlanations) berechnet den durchschnittlichen Beitrag jedes Merkmals zur Modellvorhersage. In diesem Barplot werden die **mittleren absoluten SHAP-Werte** aller Features dargestellt. Je höher, desto stärker beeinflusst ein Merkmal das Ergebnis. 
<a name="l1119"><span class="ln">1119 </span></a> 
<a name="l1120"><span class="ln">1120 </span></a>**Ziel:** Identifikation der global wichtigsten Einflussfaktoren auf die vorhergesagte Prüfungsleistung. 
<a name="l1121"><span class="ln">1121 </span></a> 
<a name="l1122"><span class="ln">1122 </span></a>**Erwartungsgemäße Befunde:** 
<a name="l1123"><span class="ln">1123 </span></a>- Es war zu erwarten, dass `study_hours_per_day` (tägliche Lernzeit) das Modell stark beeinflusst, da mehr Lernzeit typischerweise mit besseren Leistungen korreliert. 
<a name="l1124"><span class="ln">1124 </span></a>- Auch `mental_health_rating` (subjektive Einschätzung der psychischen Verfassung) ist plausibel: Mentale Stabilität kann die Konzentration, Ausdauer und Motivation verbessern. 
<a name="l1125"><span class="ln">1125 </span></a> 
<a name="l1126"><span class="ln">1126 </span></a>**Unerwartetes / Auffälliges:** 
<a name="l1127"><span class="ln">1127 </span></a>- Überraschend deutlich ist der Abstand der beiden Top-Features zum Rest: Der Einfluss anderer Merkmale fällt stark ab. 
<a name="l1128"><span class="ln">1128 </span></a>- `social_media_hours` und `netflix_hours` haben zwar einen Effekt, aber kleiner als erwartet – möglicherweise, weil sie in der Regel **nicht extrem ausgeprägt** sind oder **mit Lernzeit negativ korreliert** sind (multikollinear). 
<a name="l1129"><span class="ln">1129 </span></a>- Einige Merkmale wie `diet_quality`, `internet_quality` oder `parental_education_level` zeigen **nahezu keinen Effekt**, obwohl man annehmen könnte, dass sie indirekt relevant sind. 
<a name="l1130"><span class="ln">1130 </span></a> 
<a name="l1131"><span class="ln">1131 </span></a>**Fazit:** Das Modell fokussiert sich stark auf **Verhalten und mentale Verfassung**, strukturelle oder demografische Merkmale spielen eine untergeordnete Rolle. 
<a name="l1132"><span class="ln">1132 </span></a> <hr class="ls0"><a name="l1133"><span class="ln">1133 </span></a>#%% md 
<a name="l1134"><span class="ln">1134 </span></a>### SHAP Summary Plot – Wirkung und Streuung der Merkmalseffekte 
<a name="l1135"><span class="ln">1135 </span></a> 
<a name="l1136"><span class="ln">1136 </span></a>**Methode:** Der Summary Plot kombiniert Feature-Wichtigkeit (Rangfolge) mit der **Wirkungsrichtung** (SHAP-Wert positiv oder negativ) und der **Verteilung der Merkmalsausprägungen** (Farbskala). 
<a name="l1137"><span class="ln">1137 </span></a> 
<a name="l1138"><span class="ln">1138 </span></a>**Ziel:** Besseres Verständnis darüber, **wie** ein Merkmal wirkt: z.B. ob hohe Werte die Leistung fördern oder senken. 
<a name="l1139"><span class="ln">1139 </span></a> 
<a name="l1140"><span class="ln">1140 </span></a>**Erwartungsgemäße Befunde:** 
<a name="l1141"><span class="ln">1141 </span></a>- Höhere `study_hours_per_day` führen zu höheren Vorhersagen (pink Punkte rechts). Genau wie erwartet. 
<a name="l1142"><span class="ln">1142 </span></a>- Auch bei `mental_health_rating` ergibt sich ein klar positiver Zusammenhang: Personen mit stabiler mentaler Gesundheit erzielen tendenziell bessere Leistungen. 
<a name="l1143"><span class="ln">1143 </span></a> 
<a name="l1144"><span class="ln">1144 </span></a>**Unerwartetes / Interessantes:** 
<a name="l1145"><span class="ln">1145 </span></a>- `social_media_hours`: Höhere Werte (pink) liegen häufig auf der linken Seite → **mehr Nutzung senkt die vorhergesagte Leistung**. Das passt zu typischen Hypothesen, ist aber erfreulich klar sichtbar. 
<a name="l1146"><span class="ln">1146 </span></a>- `sleep_hours`: zeigt **ein gemischtes Bild**, was auf einen **nicht-linearen Zusammenhang** hinweist. Eventuell gibt es ein &quot;Optimum&quot; an Schlaf. 
<a name="l1147"><span class="ln">1147 </span></a>- `attendance_percentage` hat nur moderaten Einfluss, obwohl man eine stärkere Rolle vermuten könnte – eventuell, weil sie mit anderen Faktoren (z.B. Lernzeit) korreliert und das Modell daher den **direkteren Effekt bevorzugt**. 
<a name="l1148"><span class="ln">1148 </span></a> 
<a name="l1149"><span class="ln">1149 </span></a>**Fazit:** Die Summary-Darstellung hilft, plausible Zusammenhänge empirisch zu bestätigen. Gleichzeitig zeigt sie aber auch, dass manche vermeintlich „wichtige“ Merkmale (z.B. Ernährung, Elternbildung) **weniger Einfluss** haben als erwartet. 
<a name="l1150"><span class="ln">1150 </span></a> <hr class="ls0"><a name="l1151"><span class="ln">1151 </span></a>#%% md 
<a name="l1152"><span class="ln">1152 </span></a>### SHAP Dependence Plot – Lernzeit in Wechselwirkung mit Schlafdauer 
<a name="l1153"><span class="ln">1153 </span></a> 
<a name="l1154"><span class="ln">1154 </span></a>**Methode:** Darstellung der SHAP-Werte für `study_hours_per_day`, gefärbt nach `sleep_hours`, um Interaktionen visuell erkennbar zu machen. 
<a name="l1155"><span class="ln">1155 </span></a> 
<a name="l1156"><span class="ln">1156 </span></a>**Ziel:** Sichtbarmachung des Zusammenhangs zwischen Lernverhalten und Modellvorhersage, sowie möglicher Verstärker oder Dämpfungseffekte durch Schlafverhalten. 
<a name="l1157"><span class="ln">1157 </span></a> 
<a name="l1158"><span class="ln">1158 </span></a>**Erwartungsgemäße Befunde:** 
<a name="l1159"><span class="ln">1159 </span></a>- Der lineare Anstieg der SHAP-Werte mit steigender Lernzeit ist logisch. Jede zusätzliche Lernstunde wirkt sich **gleichmäßig positiv** auf die vorhergesagte Leistung aus. 
<a name="l1160"><span class="ln">1160 </span></a>- Die Farbskala (Interaktion mit Schlafdauer) zeigt einen subtilen Effekt: Bei höherem Schlaf (pink) ist der Lernzeit-Effekt leicht verstärkt. Auch das passt zum allgemeinen Verständnis von Leistungsförderung. 
<a name="l1161"><span class="ln">1161 </span></a> 
<a name="l1162"><span class="ln">1162 </span></a>**Unerwartetes / Auffälliges:** 
<a name="l1163"><span class="ln">1163 </span></a>- Die lineare Beziehung ist **außergewöhnlich klar**. In der Realität wären abnehmende Grenzerträge (z.B. Ermüdung bei &gt;6h Lernen) denkbar. Das Modell bildet solche **nicht-linearen Schwellen** hier nicht ab, was an der Einfachheit der linearen Regression liegen kann. 
<a name="l1164"><span class="ln">1164 </span></a>- Die Schlafinteraktion ist **relativ schwach**, eventuell müsste sie explizit modelliert werden (z.B. als Interaktionsterm), um differenziertere Effekte abzubilden. 
<a name="l1165"><span class="ln">1165 </span></a> 
<a name="l1166"><span class="ln">1166 </span></a>**Fazit:** Der Plot zeigt eine starke und erwartbare Haupteffektbeziehung – und eine leichte, aber potenziell optimierbare Interaktion. 
<a name="l1167"><span class="ln">1167 </span></a> <hr class="ls0"><a name="l1168"><span class="ln">1168 </span></a>#%% 
<a name="l1169"><span class="ln">1169 </span></a></span>
<a name="l1170"><span class="ln">1170 </span></a>
<a name="l1171"><span class="ln">1171 </span></a><span class="s2"># 1. SHAP vorbereiten</span>
<a name="l1172"><span class="ln">1172 </span></a><span class="s0">preprocessor_rf = model_pipeline_rf.named_steps[</span><span class="s3">&quot;preprocessing&quot;</span><span class="s0">]</span>
<a name="l1173"><span class="ln">1173 </span></a><span class="s0">model_rf = model_pipeline_rf.named_steps[</span><span class="s3">&quot;regressor&quot;</span><span class="s0">]</span>
<a name="l1174"><span class="ln">1174 </span></a><span class="s0">X_test_transformed_rf = preprocessor_rf.transform(X_test)</span>
<a name="l1175"><span class="ln">1175 </span></a><span class="s0">feature_names_rf = preprocessor_rf.get_feature_names_out()</span>
<a name="l1176"><span class="ln">1176 </span></a>
<a name="l1177"><span class="ln">1177 </span></a><span class="s2"># 2. Feature-Namen bereinigen</span>
<a name="l1178"><span class="ln">1178 </span></a><span class="s1">def </span><span class="s0">simplify_feature_names(feature_names):</span>
<a name="l1179"><span class="ln">1179 </span></a>    <span class="s1">return </span><span class="s0">[name.replace(</span><span class="s3">&quot;cat__&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s0">).replace(</span><span class="s3">&quot;remainder__&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s0">) </span><span class="s1">for </span><span class="s0">name </span><span class="s1">in </span><span class="s0">feature_names]</span>
<a name="l1180"><span class="ln">1180 </span></a>
<a name="l1181"><span class="ln">1181 </span></a><span class="s0">feature_names_clean_rf = simplify_feature_names(feature_names_rf)</span>
<a name="l1182"><span class="ln">1182 </span></a>
<a name="l1183"><span class="ln">1183 </span></a><span class="s2"># 3. SHAP-Werte berechnen (für Random Forest)</span>
<a name="l1184"><span class="ln">1184 </span></a><span class="s0">explainer_rf = shap.Explainer(model_rf, X_test_transformed_rf)</span>
<a name="l1185"><span class="ln">1185 </span></a><span class="s0">shap_values_rf = explainer_rf(X_test_transformed_rf, check_additivity=</span><span class="s1">False</span><span class="s0">).values</span>
<a name="l1186"><span class="ln">1186 </span></a>
<a name="l1187"><span class="ln">1187 </span></a><span class="s2"># 4. Barplot – mittlere absolute SHAP-Werte</span>
<a name="l1188"><span class="ln">1188 </span></a><span class="s0">shap_df_rf = pd.DataFrame(np.abs(shap_values_rf), columns=feature_names_clean_rf)</span>
<a name="l1189"><span class="ln">1189 </span></a><span class="s0">shap_summary_rf = shap_df_rf.mean().sort_values(ascending=</span><span class="s1">True</span><span class="s0">)</span>
<a name="l1190"><span class="ln">1190 </span></a>
<a name="l1191"><span class="ln">1191 </span></a><span class="s0">plt.figure(figsize=(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">6</span><span class="s0">))</span>
<a name="l1192"><span class="ln">1192 </span></a><span class="s0">shap_summary_rf.plot(kind=</span><span class="s3">'barh'</span><span class="s0">, color=</span><span class="s3">'seagreen'</span><span class="s0">)</span>
<a name="l1193"><span class="ln">1193 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Barplot – Mittlere absolute SHAP-Werte (Random Forest)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1194"><span class="ln">1194 </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Mittlerer absoluter SHAP-Wert&quot;</span><span class="s0">)</span>
<a name="l1195"><span class="ln">1195 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1196"><span class="ln">1196 </span></a><span class="s0">plt.show()</span>
<a name="l1197"><span class="ln">1197 </span></a>
<a name="l1198"><span class="ln">1198 </span></a><span class="s2"># 5. SHAP Summary Plot</span>
<a name="l1199"><span class="ln">1199 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Summary Plot – Featurewirkung und -verteilung (Random Forest)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1200"><span class="ln">1200 </span></a><span class="s0">shap.summary_plot(</span>
<a name="l1201"><span class="ln">1201 </span></a>    <span class="s0">shap_values_rf,</span>
<a name="l1202"><span class="ln">1202 </span></a>    <span class="s0">X_test_transformed_rf,</span>
<a name="l1203"><span class="ln">1203 </span></a>    <span class="s0">feature_names=feature_names_clean_rf</span>
<a name="l1204"><span class="ln">1204 </span></a><span class="s0">)</span>
<a name="l1205"><span class="ln">1205 </span></a>
<a name="l1206"><span class="ln">1206 </span></a><span class="s2"># 6a. Dependence Plot: study_hours_per_day abhängig von sleep_hours</span>
<a name="l1207"><span class="ln">1207 </span></a><span class="s0">shap.dependence_plot(</span>
<a name="l1208"><span class="ln">1208 </span></a>    <span class="s0">ind=</span><span class="s3">&quot;remainder__study_hours_per_day&quot;</span><span class="s0">,</span>
<a name="l1209"><span class="ln">1209 </span></a>    <span class="s0">shap_values=shap_values_rf,</span>
<a name="l1210"><span class="ln">1210 </span></a>    <span class="s0">features=X_test_transformed_rf,</span>
<a name="l1211"><span class="ln">1211 </span></a>    <span class="s0">feature_names=feature_names_rf,</span>
<a name="l1212"><span class="ln">1212 </span></a>    <span class="s0">interaction_index=</span><span class="s3">&quot;remainder__sleep_hours&quot;</span><span class="s0">,</span>
<a name="l1213"><span class="ln">1213 </span></a>    <span class="s0">show=</span><span class="s1">False</span>
<a name="l1214"><span class="ln">1214 </span></a><span class="s0">)</span>
<a name="l1215"><span class="ln">1215 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Dependence Plot – Lernzeit abhängig vom Schlaf (Random Forest)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1216"><span class="ln">1216 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1217"><span class="ln">1217 </span></a><span class="s0">plt.show()</span>
<a name="l1218"><span class="ln">1218 </span></a>
<a name="l1219"><span class="ln">1219 </span></a><span class="s2"># 6b. Dependence Plot: mental_health_rating abhängig von study_hours_per_day</span>
<a name="l1220"><span class="ln">1220 </span></a><span class="s0">shap.dependence_plot(</span>
<a name="l1221"><span class="ln">1221 </span></a>    <span class="s0">ind=</span><span class="s3">&quot;remainder__mental_health_rating&quot;</span><span class="s0">,</span>
<a name="l1222"><span class="ln">1222 </span></a>    <span class="s0">shap_values=shap_values_rf,</span>
<a name="l1223"><span class="ln">1223 </span></a>    <span class="s0">features=X_test_transformed_rf,</span>
<a name="l1224"><span class="ln">1224 </span></a>    <span class="s0">feature_names=feature_names_rf,</span>
<a name="l1225"><span class="ln">1225 </span></a>    <span class="s0">interaction_index=</span><span class="s3">&quot;remainder__study_hours_per_day&quot;</span><span class="s0">,</span>
<a name="l1226"><span class="ln">1226 </span></a>    <span class="s0">show=</span><span class="s1">False</span>
<a name="l1227"><span class="ln">1227 </span></a><span class="s0">)</span>
<a name="l1228"><span class="ln">1228 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;SHAP Dependence Plot – Mentale Gesundheit abhängig von Lernzeit (Random Forest)&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1229"><span class="ln">1229 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1230"><span class="ln">1230 </span></a><span class="s0">plt.show()</span>
<a name="l1231"><span class="ln">1231 </span></a><hr class="ls0"><a name="l1232"><span class="ln">1232 </span></a><span class="s0">#%% md 
<a name="l1233"><span class="ln">1233 </span></a>### SHAP Barplot – Globale Bedeutung der Merkmale (Random Forest) 
<a name="l1234"><span class="ln">1234 </span></a> 
<a name="l1235"><span class="ln">1235 </span></a>**Methode:** Diese Visualisierung basiert auf SHAP (SHapley Additive exPlanations). Für jedes Merkmal wird der mittlere absolute Einfluss auf die Modellvorhersage berechnet d.h. wie stark ein Merkmal über alle Testbeobachtungen hinweg zur Prognose beiträgt. 
<a name="l1236"><span class="ln">1236 </span></a> 
<a name="l1237"><span class="ln">1237 </span></a>**Ziel:** Die globale Wichtigkeit von Features innerhalb des Random-Forest-Modells sichtbar machen. 
<a name="l1238"><span class="ln">1238 </span></a> 
<a name="l1239"><span class="ln">1239 </span></a>**Erwartet:** 
<a name="l1240"><span class="ln">1240 </span></a>- `study_hours_per_day` ist mit großem Abstand das wichtigste Merkmal konsistent mit der linearen Regression. 
<a name="l1241"><span class="ln">1241 </span></a>- `mental_health_rating` ist ebenfalls sehr bedeutsam. Mentale Stabilität scheint in beiden Modellarten ein Schlüsselfaktor für Prüfungsleistung zu sein. 
<a name="l1242"><span class="ln">1242 </span></a> 
<a name="l1243"><span class="ln">1243 </span></a>**Unerwartet / Bemerkenswert:** 
<a name="l1244"><span class="ln">1244 </span></a>- Der Einfluss struktureller Merkmale (z.B. `parental_education_level`, `gender`) bleibt sehr gering, obwohl Random Forest auch Interaktionen abbilden kann. 
<a name="l1245"><span class="ln">1245 </span></a>- `sleep_hours` und `exercise_frequency` gewinnen im Vergleich zum linearen Modell leicht an Bedeutung. Das spricht für nicht-lineare Wechselwirkungen, die dort nicht modelliert wurden. 
<a name="l1246"><span class="ln">1246 </span></a> 
<a name="l1247"><span class="ln">1247 </span></a>**Fazit:** Der Random Forest erkennt ähnliche Haupttreiber wie das lineare Modell, gewichtet aber einzelne sekundäre Merkmale leicht anders. SHAP macht diese Nuancen transparent und nachvollziehbar. 
<a name="l1248"><span class="ln">1248 </span></a> <hr class="ls0"><a name="l1249"><span class="ln">1249 </span></a>#%% md 
<a name="l1250"><span class="ln">1250 </span></a>### SHAP Summary Plot – Verteilung und Richtung der Merkmalseffekte (Random Forest) 
<a name="l1251"><span class="ln">1251 </span></a> 
<a name="l1252"><span class="ln">1252 </span></a>**Methode:** Jeder Punkt stellt den Einfluss eines Merkmals auf die Modellvorhersage für eine einzelne Testinstanz dar. Die Farbe gibt die Merkmalsausprägung an (hoch = pink, niedrig = blau), die horizontale Lage zeigt, ob der Einfluss positiv oder negativ war. 
<a name="l1253"><span class="ln">1253 </span></a> 
<a name="l1254"><span class="ln">1254 </span></a>**Ziel:** Analyse, welche Merkmale in welcher Weise wirken  und ob sich **nicht-lineare Beziehungen oder Interaktionseffekte** zeigen. 
<a name="l1255"><span class="ln">1255 </span></a> 
<a name="l1256"><span class="ln">1256 </span></a>**Erwartet:** 
<a name="l1257"><span class="ln">1257 </span></a>- `study_hours_per_day`: Deutlich positiver Effekt bei hohen Werten. 
<a name="l1258"><span class="ln">1258 </span></a>- `mental_health_rating`: Ebenfalls wie erwartet positiver Zusammenhang. 
<a name="l1259"><span class="ln">1259 </span></a> 
<a name="l1260"><span class="ln">1260 </span></a>**Unerwartet / Interessant:** 
<a name="l1261"><span class="ln">1261 </span></a>- `social_media_hours`: Die Verteilung ist deutlich asymmetrisch – hohe Werte (pink) führen meist zu negativen SHAP-Werten, was auf **Ablenkungspotenzial** hinweist. 
<a name="l1262"><span class="ln">1262 </span></a>- `sleep_hours`: Farblich gemischt über das gesamte SHAP-Wertspektrum → ein Hinweis auf ein **nicht-monotones Verhalten** (z.B. zu viel Schlaf kann ebenso schaden wie zu wenig). 
<a name="l1263"><span class="ln">1263 </span></a>- Der Plot zeigt insgesamt deutlich mehr **Streuung und komplexe Muster** als im linearen Modell. Typisch für Random Forest. 
<a name="l1264"><span class="ln">1264 </span></a> 
<a name="l1265"><span class="ln">1265 </span></a>**Fazit:** Der Summary Plot macht sichtbar, dass der Random Forest nicht nur lineare Zusammenhänge erkennt, sondern auch **nicht-lineare Wechselwirkungen zwischen Features**. SHAP übersetzt diese komplexen Muster in verständliche Visualisierungen. 
<a name="l1266"><span class="ln">1266 </span></a> <hr class="ls0"><a name="l1267"><span class="ln">1267 </span></a>#%% md 
<a name="l1268"><span class="ln">1268 </span></a>### SHAP Dependence Plot – Lernzeit in Wechselwirkung mit Schlafdauer (Random Forest) 
<a name="l1269"><span class="ln">1269 </span></a> 
<a name="l1270"><span class="ln">1270 </span></a>**Methode:** Darstellung des SHAP-Werts für `study_hours_per_day` über alle Instanzen hinweg. Die Punkte sind eingefärbt nach `sleep_hours`, um mögliche Interaktionseffekte zu erkennen. 
<a name="l1271"><span class="ln">1271 </span></a> 
<a name="l1272"><span class="ln">1272 </span></a>**Ziel:** Herausfinden, ob der Zusammenhang zwischen Lernzeit und Leistung linear bleibt – oder ob sich z.B. Sättigungseffekte zeigen. 
<a name="l1273"><span class="ln">1273 </span></a> 
<a name="l1274"><span class="ln">1274 </span></a>**Erwartet:** 
<a name="l1275"><span class="ln">1275 </span></a>- Der SHAP-Wert steigt mit zunehmender Lernzeit – je mehr gelernt wird, desto besser ist die Vorhersage. 
<a name="l1276"><span class="ln">1276 </span></a> 
<a name="l1277"><span class="ln">1277 </span></a>**Unerwartet / Auffällig:** 
<a name="l1278"><span class="ln">1278 </span></a>- Der Anstieg ist nicht streng linear: Zwischen ca. 5 und 6 Stunden flacht der Effekt ab, bei ca. 6–7 Stunden wirkt er instabil → **Hinweis auf abnehmende Grenznutzen**. 
<a name="l1279"><span class="ln">1279 </span></a>- Die Farbverläufe zeigen, dass viel Schlaf tendenziell den positiven Effekt unterstützt – allerdings ist der Effekt weniger klar als beim linearen Modell. 
<a name="l1280"><span class="ln">1280 </span></a> 
<a name="l1281"><span class="ln">1281 </span></a>**Fazit:** Random Forest erlaubt ein differenzierteres Verständnis darüber, **wann Lernzeit ihre Wirkung verliert**. SHAP zeigt: Lernzeit ist wichtig – aber nicht unbegrenzt. 
<a name="l1282"><span class="ln">1282 </span></a> <hr class="ls0"><a name="l1283"><span class="ln">1283 </span></a>#%% md 
<a name="l1284"><span class="ln">1284 </span></a>### SHAP Dependence Plot – Mentale Gesundheit in Wechselwirkung mit Lernverhalten (Random Forest) 
<a name="l1285"><span class="ln">1285 </span></a> 
<a name="l1286"><span class="ln">1286 </span></a>**Methode:** SHAP-Werte für `mental_health_rating` werden dargestellt, eingefärbt nach `study_hours_per_day`. 
<a name="l1287"><span class="ln">1287 </span></a> 
<a name="l1288"><span class="ln">1288 </span></a>**Ziel:** Untersuchung, wie stark mentale Gesundheit den Output beeinflusst – und ob dies abhängig vom Lernverhalten variiert. 
<a name="l1289"><span class="ln">1289 </span></a> 
<a name="l1290"><span class="ln">1290 </span></a>**Erwartet:** 
<a name="l1291"><span class="ln">1291 </span></a>- Positiver Zusammenhang: Je besser die mentale Verfassung, desto höher fällt die vorhergesagte Prüfungsleistung aus. 
<a name="l1292"><span class="ln">1292 </span></a> 
<a name="l1293"><span class="ln">1293 </span></a>**Unerwartet / Bemerkenswert:** 
<a name="l1294"><span class="ln">1294 </span></a>- Bei gleichem `mental_health_rating` zeigt sich deutliche Streuung in den SHAP-Werten – je nachdem, wie viel zusätzlich gelernt wurde. 
<a name="l1295"><span class="ln">1295 </span></a>→ Mentale Gesundheit entfaltet ihre Wirkung also besonders **in Verbindung mit aktivem Lernverhalten**. 
<a name="l1296"><span class="ln">1296 </span></a>- Ohne nennenswerte Lernzeit (blaue Punkte) bleibt der Effekt begrenzt. Psychisches Wohlbefinden allein reicht nicht aus, um hohe Leistungen zu prognostizieren. 
<a name="l1297"><span class="ln">1297 </span></a> 
<a name="l1298"><span class="ln">1298 </span></a>**Fazit:** Der Plot legt nahe, dass **mentale Gesundheit ein Verstärker, aber kein Ersatz für aktives Lernen** ist. Diese Differenzierung ist mit linearen Modellen schwer zu erfassen. SHAP plus Random Forest zeigen sie deutlich. 
<a name="l1299"><span class="ln">1299 </span></a> <hr class="ls0"><a name="l1300"><span class="ln">1300 </span></a>#%% md 
<a name="l1301"><span class="ln">1301 </span></a># Vergleich der erklärbaren Modelle: Lineare Regression vs. Random Forest 
<a name="l1302"><span class="ln">1302 </span></a> 
<a name="l1303"><span class="ln">1303 </span></a>**Ziel des Vergleichs:** 
<a name="l1304"><span class="ln">1304 </span></a>Beide Modelle wurden hinsichtlich ihrer erklärbaren Struktur mittels SHAP analysiert. Während die lineare Regression als **White-Box-Modell** per se interpretierbar ist, stellt der Random Forest ein **Black-Box-Modell** dar, das nur durch XAI-Methoden wie SHAP erklärbar gemacht werden kann. 
<a name="l1305"><span class="ln">1305 </span></a> 
<a name="l1306"><span class="ln">1306 </span></a>**Gemeinsamkeiten:** 
<a name="l1307"><span class="ln">1307 </span></a>- In beiden Modellen zeigt sich `study_hours_per_day` als wichtigstes Merkmal. Ein stabiler, domänenplausibler Haupteffekt. 
<a name="l1308"><span class="ln">1308 </span></a>- Auch `mental_health_rating` und `social_media_hours` sind in beiden Fällen erklärungsrelevant, was für eine gewisse **Modellrobustheit** spricht. 
<a name="l1309"><span class="ln">1309 </span></a> 
<a name="l1310"><span class="ln">1310 </span></a>**Unterschiede:** 
<a name="l1311"><span class="ln">1311 </span></a>- Die lineare Regression zeigt klare, oft monotone Effekte (z.B. linearer Anstieg mit Lernzeit), wohingegen der Random Forest **nicht-lineare Muster** und **abnehmende Grenznutzen** (z.B. bei Lernzeit oder Schlaf) sichtbar macht. 
<a name="l1312"><span class="ln">1312 </span></a>- Der Random Forest erkennt auch **komplexe Interaktionen**: z.B. die verstärkte Wirkung von mentaler Gesundheit bei hoher Lernzeit, ein Effekt der im linearen Modell nicht deutlich wurde. 
<a name="l1313"><span class="ln">1313 </span></a>- Die Summary Plots des Random Forest zeigen eine deutlich **breitere Streuung**, was auf eine **größere Modellflexibilität** bei der Berücksichtigung individueller Fallkontexte hinweist. 
<a name="l1314"><span class="ln">1314 </span></a> 
<a name="l1315"><span class="ln">1315 </span></a>**Fazit:** 
<a name="l1316"><span class="ln">1316 </span></a>Der Einsatz von SHAP erlaubt es, sowohl das simple lineare Modell als auch den komplexeren Random Forest auf ein gemeinsames Erklärbarkeitsniveau zu bringen. 
<a name="l1317"><span class="ln">1317 </span></a>Während die lineare Regression eher **globale Tendenzen** sichtbar macht, zeigt der Random Forest, unterstützt durch SHAP, auch **lokale und nicht-lineare Zusammenhänge**, die für datengestützte Hypothesenbildung besonders wertvoll sind. 
<a name="l1318"><span class="ln">1318 </span></a> <hr class="ls0"><a name="l1319"><span class="ln">1319 </span></a>#%% 
<a name="l1320"><span class="ln">1320 </span></a></span>
<a name="l1321"><span class="ln">1321 </span></a><span class="s2"># DataFrames mit mittleren SHAP-Werten (bereits berechnet)</span>
<a name="l1322"><span class="ln">1322 </span></a><span class="s2"># Stelle sicher, dass shap_summary_full und shap_summary_rf vorhanden sind</span>
<a name="l1323"><span class="ln">1323 </span></a><span class="s2"># und jeweils ein pd.Series mit gleichen Indexnamen (Feature-Namen) darstellen</span>
<a name="l1324"><span class="ln">1324 </span></a>
<a name="l1325"><span class="ln">1325 </span></a><span class="s2"># Beispiel:</span>
<a name="l1326"><span class="ln">1326 </span></a><span class="s2"># shap_summary_full = pd.Series([...], name=&quot;Lineare Regression&quot;)</span>
<a name="l1327"><span class="ln">1327 </span></a><span class="s2"># shap_summary_rf = pd.Series([...], name=&quot;Random Forest&quot;)</span>
<a name="l1328"><span class="ln">1328 </span></a>
<a name="l1329"><span class="ln">1329 </span></a><span class="s2"># Gemeinsamer DataFrame zum Vergleich</span>
<a name="l1330"><span class="ln">1330 </span></a><span class="s0">df_compare = pd.DataFrame({</span>
<a name="l1331"><span class="ln">1331 </span></a>    <span class="s3">&quot;Lineare Regression&quot;</span><span class="s0">: shap_summary_full,</span>
<a name="l1332"><span class="ln">1332 </span></a>    <span class="s3">&quot;Random Forest&quot;</span><span class="s0">: shap_summary_rf</span>
<a name="l1333"><span class="ln">1333 </span></a><span class="s0">}).dropna()</span>
<a name="l1334"><span class="ln">1334 </span></a>
<a name="l1335"><span class="ln">1335 </span></a><span class="s2"># Sortieren nach linearer Regression für konsistente Reihenfolge</span>
<a name="l1336"><span class="ln">1336 </span></a><span class="s0">df_compare = df_compare.sort_values(</span><span class="s3">&quot;Lineare Regression&quot;</span><span class="s0">, ascending=</span><span class="s1">True</span><span class="s0">)</span>
<a name="l1337"><span class="ln">1337 </span></a>
<a name="l1338"><span class="ln">1338 </span></a><span class="s2"># Barplot</span>
<a name="l1339"><span class="ln">1339 </span></a><span class="s0">ax = df_compare.plot(</span>
<a name="l1340"><span class="ln">1340 </span></a>    <span class="s0">kind=</span><span class="s3">&quot;barh&quot;</span><span class="s0">,</span>
<a name="l1341"><span class="ln">1341 </span></a>    <span class="s0">figsize=(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">6</span><span class="s0">),</span>
<a name="l1342"><span class="ln">1342 </span></a>    <span class="s0">color=[</span><span class="s3">&quot;cornflowerblue&quot;</span><span class="s0">, </span><span class="s3">&quot;seagreen&quot;</span><span class="s0">]</span>
<a name="l1343"><span class="ln">1343 </span></a><span class="s0">)</span>
<a name="l1344"><span class="ln">1344 </span></a>
<a name="l1345"><span class="ln">1345 </span></a><span class="s0">plt.title(</span><span class="s3">&quot;Vergleich der mittleren SHAP-Werte: Lineare Regression vs. Random Forest&quot;</span><span class="s0">, fontsize=</span><span class="s4">14</span><span class="s0">)</span>
<a name="l1346"><span class="ln">1346 </span></a><span class="s0">plt.xlabel(</span><span class="s3">&quot;Mittlerer SHAP-Wert&quot;</span><span class="s0">)</span>
<a name="l1347"><span class="ln">1347 </span></a><span class="s0">plt.legend(loc=</span><span class="s3">&quot;lower right&quot;</span><span class="s0">)</span>
<a name="l1348"><span class="ln">1348 </span></a><span class="s0">plt.tight_layout()</span>
<a name="l1349"><span class="ln">1349 </span></a><span class="s0">plt.show()</span>
<a name="l1350"><span class="ln">1350 </span></a><hr class="ls0"><a name="l1351"><span class="ln">1351 </span></a><span class="s0">#%% md 
<a name="l1352"><span class="ln">1352 </span></a>### Vergleich der globalen SHAP-Werte – Lineare Regression vs. Random Forest 
<a name="l1353"><span class="ln">1353 </span></a> 
<a name="l1354"><span class="ln">1354 </span></a>**Ziel:** 
<a name="l1355"><span class="ln">1355 </span></a>Diese Visualisierung zeigt die mittleren absoluten SHAP-Werte der einzelnen Merkmale in beiden Modellen – nebeneinander dargestellt. So lässt sich direkt erkennen, ob die Modelle zu ähnlichen Einschätzungen kommen oder bestimmte Einflussgrößen unterschiedlich bewerten. 
<a name="l1356"><span class="ln">1356 </span></a> 
<a name="l1357"><span class="ln">1357 </span></a>**Interpretation:** 
<a name="l1358"><span class="ln">1358 </span></a>- Beide Modelle identifizieren `study_hours_per_day` als dominantestes Merkmal – das unterstreicht die Robustheit dieses Zusammenhangs. 
<a name="l1359"><span class="ln">1359 </span></a>- Auch `mental_health_rating` ist in beiden Modellen stark gewichtet, jedoch in der linearen Regression noch etwas deutlicher – was für einen konsistent linearen Effekt spricht. 
<a name="l1360"><span class="ln">1360 </span></a>- `social_media_hours` und `exercise_frequency` werden im linearen Modell stärker betont, während beim Random Forest `diet_quality_Good` und `sleep_hours` etwas mehr Gewicht erhalten. 
<a name="l1361"><span class="ln">1361 </span></a>- Merkmale wie `gender`, `internet_quality` oder `parental_education_level` spielen in beiden Modellen eine untergeordnete Rolle. 
<a name="l1362"><span class="ln">1362 </span></a> 
<a name="l1363"><span class="ln">1363 </span></a>**Fazit:** 
<a name="l1364"><span class="ln">1364 </span></a>Das Ergebnis zeigt, dass beide Modelle zwar zentrale Einflussfaktoren ähnlich erkennen, der Random Forest aber auch **nicht-lineare Muster und subtilere Zusammenhänge** berücksichtigt, was sich in leicht abweichenden Gewichtungen niederschlägt. Die lineare Regression legt den Fokus auf **starke, direkt lineare Beziehungen**, während der Random Forest auch **kontextuelle oder kombinierte Effekte** erfasst. 
<a name="l1365"><span class="ln">1365 </span></a> <hr class="ls0"><a name="l1366"><span class="ln">1366 </span></a>#%% md 
<a name="l1367"><span class="ln">1367 </span></a># Schwellenwertanalyse einzelner Merkmale 
<a name="l1368"><span class="ln">1368 </span></a> 
<a name="l1369"><span class="ln">1369 </span></a>In diesem Abschnitt untersuche ich, **ab wann ein Merkmal einen positiven oder negativen Einfluss auf die Modellvorhersage hat** – und ob es möglicherweise Schwellenwerte oder Wendepunkte gibt, ab denen sich der Effekt umkehrt. 
<a name="l1370"><span class="ln">1370 </span></a> 
<a name="l1371"><span class="ln">1371 </span></a>Dazu wird der Zusammenhang zwischen dem **Merkmalswert** (x-Achse) und dem dazugehörigen **SHAP-Wert** (y-Achse) visualisiert. 
<a name="l1372"><span class="ln">1372 </span></a>Der SHAP-Wert zeigt, **wie stark und in welche Richtung** das jeweilige Merkmal die Modellvorhersage verändert. 
<a name="l1373"><span class="ln">1373 </span></a> 
<a name="l1374"><span class="ln">1374 </span></a>**Ziel:** 
<a name="l1375"><span class="ln">1375 </span></a>Nicht nur zu wissen, dass ein Merkmal wichtig ist, sondern **wie genau es wirkt**. Gibt es z.B. eine Schlafdauer, bei der sich der Einfluss auf die Leistung ändert? Oder einen Punkt, an dem zu viel Lernen nicht mehr hilft? 
<a name="l1376"><span class="ln">1376 </span></a> 
<a name="l1377"><span class="ln">1377 </span></a>Die nachfolgende Visualisierung liefert eine erste datenbasierte Antwort auf solche Fragen. 
<a name="l1378"><span class="ln">1378 </span></a> <hr class="ls0"><a name="l1379"><span class="ln">1379 </span></a>#%% 
<a name="l1380"><span class="ln">1380 </span></a></span>
<a name="l1381"><span class="ln">1381 </span></a><span class="s2"># Nur numerische, kontinuierliche Features visualisieren</span>
<a name="l1382"><span class="ln">1382 </span></a><span class="s1">for </span><span class="s0">i, original_name </span><span class="s1">in </span><span class="s0">enumerate(feature_names_rf):</span>
<a name="l1383"><span class="ln">1383 </span></a>
<a name="l1384"><span class="ln">1384 </span></a>    <span class="s2"># Feature-Name vereinfachen</span>
<a name="l1385"><span class="ln">1385 </span></a>    <span class="s0">simplified_name = original_name.replace(</span><span class="s3">&quot;remainder__&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s0">).replace(</span><span class="s3">&quot;cat__&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s0">)</span>
<a name="l1386"><span class="ln">1386 </span></a>
<a name="l1387"><span class="ln">1387 </span></a>    <span class="s0">shap_values_single = shap_values_rf[:, i]</span>
<a name="l1388"><span class="ln">1388 </span></a>    <span class="s0">feature_values = X_test_transformed_rf[:, i]</span>
<a name="l1389"><span class="ln">1389 </span></a>
<a name="l1390"><span class="ln">1390 </span></a>    <span class="s2"># Erkenne kontinuierliche Features</span>
<a name="l1391"><span class="ln">1391 </span></a>    <span class="s0">unique_vals = np.unique(feature_values)</span>
<a name="l1392"><span class="ln">1392 </span></a>    <span class="s0">is_continuous = len(unique_vals) &gt; </span><span class="s4">6 </span><span class="s1">and not </span><span class="s0">np.all(np.isin(unique_vals, [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">]))</span>
<a name="l1393"><span class="ln">1393 </span></a>
<a name="l1394"><span class="ln">1394 </span></a>    <span class="s1">if </span><span class="s0">is_continuous:</span>
<a name="l1395"><span class="ln">1395 </span></a>        <span class="s0">df_plot = pd.DataFrame({</span>
<a name="l1396"><span class="ln">1396 </span></a>            <span class="s0">simplified_name: feature_values,</span>
<a name="l1397"><span class="ln">1397 </span></a>            <span class="s3">&quot;SHAP-Wert&quot;</span><span class="s0">: shap_values_single</span>
<a name="l1398"><span class="ln">1398 </span></a>        <span class="s0">}).sort_values(by=simplified_name)</span>
<a name="l1399"><span class="ln">1399 </span></a>
<a name="l1400"><span class="ln">1400 </span></a>        <span class="s2"># Gleitender Mittelwert als Trendlinie</span>
<a name="l1401"><span class="ln">1401 </span></a>        <span class="s0">df_plot[</span><span class="s3">&quot;Trend&quot;</span><span class="s0">] = df_plot[</span><span class="s3">&quot;SHAP-Wert&quot;</span><span class="s0">].rolling(window=</span><span class="s4">30</span><span class="s0">, center=</span><span class="s1">True</span><span class="s0">).mean()</span>
<a name="l1402"><span class="ln">1402 </span></a>
<a name="l1403"><span class="ln">1403 </span></a>        <span class="s0">plt.figure(figsize=(</span><span class="s4">8</span><span class="s0">, </span><span class="s4">5</span><span class="s0">))</span>
<a name="l1404"><span class="ln">1404 </span></a>        <span class="s0">plt.scatter(df_plot[simplified_name], df_plot[</span><span class="s3">&quot;SHAP-Wert&quot;</span><span class="s0">], alpha=</span><span class="s4">0.3</span><span class="s0">, s=</span><span class="s4">20</span><span class="s0">, label=</span><span class="s3">&quot;Einzelne SHAP-Werte&quot;</span><span class="s0">)</span>
<a name="l1405"><span class="ln">1405 </span></a>        <span class="s0">plt.plot(df_plot[simplified_name], df_plot[</span><span class="s3">&quot;Trend&quot;</span><span class="s0">], color=</span><span class="s3">&quot;crimson&quot;</span><span class="s0">, label=</span><span class="s3">&quot;Trendlinie (mittlerer Verlauf)&quot;</span><span class="s0">)</span>
<a name="l1406"><span class="ln">1406 </span></a>        <span class="s0">plt.axhline(</span><span class="s4">0</span><span class="s0">, linestyle=</span><span class="s3">&quot;--&quot;</span><span class="s0">, color=</span><span class="s3">&quot;gray&quot;</span><span class="s0">)</span>
<a name="l1407"><span class="ln">1407 </span></a>
<a name="l1408"><span class="ln">1408 </span></a>        <span class="s0">plt.title(</span><span class="s3">f&quot;Schwellenwertanalyse – '</span><span class="s5">{</span><span class="s0">simplified_name</span><span class="s5">}</span><span class="s3">'&quot;</span><span class="s0">, fontsize=</span><span class="s4">13</span><span class="s0">)</span>
<a name="l1409"><span class="ln">1409 </span></a>        <span class="s0">plt.xlabel(simplified_name)</span>
<a name="l1410"><span class="ln">1410 </span></a>        <span class="s0">plt.ylabel(</span><span class="s3">&quot;SHAP-Wert (Einfluss auf Modelloutput)&quot;</span><span class="s0">)</span>
<a name="l1411"><span class="ln">1411 </span></a>        <span class="s0">plt.legend()</span>
<a name="l1412"><span class="ln">1412 </span></a>        <span class="s0">plt.tight_layout()</span>
<a name="l1413"><span class="ln">1413 </span></a>        <span class="s0">plt.show()</span>
<a name="l1414"><span class="ln">1414 </span></a><hr class="ls0"><a name="l1415"><span class="ln">1415 </span></a><span class="s0">#%% md 
<a name="l1416"><span class="ln">1416 </span></a>## Schwellenwertanalyse: Einflussverlauf und Nullschnitt numerischer Merkmale 
<a name="l1417"><span class="ln">1417 </span></a> 
<a name="l1418"><span class="ln">1418 </span></a>In dieser Analyse betrachten wir die Richtung und Intensität des Einflusses numerischer Features auf die Modellvorhersage mithilfe von SHAP-Werten. Besonderes Augenmerk liegt darauf, **wo genau ein Merkmal seinen Einfluss von negativ zu positiv wechselt** – also den **Nullpunkt** (SHAP = 0) überschreitet. 
<a name="l1419"><span class="ln">1419 </span></a> 
<a name="l1420"><span class="ln">1420 </span></a>Die Diagramme zeigen: 
<a name="l1421"><span class="ln">1421 </span></a> 
<a name="l1422"><span class="ln">1422 </span></a>- **Punkte:** einzelne SHAP-Werte (Einfluss pro Person) 
<a name="l1423"><span class="ln">1423 </span></a>- **Rote Linie:** geglätteter Mittelwertverlauf 
<a name="l1424"><span class="ln">1424 </span></a>- **Grau gestrichelte Linie:** SHAP = 0 → **kein Einfluss auf die Modellvorhersage** 
<a name="l1425"><span class="ln">1425 </span></a> 
<a name="l1426"><span class="ln">1426 </span></a>--- 
<a name="l1427"><span class="ln">1427 </span></a> 
<a name="l1428"><span class="ln">1428 </span></a>### 🔹 `study_hours_per_day` 
<a name="l1429"><span class="ln">1429 </span></a>- **Verlauf:** Stetig zunehmender positiver Einfluss. 
<a name="l1430"><span class="ln">1430 </span></a>- **SHAP-Wert = 0 bei:** **ca. 3.0 Stunden** 
<a name="l1431"><span class="ln">1431 </span></a>- **Interpretation:** Ab 3 Lernstunden täglich wirkt sich das Feature positiv auf die vorhergesagte Leistung aus. Darunter ist der Einfluss eher negativ (zu wenig lernen = leistungsmindernd). 
<a name="l1432"><span class="ln">1432 </span></a> 
<a name="l1433"><span class="ln">1433 </span></a>--- 
<a name="l1434"><span class="ln">1434 </span></a> 
<a name="l1435"><span class="ln">1435 </span></a>### 🔹 `mental_health_rating` 
<a name="l1436"><span class="ln">1436 </span></a>- **Verlauf:** Zunächst negativ, dann stark positiv. 
<a name="l1437"><span class="ln">1437 </span></a>- **SHAP-Wert = 0 bei:** **genau bei 6** 
<a name="l1438"><span class="ln">1438 </span></a>- **Interpretation:** Ab einer mentalen Bewertung von 6 steigt der Einfluss auf die Vorhersage. Studierende mit schlechterer mentaler Gesundheit (&lt;6) sind tendenziell im Nachteil. 
<a name="l1439"><span class="ln">1439 </span></a> 
<a name="l1440"><span class="ln">1440 </span></a>--- 
<a name="l1441"><span class="ln">1441 </span></a> 
<a name="l1442"><span class="ln">1442 </span></a>### 🔹 `social_media_hours` 
<a name="l1443"><span class="ln">1443 </span></a>- **Verlauf:** Abnehmend, mit deutlich negativem Trend. 
<a name="l1444"><span class="ln">1444 </span></a>- **SHAP-Wert = 0 bei:** **ca. 1.7 Stunden** 
<a name="l1445"><span class="ln">1445 </span></a>- **Interpretation:** Bis etwa 1.7 Stunden Social Media ist der Einfluss noch leicht positiv/neutral, danach negativ. Übermäßiger Konsum wirkt sich leistungsmindernd aus. 
<a name="l1446"><span class="ln">1446 </span></a> 
<a name="l1447"><span class="ln">1447 </span></a>--- 
<a name="l1448"><span class="ln">1448 </span></a> 
<a name="l1449"><span class="ln">1449 </span></a>### 🔹 `exercise_frequency` 
<a name="l1450"><span class="ln">1450 </span></a>- **Verlauf:** Negativer Einfluss bei wenig Bewegung, positiver bei mehr Sport. 
<a name="l1451"><span class="ln">1451 </span></a>- **SHAP-Wert = 0 bei:** **ca. 3 Einheiten pro Woche** 
<a name="l1452"><span class="ln">1452 </span></a>- **Interpretation:** Unterhalb von 3 ist der Effekt eher neutral bis negativ. Ab 3 Trainingseinheiten pro Woche wirkt sich körperliche Aktivität positiv aus. 
<a name="l1453"><span class="ln">1453 </span></a> 
<a name="l1454"><span class="ln">1454 </span></a>--- 
<a name="l1455"><span class="ln">1455 </span></a> 
<a name="l1456"><span class="ln">1456 </span></a>### 🔹 `sleep_hours` 
<a name="l1457"><span class="ln">1457 </span></a>- **Verlauf:** Stetig zunehmender positiver Effekt. 
<a name="l1458"><span class="ln">1458 </span></a>- **SHAP-Wert = 0 bei:** **ca. 6.8 Stunden** 
<a name="l1459"><span class="ln">1459 </span></a>- **Interpretation:** Unter 7 Stunden hat Schlaf eher einen negativen Einfluss. Ab etwa 6.8–7 Stunden beginnt der positive Effekt auf die Vorhersage. 
<a name="l1460"><span class="ln">1460 </span></a> 
<a name="l1461"><span class="ln">1461 </span></a>--- 
<a name="l1462"><span class="ln">1462 </span></a> 
<a name="l1463"><span class="ln">1463 </span></a>### 🔹 `netflix_hours` 
<a name="l1464"><span class="ln">1464 </span></a>- **Verlauf:** Umgekehrte Tendenz – je mehr, desto negativer. 
<a name="l1465"><span class="ln">1465 </span></a>- **SHAP-Wert = 0 bei:** **ca. 1.0 Stunden** 
<a name="l1466"><span class="ln">1466 </span></a>- **Interpretation:** Bis ca. 1 Stunde Netflix pro Tag ist der Einfluss neutral bis leicht positiv. Danach überwiegt der negative Effekt. 
<a name="l1467"><span class="ln">1467 </span></a> 
<a name="l1468"><span class="ln">1468 </span></a>--- 
<a name="l1469"><span class="ln">1469 </span></a> 
<a name="l1470"><span class="ln">1470 </span></a>### 🔹 `attendance_percentage` 
<a name="l1471"><span class="ln">1471 </span></a>- **Verlauf:** Deutlicher positiver Effekt bei hoher Anwesenheit. 
<a name="l1472"><span class="ln">1472 </span></a>- **SHAP-Wert = 0 bei:** **ca. 85 %** 
<a name="l1473"><span class="ln">1473 </span></a>- **Interpretation:** Unter 85 % Anwesenheit wirkt sich dieses Feature negativ auf die Vorhersage aus. Ab 85 % beginnt ein klar positiver Einfluss. 
<a name="l1474"><span class="ln">1474 </span></a> 
<a name="l1475"><span class="ln">1475 </span></a>--- 
<a name="l1476"><span class="ln">1476 </span></a> 
<a name="l1477"><span class="ln">1477 </span></a>### 🔹 `age` 
<a name="l1478"><span class="ln">1478 </span></a>- **Verlauf:** Nahezu horizontal um 0. 
<a name="l1479"><span class="ln">1479 </span></a>- **SHAP-Wert = 0 bei:** nicht definierbar (schwankt minimal um 0) 
<a name="l1480"><span class="ln">1480 </span></a>- **Interpretation:** Das Alter hat keinen nennenswerten Effekt auf die Modellvorhersage. Kein klarer Schwellenwert vorhanden. 
<a name="l1481"><span class="ln">1481 </span></a> 
<a name="l1482"><span class="ln">1482 </span></a>--- 
<a name="l1483"><span class="ln">1483 </span></a> 
<a name="l1484"><span class="ln">1484 </span></a>## Interpretation der Schwellenwertanalyse 
<a name="l1485"><span class="ln">1485 </span></a> 
<a name="l1486"><span class="ln">1486 </span></a>Die vorgestellten Visualisierungen zeigen, wie stark einzelne Merkmale abhängig von ihrem konkreten Wert die Modellvorhersage der Prüfungsleistung beeinflussen. Durch die Betrachtung der SHAP-Werte entlang der Merkmalsausprägung lassen sich **nicht-lineare Effekte**, **kritische Kipppunkte** sowie **überraschende Trends** erkennen. 
<a name="l1487"><span class="ln">1487 </span></a> 
<a name="l1488"><span class="ln">1488 </span></a>### Was war erwartbar? 
<a name="l1489"><span class="ln">1489 </span></a>- Es bestätigt sich, dass **mehr Lernzeit** und eine **bessere mentale Gesundheit** positiv zur Vorhersage beitragen. Dies entspricht allgemeinen Annahmen über erfolgreiche Lernverhaltensweisen. 
<a name="l1490"><span class="ln">1490 </span></a>- Auch die Erkenntnis, dass **hoher Medienkonsum (Netflix, Social Media)** oder **geringe Schlafdauer** tendenziell negativ wirken, ist konsistent mit bestehenden Forschungsergebnissen. 
<a name="l1491"><span class="ln">1491 </span></a>- Die **Anwesenheit in Lehrveranstaltungen** zeigt einen klaren Zusammenhang: erst ab etwa 85% beginnt ein positiver Effekt – was impliziert, dass reine Mindestanwesenheit nicht ausreicht, um sich positiv auf die Leistung auszuwirken. 
<a name="l1492"><span class="ln">1492 </span></a> 
<a name="l1493"><span class="ln">1493 </span></a>### Was war überraschend? 
<a name="l1494"><span class="ln">1494 </span></a>- Bei **mental_health_rating** zeigt sich, dass erst ab einem Wert von 6 ein wirklich positiver Einfluss sichtbar wird – das deutet darauf hin, dass auch mittlere Werte im Modell noch als problematisch interpretiert werden. 
<a name="l1495"><span class="ln">1495 </span></a>- Auch bei **exercise_frequency** wird der Effekt erst ab ca. 3 Einheiten pro Woche positiv. Weniger Bewegung scheint im Modell sogar leicht negativ zu wirken – was eine genauere Auseinandersetzung mit diesem Thema nahelegt. 
<a name="l1496"><span class="ln">1496 </span></a>- **Age** hatte im Modell keinerlei Einfluss – was insofern überrascht, als dass man annehmen könnte, dass ältere oder erfahrenere Studierende eventuell strukturell andere Ergebnisse erzielen. Das Modell erkennt hier aber keine systematische Tendenz. 
<a name="l1497"><span class="ln">1497 </span></a> 
<a name="l1498"><span class="ln">1498 </span></a>### Bedeutung der Nullschnittpunkte 
<a name="l1499"><span class="ln">1499 </span></a>Die Nullschnittpunkte markieren die **kritischen Schwellen**, ab denen ein Merkmal das Modellverhalten „umschaltet“ – also von einem neutralen oder negativen Einfluss zu einem positiven (oder umgekehrt). Solche Punkte bieten eine wertvolle Grundlage, um: 
<a name="l1500"><span class="ln">1500 </span></a>- **interventionsrelevante Grenzwerte** zu definieren (z.B. mindestens 3 Lernstunden pro Tag, mindestens 7 Stunden Schlaf), 
<a name="l1501"><span class="ln">1501 </span></a>- **kritische Risikozonen** zu identifizieren (z.B. &gt;1.5h Social Media), 
<a name="l1502"><span class="ln">1502 </span></a>- und **potenzielle Zielgrößen** für individuelle Verbesserung zu formulieren. 
<a name="l1503"><span class="ln">1503 </span></a> 
<a name="l1504"><span class="ln">1504 </span></a>--- 
<a name="l1505"><span class="ln">1505 </span></a> 
<a name="l1506"><span class="ln">1506 </span></a>**Fazit:** 
<a name="l1507"><span class="ln">1507 </span></a>Die Schwellenwertanalyse liefert konkrete Einsichten darüber, **wie** genau ein Merkmal wirkt, nicht nur ob. Dadurch entsteht ein tieferes Verständnis der Modelllogik und der Zusammenhänge zwischen studentischem Verhalten und prognostizierter Leistung. Diese Form der Modellinterpretation ist ein zentraler Bestandteil erklärbarer KI (XAI) und zeigt eindrucksvoll, wie datenbasierte Modelle nicht nur vorhersagen, sondern auch **verstehbar und nachvollziehbar gemacht werden können.** 
<a name="l1508"><span class="ln">1508 </span></a> 
<a name="l1509"><span class="ln">1509 </span></a> 
<a name="l1510"><span class="ln">1510 </span></a> 
<a name="l1511"><span class="ln">1511 </span></a> <hr class="ls0"><a name="l1512"><span class="ln">1512 </span></a>#%% md 
<a name="l1513"><span class="ln">1513 </span></a># Schlussbetrachtung und Gesamteinordnung 
<a name="l1514"><span class="ln">1514 </span></a> 
<a name="l1515"><span class="ln">1515 </span></a>## Zusammenfassung des Projektverlaufs 
<a name="l1516"><span class="ln">1516 </span></a> 
<a name="l1517"><span class="ln">1517 </span></a>In dieser Arbeit wurde anhand eines synthetischen Datensatzes untersucht, wie sich studentische Verhaltensweisen auf die akademische Leistung auswirken. Dazu wurden zwei Modelle trainiert. Eine **lineare Regression** als transparentes Referenzmodell sowie ein **Random Forest** als leistungsstarkes Black-Box-Modell. 
<a name="l1518"><span class="ln">1518 </span></a> 
<a name="l1519"><span class="ln">1519 </span></a>Beide Modelle wurden systematisch analysiert: 
<a name="l1520"><span class="ln">1520 </span></a>- Zunächst durch klassische Gütemaße (MSE, R²), 
<a name="l1521"><span class="ln">1521 </span></a>- anschließend mittels **SHAP-Analyse**, um erklärbare Einblicke in die Funktionsweise und Einflussgrößen der Modelle zu gewinnen. 
<a name="l1522"><span class="ln">1522 </span></a> 
<a name="l1523"><span class="ln">1523 </span></a>Die erklärbaren KI-Methoden (XAI) ermöglichten dabei nicht nur die Bewertung der globalen Wichtigkeit einzelner Features, sondern auch eine **lokale, merkmalsbasierte Schwellenwertanalyse**. Damit wurde deutlich, **ab welchen Ausprägungen** ein Feature beginnt, sich systematisch positiv oder negativ auf die Vorhersage auszuwirken. 
<a name="l1524"><span class="ln">1524 </span></a> 
<a name="l1525"><span class="ln">1525 </span></a>--- 
<a name="l1526"><span class="ln">1526 </span></a> 
<a name="l1527"><span class="ln">1527 </span></a>### Methodische Reflexion 
<a name="l1528"><span class="ln">1528 </span></a> 
<a name="l1529"><span class="ln">1529 </span></a>- Die **lineare Regression** lieferte nachvollziehbare Ergebnisse, allerdings mit teils zu starren Zusammenhängen. 
<a name="l1530"><span class="ln">1530 </span></a>- Der **Random Forest** erzielte eine deutlich bessere Modellgüte, zeigte aber auch komplexere (nichtlineare) Einflussstrukturen. 
<a name="l1531"><span class="ln">1531 </span></a>- Erst durch den Einsatz von **SHAP** konnten diese Zusammenhänge transparent und individuell verständlich gemacht werden. 
<a name="l1532"><span class="ln">1532 </span></a> 
<a name="l1533"><span class="ln">1533 </span></a>Besonders die Visualisierung der SHAP-Werte als: 
<a name="l1534"><span class="ln">1534 </span></a>- Barplots (globale Wichtigkeit), 
<a name="l1535"><span class="ln">1535 </span></a>- Summary Plots (Verteilung und Richtung), 
<a name="l1536"><span class="ln">1536 </span></a>- Dependence Plots (Interaktionen), 
<a name="l1537"><span class="ln">1537 </span></a>- sowie Punktverläufe mit Schwellenwertinterpretation, 
<a name="l1538"><span class="ln">1538 </span></a> 
<a name="l1539"><span class="ln">1539 </span></a>ermöglichten eine tiefgehende Analyse, die weit über eine klassische Modellbewertung hinausgeht. 
<a name="l1540"><span class="ln">1540 </span></a> 
<a name="l1541"><span class="ln">1541 </span></a>--- 
<a name="l1542"><span class="ln">1542 </span></a> 
<a name="l1543"><span class="ln">1543 </span></a>### Interpretation der wichtigsten Ergebnisse 
<a name="l1544"><span class="ln">1544 </span></a> 
<a name="l1545"><span class="ln">1545 </span></a>Die SHAP-Analysen ergaben, dass: 
<a name="l1546"><span class="ln">1546 </span></a>- **Mehr Lernzeit**, **bessere mentale Gesundheit**, **ausreichender Schlaf** und **hohe Anwesenheit** konsistent positiv wirken. 
<a name="l1547"><span class="ln">1547 </span></a>- **Hoher Social Media- und Netflix-Konsum** sowie **Schlafmangel** ab bestimmten Schwellenwerten klar negativ beeinflussen. 
<a name="l1548"><span class="ln">1548 </span></a>- Der Einfluss vieler Features **nicht-linear** verläuft und häufig **erst ab einem bestimmten Punkt ins Positive umschlägt** (z.B. ab 3h Lernzeit oder ab 85% Anwesenheit). 
<a name="l1549"><span class="ln">1549 </span></a>- Einige Merkmale, etwa **Alter** im Modell **keine systematische Rolle spielen**. 
<a name="l1550"><span class="ln">1550 </span></a> 
<a name="l1551"><span class="ln">1551 </span></a>Diese Erkenntnisse wurden nicht nur visualisiert, sondern auch systematisch dokumentiert, wodurch konkrete Schwellenwerte (z.B. 6.8 Stunden Schlaf, &lt;1.5h Social Media) als Handlungsempfehlung ableitbar wurden. 
<a name="l1552"><span class="ln">1552 </span></a> 
<a name="l1553"><span class="ln">1553 </span></a>--- 
<a name="l1554"><span class="ln">1554 </span></a> 
<a name="l1555"><span class="ln">1555 </span></a>### Limitationen 
<a name="l1556"><span class="ln">1556 </span></a> 
<a name="l1557"><span class="ln">1557 </span></a>Trotz der fundierten Analyse gilt es, folgende Einschränkungen zu beachten: 
<a name="l1558"><span class="ln">1558 </span></a>- Der zugrunde liegende Datensatz ist **synthetisch generiert** und orientiert sich nur an plausiblen, aber nicht real validierten Strukturen. 
<a name="l1559"><span class="ln">1559 </span></a>- Die Modelle basieren auf den verfügbaren Merkmalen – **nicht berücksichtigte externe Faktoren** (z.B. Prüfungsangst, Vorwissen, Betreuung) könnten ebenfalls relevant sein. 
<a name="l1560"><span class="ln">1560 </span></a>- Die Interpretationen gelten ausschließlich im Rahmen des trainierten Modells – sie zeigen **modellinterne Kausalität**, aber keine echte Kausalität im wissenschaftlichen Sinne. 
<a name="l1561"><span class="ln">1561 </span></a> 
<a name="l1562"><span class="ln">1562 </span></a>--- 
<a name="l1563"><span class="ln">1563 </span></a> 
<a name="l1564"><span class="ln">1564 </span></a>### Bedeutung und Einsatzpotenzial 
<a name="l1565"><span class="ln">1565 </span></a> 
<a name="l1566"><span class="ln">1566 </span></a>Diese Arbeit demonstriert, wie **Machine Learning und XAI** gemeinsam genutzt werden können, um nicht nur leistungsfähige Vorhersagemodelle zu bauen, sondern auch konkrete, nachvollziehbare Aussagen zu generieren wie z.B.: 
<a name="l1567"><span class="ln">1567 </span></a>- Welche Lerngewohnheiten förderlich oder hinderlich sind, 
<a name="l1568"><span class="ln">1568 </span></a>- Wo realistische Zielwerte liegen (z.B. mindestens 3h Lernen/Tag), 
<a name="l1569"><span class="ln">1569 </span></a>- Und wie individuelles Verhalten mit erwarteter Leistung zusammenhängt. 
<a name="l1570"><span class="ln">1570 </span></a> 
<a name="l1571"><span class="ln">1571 </span></a>Gerade im Bildungsbereich bietet die Kombination aus erklärbaren Vorhersagen und visueller Aufbereitung ein großes Potenzial für: 
<a name="l1572"><span class="ln">1572 </span></a>- **Studienberatung** 
<a name="l1573"><span class="ln">1573 </span></a>- **Selbstreflexion von Studierenden** 
<a name="l1574"><span class="ln">1574 </span></a>- **Didaktische Entscheidungen** im Hochschulkontext 
<a name="l1575"><span class="ln">1575 </span></a> 
<a name="l1576"><span class="ln">1576 </span></a>--- 
<a name="l1577"><span class="ln">1577 </span></a> 
<a name="l1578"><span class="ln">1578 </span></a>**Abschließend zeigt dieses Projekt**, dass der Mehrwert von XAI nicht nur im Verstehen von Modellen liegt, sondern in der Möglichkeit, **konkrete, nachvollziehbare Entscheidungen aus Daten abzuleiten** – und dies auch für komplexe, nichtlineare Zusammenhänge visuell transparent zu machen. 
<a name="l1579"><span class="ln">1579 </span></a> <hr class="ls0"><a name="l1580"><span class="ln">1580 </span></a>#%% md 
<a name="l1581"><span class="ln">1581 </span></a>--- 
<a name="l1582"><span class="ln">1582 </span></a> 
<a name="l1583"><span class="ln">1583 </span></a>## Lessons Learned – Was aus dem Projekt mitgenommen wurde 
<a name="l1584"><span class="ln">1584 </span></a> 
<a name="l1585"><span class="ln">1585 </span></a>✅ **Modellgüte ist nicht alles.** 
<a name="l1586"><span class="ln">1586 </span></a>Ein leistungsfähiges Modell wie der Random Forest liefert zwar bessere Vorhersagen, doch ohne Erklärbarkeit bleiben viele Zusammenhänge verborgen. Erst durch XAI-Methoden wie SHAP wurden die inneren Entscheidungsprozesse verständlich und nachvollziehbar. 
<a name="l1587"><span class="ln">1587 </span></a> 
<a name="l1588"><span class="ln">1588 </span></a>✅ **Erklärbarkeit erhöht Vertrauen.** 
<a name="l1589"><span class="ln">1589 </span></a>Die visuelle Aufbereitung der Einflussgrößen – etwa durch Barplots, Dependence-Plots und Schwellenwertanalysen – machte deutlich, wie wichtig nachvollziehbare Modelle im Bildungs- und Beratungskontext sind. 
<a name="l1590"><span class="ln">1590 </span></a> 
<a name="l1591"><span class="ln">1591 </span></a>✅ **Nicht alle Effekte sind linear.** 
<a name="l1592"><span class="ln">1592 </span></a>Viele Merkmale – wie Schlafdauer, Sport oder Mediennutzung – wirken sich erst ab bestimmten Ausprägungen aus. Solche Erkenntnisse wären mit rein linearen Modellen nur schwer erfassbar gewesen. 
<a name="l1593"><span class="ln">1593 </span></a> 
<a name="l1594"><span class="ln">1594 </span></a>✅ **Datenverständnis braucht Visualisierung.** 
<a name="l1595"><span class="ln">1595 </span></a>Erst durch gut gestaltete, interpretierbare Diagramme wurde deutlich, wo z.B. Kipppunkte liegen (z.B. 3h Lernen, 1.5h Social Media). Solche Darstellungen fördern sowohl die eigene Reflexion als auch die Kommunikation mit Dritten. 
<a name="l1596"><span class="ln">1596 </span></a> 
<a name="l1597"><span class="ln">1597 </span></a>✅ **Erklärbare KI ist mehr als ein Tool – es ist eine Denkweise.** 
<a name="l1598"><span class="ln">1598 </span></a>Statt nur auf das „Was“ (z.B. Vorhersagewert) zu schauen, hat dieses Projekt gezeigt, wie wichtig auch das „Warum“ und „Wie“ ist. Dadurch lassen sich datenbasierte Modelle nicht nur verwenden, sondern auch verstehen, hinterfragen und sinnvoll einsetzen. 
<a name="l1599"><span class="ln">1599 </span></a> <hr class="ls0"><a name="l1600"><span class="ln">1600 </span></a>#%% md 
<a name="l1601"><span class="ln">1601 </span></a>## Bonus: Interaktiver Vorhersage-Rechner 
<a name="l1602"><span class="ln">1602 </span></a> 
<a name="l1603"><span class="ln">1603 </span></a>Zum Abschluss dieses Projekts wird ein kleiner interaktiver Rechner bereitgestellt. Nutzerinnen und Nutzer können selbstständig verschiedene Merkmalsausprägungen angeben (z.B. Lernzeit, Schlafdauer, mentale Gesundheit) und auf dieser Basis eine **Vorhersage der erwarteten Prüfungsleistung** erhalten. 
<a name="l1604"><span class="ln">1604 </span></a> 
<a name="l1605"><span class="ln">1605 </span></a>Die Vorhersage basiert auf dem trainierten **linearen Regressionsmodell**, das in den vorherigen Kapiteln entwickelt und evaluiert wurde. 
<a name="l1606"><span class="ln">1606 </span></a> 
<a name="l1607"><span class="ln">1607 </span></a>### So funktioniert die Eingabe: 
<a name="l1608"><span class="ln">1608 </span></a>- Wähle oder gib für jedes Feature den gewünschten Wert ein 
<a name="l1609"><span class="ln">1609 </span></a>- Klicke auf **„Vorhersage starten“** 
<a name="l1610"><span class="ln">1610 </span></a>- Die geschätzte Prüfungsleistung erscheint direkt darunter 
<a name="l1611"><span class="ln">1611 </span></a> 
<a name="l1612"><span class="ln">1612 </span></a>Diese Anwendung zeigt beispielhaft, wie **erklärbare KI-Modelle** nicht nur analysiert, sondern auch in der Praxis verwendet werden können z.B. für Selbstreflexion, Beratung oder hypothetische Szenarien. 
<a name="l1613"><span class="ln">1613 </span></a> 
<a name="l1614"><span class="ln">1614 </span></a>Es müssen alle codezeilen des Notebooks vorher ausgeführt und der Server gestartet worden sein damit der Rechner funktioniert. 
<a name="l1615"><span class="ln">1615 </span></a> <hr class="ls0"><a name="l1616"><span class="ln">1616 </span></a>#%% 
<a name="l1617"><span class="ln">1617 </span></a></span>
<a name="l1618"><span class="ln">1618 </span></a><span class="s2"># Stil für Titel</span>
<a name="l1619"><span class="ln">1619 </span></a><span class="s0">display(HTML(</span><span class="s3">&quot;&lt;h3 style='color:#2C3E50'&gt; Individuelle Prognose der Prüfungsleistung&lt;/h3&gt;&quot;</span><span class="s0">))</span>
<a name="l1620"><span class="ln">1620 </span></a>
<a name="l1621"><span class="ln">1621 </span></a><span class="s2"># Eingabefelder gruppieren</span>
<a name="l1622"><span class="ln">1622 </span></a><span class="s0">numerical_widgets = widgets.VBox([</span>
<a name="l1623"><span class="ln">1623 </span></a>    <span class="s0">widgets.IntSlider(min=</span><span class="s4">16</span><span class="s0">, max=</span><span class="s4">35</span><span class="s0">, value=</span><span class="s4">20</span><span class="s0">, description=</span><span class="s3">&quot;Alter:&quot;</span><span class="s0">),</span>
<a name="l1624"><span class="ln">1624 </span></a>    <span class="s0">widgets.FloatSlider(min=</span><span class="s4">0</span><span class="s0">, max=</span><span class="s4">10</span><span class="s0">, step=</span><span class="s4">0.1</span><span class="s0">, value=</span><span class="s4">3.0</span><span class="s0">, description=</span><span class="s3">&quot;Lernzeit:&quot;</span><span class="s0">),</span>
<a name="l1625"><span class="ln">1625 </span></a>    <span class="s0">widgets.FloatSlider(min=</span><span class="s4">0</span><span class="s0">, max=</span><span class="s4">12</span><span class="s0">, step=</span><span class="s4">0.1</span><span class="s0">, value=</span><span class="s4">7.0</span><span class="s0">, description=</span><span class="s3">&quot;Schlaf:&quot;</span><span class="s0">),</span>
<a name="l1626"><span class="ln">1626 </span></a>    <span class="s0">widgets.FloatSlider(min=</span><span class="s4">0</span><span class="s0">, max=</span><span class="s4">10</span><span class="s0">, step=</span><span class="s4">0.1</span><span class="s0">, value=</span><span class="s4">2.0</span><span class="s0">, description=</span><span class="s3">&quot;Social Media:&quot;</span><span class="s0">),</span>
<a name="l1627"><span class="ln">1627 </span></a>    <span class="s0">widgets.FloatSlider(min=</span><span class="s4">0</span><span class="s0">, max=</span><span class="s4">10</span><span class="s0">, step=</span><span class="s4">0.1</span><span class="s0">, value=</span><span class="s4">1.0</span><span class="s0">, description=</span><span class="s3">&quot;Netflix:&quot;</span><span class="s0">),</span>
<a name="l1628"><span class="ln">1628 </span></a>    <span class="s0">widgets.IntSlider(min=</span><span class="s4">0</span><span class="s0">, max=</span><span class="s4">100</span><span class="s0">, value=</span><span class="s4">90</span><span class="s0">, description=</span><span class="s3">&quot;Anwesenheit:&quot;</span><span class="s0">),</span>
<a name="l1629"><span class="ln">1629 </span></a>    <span class="s0">widgets.IntSlider(min=</span><span class="s4">0</span><span class="s0">, max=</span><span class="s4">10</span><span class="s0">, value=</span><span class="s4">3</span><span class="s0">, description=</span><span class="s3">&quot;Sport/Woche:&quot;</span><span class="s0">),</span>
<a name="l1630"><span class="ln">1630 </span></a>    <span class="s0">widgets.IntSlider(min=</span><span class="s4">1</span><span class="s0">, max=</span><span class="s4">10</span><span class="s0">, value=</span><span class="s4">6</span><span class="s0">, description=</span><span class="s3">&quot;Mental:&quot;</span><span class="s0">),</span>
<a name="l1631"><span class="ln">1631 </span></a><span class="s0">])</span>
<a name="l1632"><span class="ln">1632 </span></a>
<a name="l1633"><span class="ln">1633 </span></a><span class="s0">categorical_widgets = widgets.VBox([</span>
<a name="l1634"><span class="ln">1634 </span></a>    <span class="s0">widgets.Dropdown(options=[</span><span class="s3">&quot;Male&quot;</span><span class="s0">, </span><span class="s3">&quot;Female&quot;</span><span class="s0">, </span><span class="s3">&quot;Other&quot;</span><span class="s0">], description=</span><span class="s3">&quot;Geschlecht:&quot;</span><span class="s0">),</span>
<a name="l1635"><span class="ln">1635 </span></a>    <span class="s0">widgets.Dropdown(options=[</span><span class="s3">&quot;Yes&quot;</span><span class="s0">, </span><span class="s3">&quot;No&quot;</span><span class="s0">], description=</span><span class="s3">&quot;Nebenjob:&quot;</span><span class="s0">),</span>
<a name="l1636"><span class="ln">1636 </span></a>    <span class="s0">widgets.Dropdown(options=[</span><span class="s3">&quot;Poor&quot;</span><span class="s0">, </span><span class="s3">&quot;Average&quot;</span><span class="s0">, </span><span class="s3">&quot;Good&quot;</span><span class="s0">], description=</span><span class="s3">&quot;Ernährung:&quot;</span><span class="s0">),</span>
<a name="l1637"><span class="ln">1637 </span></a>    <span class="s0">widgets.Dropdown(options=[</span><span class="s3">&quot;High School&quot;</span><span class="s0">, </span><span class="s3">&quot;Bachelor&quot;</span><span class="s0">, </span><span class="s3">&quot;Master&quot;</span><span class="s0">, </span><span class="s3">&quot;nan&quot;</span><span class="s0">], description=</span><span class="s3">&quot;Eltern:&quot;</span><span class="s0">),</span>
<a name="l1638"><span class="ln">1638 </span></a>    <span class="s0">widgets.Dropdown(options=[</span><span class="s3">&quot;Poor&quot;</span><span class="s0">, </span><span class="s3">&quot;Average&quot;</span><span class="s0">, </span><span class="s3">&quot;Good&quot;</span><span class="s0">], description=</span><span class="s3">&quot;Internet:&quot;</span><span class="s0">),</span>
<a name="l1639"><span class="ln">1639 </span></a>    <span class="s0">widgets.Dropdown(options=[</span><span class="s3">&quot;Yes&quot;</span><span class="s0">, </span><span class="s3">&quot;No&quot;</span><span class="s0">], description=</span><span class="s3">&quot;Aktivitäten:&quot;</span><span class="s0">)</span>
<a name="l1640"><span class="ln">1640 </span></a><span class="s0">])</span>
<a name="l1641"><span class="ln">1641 </span></a>
<a name="l1642"><span class="ln">1642 </span></a><span class="s2"># Layout</span>
<a name="l1643"><span class="ln">1643 </span></a><span class="s0">input_ui = widgets.HBox([numerical_widgets, categorical_widgets])</span>
<a name="l1644"><span class="ln">1644 </span></a>
<a name="l1645"><span class="ln">1645 </span></a><span class="s2"># Button und Ausgabe</span>
<a name="l1646"><span class="ln">1646 </span></a><span class="s0">button = widgets.Button(description=</span><span class="s3">&quot;Vorhersage starten&quot;</span><span class="s0">, button_style=</span><span class="s3">&quot;success&quot;</span><span class="s0">)</span>
<a name="l1647"><span class="ln">1647 </span></a><span class="s0">output = widgets.Output()</span>
<a name="l1648"><span class="ln">1648 </span></a><span class="s0">display(input_ui, button, output)</span>
<a name="l1649"><span class="ln">1649 </span></a>
<a name="l1650"><span class="ln">1650 </span></a><span class="s2"># Vorhersagefunktion mit Begrenzung auf 0–100 Punkte</span>
<a name="l1651"><span class="ln">1651 </span></a><span class="s1">def </span><span class="s0">make_prediction(b):</span>
<a name="l1652"><span class="ln">1652 </span></a>    <span class="s0">keys = [</span>
<a name="l1653"><span class="ln">1653 </span></a>        <span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;study_hours_per_day&quot;</span><span class="s0">, </span><span class="s3">&quot;sleep_hours&quot;</span><span class="s0">, </span><span class="s3">&quot;social_media_hours&quot;</span><span class="s0">, </span><span class="s3">&quot;netflix_hours&quot;</span><span class="s0">,</span>
<a name="l1654"><span class="ln">1654 </span></a>        <span class="s3">&quot;attendance_percentage&quot;</span><span class="s0">, </span><span class="s3">&quot;exercise_frequency&quot;</span><span class="s0">, </span><span class="s3">&quot;mental_health_rating&quot;</span><span class="s0">,</span>
<a name="l1655"><span class="ln">1655 </span></a>        <span class="s3">&quot;gender&quot;</span><span class="s0">, </span><span class="s3">&quot;part_time_job&quot;</span><span class="s0">, </span><span class="s3">&quot;diet_quality&quot;</span><span class="s0">, </span><span class="s3">&quot;parental_education_level&quot;</span><span class="s0">,</span>
<a name="l1656"><span class="ln">1656 </span></a>        <span class="s3">&quot;internet_quality&quot;</span><span class="s0">, </span><span class="s3">&quot;extracurricular_participation&quot;</span>
<a name="l1657"><span class="ln">1657 </span></a>    <span class="s0">]</span>
<a name="l1658"><span class="ln">1658 </span></a>
<a name="l1659"><span class="ln">1659 </span></a>    <span class="s0">widgets_flat = numerical_widgets.children + categorical_widgets.children</span>
<a name="l1660"><span class="ln">1660 </span></a>    <span class="s0">user_input = {k: w.value </span><span class="s1">for </span><span class="s0">k, w </span><span class="s1">in </span><span class="s0">zip(keys, widgets_flat)}</span>
<a name="l1661"><span class="ln">1661 </span></a>    <span class="s0">df_input = pd.DataFrame([user_input])</span>
<a name="l1662"><span class="ln">1662 </span></a>
<a name="l1663"><span class="ln">1663 </span></a>    <span class="s0">raw_prediction = model_pipeline_lr.predict(df_input)[</span><span class="s4">0</span><span class="s0">]</span>
<a name="l1664"><span class="ln">1664 </span></a>    <span class="s0">prediction = max(</span><span class="s4">0</span><span class="s0">, min(</span><span class="s4">100</span><span class="s0">, raw_prediction))  </span><span class="s2"># Begrenzung auf 0–100</span>
<a name="l1665"><span class="ln">1665 </span></a>
<a name="l1666"><span class="ln">1666 </span></a>    <span class="s1">with </span><span class="s0">output:</span>
<a name="l1667"><span class="ln">1667 </span></a>        <span class="s0">clear_output()</span>
<a name="l1668"><span class="ln">1668 </span></a>        <span class="s0">print(</span><span class="s3">f&quot; Erwartete Prüfungsleistung: </span><span class="s5">{</span><span class="s0">prediction</span><span class="s5">:</span><span class="s3">.2f</span><span class="s5">} </span><span class="s3">Punkte&quot;</span><span class="s0">)</span>
<a name="l1669"><span class="ln">1669 </span></a>
<a name="l1670"><span class="ln">1670 </span></a>
<a name="l1671"><span class="ln">1671 </span></a>
<a name="l1672"><span class="ln">1672 </span></a><span class="s2"># Ereignisbindung</span>
<a name="l1673"><span class="ln">1673 </span></a><span class="s0">button.on_click(make_prediction)</span>
<a name="l1674"><span class="ln">1674 </span></a></pre>
</body>
</html>